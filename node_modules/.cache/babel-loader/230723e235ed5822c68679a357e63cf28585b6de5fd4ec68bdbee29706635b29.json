{"ast":null,"code":"import _createForOfIteratorHelper from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper.js\";\nimport _defineProperty from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nimport _classCallCheck from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _get from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get.js\";\nimport _getPrototypeOf from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf.js\";\nimport _inherits from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, cast, mul, notEqual, reshape, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport var Dropout = /*#__PURE__*/function (_Layer) {\n  _inherits(Dropout, _Layer);\n  var _super = _createSuper(Dropout);\n  function Dropout(args) {\n    var _this;\n    _classCallCheck(this, Dropout);\n    _this = _super.call(this, args);\n    _this.rate = Math.max(Math.min(args.rate, 1), 0);\n    // So that the scalar doesn't get tidied up between executions.\n    _this.noiseShape = args.noiseShape;\n    _this.seed = args.seed;\n    _this.supportsMasking = true;\n    return _this;\n  }\n  _createClass(Dropout, [{\n    key: \"getNoiseShape\",\n    value: function getNoiseShape(input) {\n      if (this.noiseShape == null) {\n        return this.noiseShape;\n      }\n      var inputShape = input.shape;\n      var noiseShape = [];\n      for (var i = 0; i < this.noiseShape.length; ++i) {\n        noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n      }\n      return noiseShape;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this2 = this;\n      return tidy(function () {\n        _this2.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        if (0 < _this2.rate && _this2.rate < 1) {\n          var training = kwargs['training'] == null ? false : kwargs['training'];\n          var noiseShape = _this2.getNoiseShape(input);\n          var output = K.inTrainPhase(function () {\n            return K.dropout(input, _this2.rate, noiseShape, _this2.seed);\n          }, function () {\n            return input;\n          }, training);\n          return output;\n        }\n        return inputs;\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        rate: this.rate,\n        noiseShape: this.noiseShape,\n        seed: this.seed\n      };\n      var baseConfig = _get(_getPrototypeOf(Dropout.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      return _get(_getPrototypeOf(Dropout.prototype), \"dispose\", this).call(this);\n    }\n  }]);\n  return Dropout;\n}(Layer);\n/** @nocollapse */\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport var SpatialDropout1D = /*#__PURE__*/function (_Dropout) {\n  _inherits(SpatialDropout1D, _Dropout);\n  var _super2 = _createSuper(SpatialDropout1D);\n  function SpatialDropout1D(args) {\n    var _this3;\n    _classCallCheck(this, SpatialDropout1D);\n    _this3 = _super2.call(this, args);\n    _this3.inputSpec = [{\n      ndim: 3\n    }];\n    return _this3;\n  }\n  _createClass(SpatialDropout1D, [{\n    key: \"getNoiseShape\",\n    value: function getNoiseShape(input) {\n      var inputShape = input.shape;\n      return [inputShape[0], 1, inputShape[2]];\n    }\n  }]);\n  return SpatialDropout1D;\n}(Dropout);\n/** @nocollapse */\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport var Dense = /*#__PURE__*/function (_Layer2) {\n  _inherits(Dense, _Layer2);\n  var _super3 = _createSuper(Dense);\n  function Dense(args) {\n    var _this4;\n    _classCallCheck(this, Dense);\n    _this4 = _super3.call(this, args);\n    // Default activation: Linear (none).\n    _this4.activation = null;\n    _this4.useBias = true;\n    _this4.kernel = null;\n    _this4.bias = null;\n    _this4.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    _this4.DEFAULT_BIAS_INITIALIZER = 'zeros';\n    if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      var batchSize = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      _this4.batchInputShape = [batchSize, args.inputDim];\n    }\n    _this4.units = args.units;\n    assertPositiveInteger(_this4.units, 'units');\n    _this4.activation = getActivation(args.activation);\n    if (args.useBias != null) {\n      _this4.useBias = args.useBias;\n    }\n    _this4.kernelInitializer = getInitializer(args.kernelInitializer || _this4.DEFAULT_KERNEL_INITIALIZER);\n    _this4.biasInitializer = getInitializer(args.biasInitializer || _this4.DEFAULT_BIAS_INITIALIZER);\n    _this4.kernelConstraint = getConstraint(args.kernelConstraint);\n    _this4.biasConstraint = getConstraint(args.biasConstraint);\n    _this4.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    _this4.biasRegularizer = getRegularizer(args.biasRegularizer);\n    _this4.activityRegularizer = getRegularizer(args.activityRegularizer);\n    _this4.supportsMasking = true;\n    _this4.inputSpec = [{\n      minNDim: 2\n    }];\n    return _this4;\n  }\n  _createClass(Dense, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var inputLastDim = inputShape[inputShape.length - 1];\n      if (this.kernel == null) {\n        this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        if (this.useBias) {\n          this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n      }\n      this.inputSpec = [{\n        minNDim: 2,\n        axes: _defineProperty({}, -1, inputLastDim)\n      }];\n      this.built = true;\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var outputShape = inputShape.slice();\n      outputShape[outputShape.length - 1] = this.units;\n      return outputShape;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this5 = this;\n      return tidy(function () {\n        _this5.invokeCallHook(inputs, kwargs);\n        // Dense layer accepts only a single input.\n        var input = getExactlyOneTensor(inputs);\n        var fusedActivationName = mapActivationToFusedKernel(_this5.activation.getClassName());\n        var output;\n        if (fusedActivationName != null) {\n          output = K.dot(input, _this5.kernel.read(), fusedActivationName, _this5.bias ? _this5.bias.read() : null);\n        } else {\n          output = K.dot(input, _this5.kernel.read());\n          if (_this5.bias != null) {\n            output = K.biasAdd(output, _this5.bias.read());\n          }\n          if (_this5.activation != null) {\n            output = _this5.activation.apply(output);\n          }\n        }\n        return output;\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        units: this.units,\n        activation: serializeActivation(this.activation),\n        useBias: this.useBias,\n        kernelInitializer: serializeInitializer(this.kernelInitializer),\n        biasInitializer: serializeInitializer(this.biasInitializer),\n        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n        biasRegularizer: serializeRegularizer(this.biasRegularizer),\n        activityRegularizer: serializeRegularizer(this.activityRegularizer),\n        kernelConstraint: serializeConstraint(this.kernelConstraint),\n        biasConstraint: serializeConstraint(this.biasConstraint)\n      };\n      var baseConfig = _get(_getPrototypeOf(Dense.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Dense;\n}(Layer);\n/** @nocollapse */\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport var Flatten = /*#__PURE__*/function (_Layer3) {\n  _inherits(Flatten, _Layer3);\n  var _super4 = _createSuper(Flatten);\n  function Flatten(args) {\n    var _this6;\n    _classCallCheck(this, Flatten);\n    args = args || {};\n    _this6 = _super4.call(this, args);\n    _this6.inputSpec = [{\n      minNDim: 3\n    }];\n    _this6.dataFormat = args.dataFormat;\n    return _this6;\n  }\n  _createClass(Flatten, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var _iterator = _createForOfIteratorHelper(inputShape.slice(1)),\n        _step;\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var dim = _step.value;\n          if (dim == null) {\n            throw new ValueError(\"The shape of the input to \\\"Flatten\\\" is not fully defined \" + \"(got \".concat(inputShape.slice(1), \"). Make sure to pass a complete \") + \"\\\"input_shape\\\" or \\\"batch_input_shape\\\" argument to the first \" + \"layer in your model.\");\n          }\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n      return [inputShape[0], arrayProd(inputShape, 1)];\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this7 = this;\n      return tidy(function () {\n        _this7.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        if (_this7.dataFormat === 'channelsFirst' && input.rank > 1) {\n          var permutation = [0];\n          for (var i = 2; i < input.rank; ++i) {\n            permutation.push(i);\n          }\n          permutation.push(1);\n          input = transpose(input, permutation);\n        }\n        return K.batchFlatten(input);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {};\n      if (this.dataFormat != null) {\n        config['dataFormat'] = this.dataFormat;\n      }\n      var baseConfig = _get(_getPrototypeOf(Flatten.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Flatten;\n}(Layer);\n/** @nocollapse */\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport var Activation = /*#__PURE__*/function (_Layer4) {\n  _inherits(Activation, _Layer4);\n  var _super5 = _createSuper(Activation);\n  function Activation(args) {\n    var _this8;\n    _classCallCheck(this, Activation);\n    _this8 = _super5.call(this, args);\n    _this8.supportsMasking = true;\n    _this8.activation = getActivation(args.activation);\n    return _this8;\n  }\n  _createClass(Activation, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this9 = this;\n      return tidy(function () {\n        _this9.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        return _this9.activation.apply(input);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        activation: serializeActivation(this.activation)\n      };\n      var baseConfig = _get(_getPrototypeOf(Activation.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Activation;\n}(Layer);\n/** @nocollapse */\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport var RepeatVector = /*#__PURE__*/function (_Layer5) {\n  _inherits(RepeatVector, _Layer5);\n  var _super6 = _createSuper(RepeatVector);\n  function RepeatVector(args) {\n    var _this10;\n    _classCallCheck(this, RepeatVector);\n    _this10 = _super6.call(this, args);\n    _this10.n = args.n;\n    _this10.inputSpec = [{\n      ndim: 2\n    }];\n    return _this10;\n  }\n  _createClass(RepeatVector, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      return [inputShape[0], this.n, inputShape[1]];\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this11 = this;\n      return tidy(function () {\n        inputs = getExactlyOneTensor(inputs);\n        return K.repeat(inputs, _this11.n);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        n: this.n\n      };\n      var baseConfig = _get(_getPrototypeOf(RepeatVector.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return RepeatVector;\n}(Layer);\n/** @nocollapse */\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport var Reshape = /*#__PURE__*/function (_Layer6) {\n  _inherits(Reshape, _Layer6);\n  var _super7 = _createSuper(Reshape);\n  function Reshape(args) {\n    var _this12;\n    _classCallCheck(this, Reshape);\n    _this12 = _super7.call(this, args);\n    _this12.targetShape = args.targetShape;\n    // Make sure that all unknown dimensions are represented as `null`.\n    for (var i = 0; i < _this12.targetShape.length; ++i) {\n      if (_this12.isUnknown(_this12.targetShape[i])) {\n        _this12.targetShape[i] = null;\n      }\n    }\n    return _this12;\n  }\n  _createClass(Reshape, [{\n    key: \"isUnknown\",\n    value: function isUnknown(dim) {\n      return dim < 0 || dim == null;\n    }\n    /**\n     * Finds and replaces a missing dimension in output shape.\n     *\n     * This is a near direct port of the internal Numpy function\n     * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n     *\n     * @param inputShape: Original shape of array begin reshape.\n     * @param outputShape: Target shape of the array, with at most a single\n     * `null` or negative number, which indicates an underdetermined dimension\n     * that should be derived from `inputShape` and the known dimensions of\n     *   `outputShape`.\n     * @returns: The output shape with `null` replaced with its computed value.\n     * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n     */\n  }, {\n    key: \"fixUnknownDimension\",\n    value: function fixUnknownDimension(inputShape, outputShape) {\n      var errorMsg = 'Total size of new array must be unchanged.';\n      var finalShape = outputShape.slice();\n      var known = 1;\n      var unknown = null;\n      for (var i = 0; i < finalShape.length; ++i) {\n        var dim = finalShape[i];\n        if (this.isUnknown(dim)) {\n          if (unknown === null) {\n            unknown = i;\n          } else {\n            throw new ValueError('Can only specifiy one unknown dimension.');\n          }\n        } else {\n          known *= dim;\n        }\n      }\n      var originalSize = arrayProd(inputShape);\n      if (unknown !== null) {\n        if (known === 0 || originalSize % known !== 0) {\n          throw new ValueError(errorMsg);\n        }\n        finalShape[unknown] = originalSize / known;\n      } else if (originalSize !== known) {\n        throw new ValueError(errorMsg);\n      }\n      return finalShape;\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      var anyUnknownDims = false;\n      for (var i = 0; i < inputShape.length; ++i) {\n        if (this.isUnknown(inputShape[i])) {\n          anyUnknownDims = true;\n          break;\n        }\n      }\n      if (anyUnknownDims) {\n        return inputShape.slice(0, 1).concat(this.targetShape);\n      } else {\n        return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      }\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this13 = this;\n      return tidy(function () {\n        _this13.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        var inputShape = input.shape;\n        var outputShape = inputShape.slice(0, 1).concat(_this13.fixUnknownDimension(inputShape.slice(1), _this13.targetShape));\n        return reshape(input, outputShape);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        targetShape: this.targetShape\n      };\n      var baseConfig = _get(_getPrototypeOf(Reshape.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Reshape;\n}(Layer);\n/** @nocollapse */\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport var Permute = /*#__PURE__*/function (_Layer7) {\n  _inherits(Permute, _Layer7);\n  var _super8 = _createSuper(Permute);\n  function Permute(args) {\n    var _this14;\n    _classCallCheck(this, Permute);\n    _this14 = _super8.call(this, args);\n    if (args.dims == null) {\n      throw new Error('Required configuration field `dims` is missing during Permute ' + 'constructor call.');\n    }\n    if (!Array.isArray(args.dims)) {\n      throw new Error('Permute constructor requires `dims` to be an Array, but received ' + \"\".concat(args.dims, \" instead.\"));\n    }\n    // Check the validity of the permutation indices.\n    var expectedSortedIndices = range(1, args.dims.length + 1);\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) + ' `dims` must contain consecutive integers starting from 1.');\n    }\n    _this14.dims = args.dims;\n    _this14.dimsIncludingBatch = [0].concat(_this14.dims);\n    _this14.inputSpec = [new InputSpec({\n      ndim: _this14.dims.length + 1\n    })];\n    return _this14;\n  }\n  _createClass(Permute, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var outputShape = inputShape.slice();\n      this.dims.forEach(function (dim, i) {\n        outputShape[i + 1] = inputShape[dim];\n      });\n      return outputShape;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        dims: this.dims\n      };\n      var baseConfig = _get(_getPrototypeOf(Permute.prototype), \"getConfig\", this).call(this);\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n  return Permute;\n}(Layer);\n/** @nocollapse */\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport var Masking = /*#__PURE__*/function (_Layer8) {\n  _inherits(Masking, _Layer8);\n  var _super9 = _createSuper(Masking);\n  function Masking(args) {\n    var _this15;\n    _classCallCheck(this, Masking);\n    _this15 = _super9.call(this, args == null ? {} : args);\n    _this15.supportsMasking = true;\n    if (args != null) {\n      _this15.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      _this15.maskValue = 0;\n    }\n    return _this15;\n  }\n  _createClass(Masking, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      return inputShape;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(Masking.prototype), \"getConfig\", this).call(this);\n      var config = {\n        maskValue: this.maskValue\n      };\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }, {\n    key: \"computeMask\",\n    value: function computeMask(inputs, mask) {\n      var input = getExactlyOneTensor(inputs);\n      var axis = -1;\n      return any(notEqual(input, this.maskValue), axis);\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this16 = this;\n      return tidy(function () {\n        _this16.invokeCallHook(inputs, kwargs);\n        var input = getExactlyOneTensor(inputs);\n        var axis = -1;\n        var keepDims = true;\n        var booleanMask = any(notEqual(input, _this16.maskValue), axis, keepDims);\n        var output = mul(input, cast(booleanMask, input.dtype));\n        return output;\n      });\n    }\n  }]);\n  return Masking;\n}(Layer);\n/** @nocollapse */\nMasking.className = 'Masking';\nserialization.registerClass(Masking);","map":{"version":3,"mappings":";;;;;;;;AAAA;;;;;;;;;AAUA;;;AAIA,SAAQA,GAAG,EAAEC,IAAI,EAAEC,GAAG,EAAEC,QAAQ,EAAEC,OAAO,EAAEC,aAAa,EAAUC,IAAI,EAAEC,SAAS,EAAEC,IAAI,QAAO,uBAAuB;AAErH,SAAoCC,aAAa,EAAEC,mBAAmB,QAAO,gBAAgB;AAC7F,OAAO,KAAKC,CAAC,MAAM,yBAAyB;AAC5C,SAA0CC,aAAa,EAAEC,mBAAmB,QAAO,gBAAgB;AACnG,SAAuBC,SAAS,EAAEC,KAAK,QAAkB,oBAAoB;AAC7E,SAAQC,UAAU,QAAO,WAAW;AACpC,SAAQC,cAAc,EAAsCC,oBAAoB,QAAO,iBAAiB;AAIxG,SAAQC,cAAc,EAAsCC,oBAAoB,QAAO,iBAAiB;AAExG,SAAQC,qBAAqB,EAAEC,0BAA0B,QAAO,wBAAwB;AACxF,SAAQC,SAAS,EAAEC,KAAK,QAAO,qBAAqB;AACpD,SAAQC,kBAAkB,EAAEC,mBAAmB,QAAO,sBAAsB;AAqB5E,WAAaC,OAAQ;EAAA;EAAA;EAOnB,iBAAYC,IAAsB;IAAA;IAAA;IAChC,0BAAMA,IAAI;IACV,MAAKC,IAAI,GAAGC,IAAI,CAACC,GAAG,CAACD,IAAI,CAACE,GAAG,CAACJ,IAAI,CAACC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;IAC/C;IACA,MAAKI,UAAU,GAAGL,IAAI,CAACK,UAAU;IACjC,MAAKC,IAAI,GAAGN,IAAI,CAACM,IAAI;IACrB,MAAKC,eAAe,GAAG,IAAI;IAAC;EAC9B;EAAC;IAAA;IAAA,OAES,uBAAcC,KAAa;MACnC,IAAI,IAAI,CAACH,UAAU,IAAI,IAAI,EAAE;QAC3B,OAAO,IAAI,CAACA,UAAU;;MAExB,IAAMI,UAAU,GAAGD,KAAK,CAACE,KAAK;MAC9B,IAAML,UAAU,GAAU,EAAE;MAC5B,KAAK,IAAIM,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACN,UAAU,CAACO,MAAM,EAAE,EAAED,CAAC,EAAE;QAC/CN,UAAU,CAACQ,IAAI,CACX,IAAI,CAACR,UAAU,CAACM,CAAC,CAAC,IAAI,IAAI,GAAGF,UAAU,CAACE,CAAC,CAAC,GAAG,IAAI,CAACN,UAAU,CAACM,CAAC,CAAC,CAAC;;MAEtE,OAAON,UAAU;IACnB;EAAC;IAAA;IAAA,OAEQ,cAAKS,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAOrC,IAAI,CAAC,YAAK;QACf,MAAI,CAACsC,cAAc,CAACF,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGV,mBAAmB,CAACgB,MAAM,CAAC;QACzC,IAAI,CAAC,GAAG,MAAI,CAACb,IAAI,IAAI,MAAI,CAACA,IAAI,GAAG,CAAC,EAAE;UAClC,IAAMgB,QAAQ,GACVF,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,GAAG,KAAK,GAAGA,MAAM,CAAC,UAAU,CAAC;UAC3D,IAAMV,UAAU,GAAG,MAAI,CAACa,aAAa,CAACV,KAAK,CAAC;UAC5C,IAAMW,MAAM,GAAGpC,CAAC,CAACqC,YAAY,CACzB;YAAA,OAAMrC,CAAC,CAACsC,OAAO,CAACb,KAAK,EAAE,MAAI,CAACP,IAAI,EAAEI,UAAU,EAAE,MAAI,CAACC,IAAI,CAAC;UAAA,GACxD;YAAA,OAAME,KAAK;UAAA,GAAES,QAAQ,CAAC;UAC1B,OAAOE,MAAM;;QAEf,OAAOL,MAAM;MACf,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAMQ,MAAM,GAAG;QACbrB,IAAI,EAAE,IAAI,CAACA,IAAI;QACfI,UAAU,EAAE,IAAI,CAACA,UAAU;QAC3BC,IAAI,EAAE,IAAI,CAACA;OACZ;MACD,IAAMiB,UAAU,yEAAoB;MACpCC,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;IAAA;IAAA,OAEQ,mBAAO;MACd;IACF;EAAC;EAAA;AAAA,EA3D0BnC,KAAK;AAChC;AACOY,iBAAS,GAAG,SAAS;AA2D9BtB,aAAa,CAACiD,aAAa,CAAC3B,OAAO,CAAC;AA4DpC,WAAa4B,gBAAiB;EAAA;EAAA;EAI5B,0BAAY3B,IAAiC;IAAA;IAAA;IAC3C,4BAAMA,IAAI;IACV,OAAK4B,SAAS,GAAG,CAAC;MAACC,IAAI,EAAE;IAAC,CAAC,CAAC;IAAC;EAC/B;EAAC;IAAA;IAAA,OAEkB,uBAAcrB,KAAa;MAC5C,IAAMC,UAAU,GAAGD,KAAK,CAACE,KAAK;MAC9B,OAAO,CAACD,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,EAAEA,UAAU,CAAC,CAAC,CAAC,CAAC;IAC1C;EAAC;EAAA;AAAA,EAZmCV,OAAO;AAC3C;AACgB4B,0BAAS,GAAG,kBAAkB;AAYhDlD,aAAa,CAACiD,aAAa,CAACC,gBAAgB,CAAC;AAE7C,WAAaG,KAAM;EAAA;EAAA;EAmBjB,eAAY9B,IAAoB;IAAA;IAAA;IAC9B,4BAAMA,IAAI;IAhBZ;IACQ,iBAAU,GAAiB,IAAI;IAC/B,cAAO,GAAG,IAAI;IAGd,aAAM,GAAkB,IAAI;IAC5B,WAAI,GAAkB,IAAI;IAEzB,iCAA0B,GAA0B,cAAc;IAClE,+BAAwB,GAA0B,OAAO;IAQhE,IAAIA,IAAI,CAAC+B,eAAe,IAAI,IAAI,IAAI/B,IAAI,CAACS,UAAU,IAAI,IAAI,IACvDT,IAAI,CAACgC,QAAQ,IAAI,IAAI,EAAE;MACzB;MACA;MACA,IAAIC,SAAS,GAAW,IAAI;MAC5B,IAAIjC,IAAI,CAACiC,SAAS,IAAI,IAAI,EAAE;QAC1BA,SAAS,GAAGjC,IAAI,CAACiC,SAAS;;MAE5B,OAAKF,eAAe,GAAG,CAACE,SAAS,EAAEjC,IAAI,CAACgC,QAAQ,CAAC;;IAGnD,OAAKE,KAAK,GAAGlC,IAAI,CAACkC,KAAK;IACvBzC,qBAAqB,CAAC,OAAKyC,KAAK,EAAE,OAAO,CAAC;IAC1C,OAAKC,UAAU,GAAGtD,aAAa,CAACmB,IAAI,CAACmC,UAAU,CAAC;IAChD,IAAInC,IAAI,CAACoC,OAAO,IAAI,IAAI,EAAE;MACxB,OAAKA,OAAO,GAAGpC,IAAI,CAACoC,OAAO;;IAE7B,OAAKC,iBAAiB,GAAGhD,cAAc,CACnCW,IAAI,CAACqC,iBAAiB,IAAI,OAAKC,0BAA0B,CAAC;IAC9D,OAAKC,eAAe,GAChBlD,cAAc,CAACW,IAAI,CAACuC,eAAe,IAAI,OAAKC,wBAAwB,CAAC;IACzE,OAAKC,gBAAgB,GAAGzD,aAAa,CAACgB,IAAI,CAACyC,gBAAgB,CAAC;IAC5D,OAAKC,cAAc,GAAG1D,aAAa,CAACgB,IAAI,CAAC0C,cAAc,CAAC;IACxD,OAAKC,iBAAiB,GAAGpD,cAAc,CAACS,IAAI,CAAC2C,iBAAiB,CAAC;IAC/D,OAAKC,eAAe,GAAGrD,cAAc,CAACS,IAAI,CAAC4C,eAAe,CAAC;IAC3D,OAAKC,mBAAmB,GAAGtD,cAAc,CAACS,IAAI,CAAC6C,mBAAmB,CAAC;IACnE,OAAKtC,eAAe,GAAG,IAAI;IAE3B,OAAKqB,SAAS,GAAG,CAAC;MAACkB,OAAO,EAAE;IAAC,CAAC,CAAC;IAAC;EAClC;EAAC;IAAA;IAAA,OAEe,eAAMrC,UAAyB;MAC7CA,UAAU,GAAGZ,kBAAkB,CAACY,UAAU,CAAC;MAC3C,IAAMsC,YAAY,GAAGtC,UAAU,CAACA,UAAU,CAACG,MAAM,GAAG,CAAC,CAAC;MACtD,IAAI,IAAI,CAACoC,MAAM,IAAI,IAAI,EAAE;QACvB,IAAI,CAACA,MAAM,GAAG,IAAI,CAACC,SAAS,CACxB,QAAQ,EAAE,CAACF,YAAY,EAAE,IAAI,CAACb,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAACG,iBAAiB,EAClE,IAAI,CAACM,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAACF,gBAAgB,CAAC;QACxD,IAAI,IAAI,CAACL,OAAO,EAAE;UAChB,IAAI,CAACc,IAAI,GAAG,IAAI,CAACD,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAACf,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAACK,eAAe,EAChD,IAAI,CAACK,eAAe,EAAE,IAAI,EAAE,IAAI,CAACF,cAAc,CAAC;;;MAIxD,IAAI,CAACd,SAAS,GAAG,CAAC;QAACkB,OAAO,EAAE,CAAC;QAAEK,IAAI,sBAAI,CAAC,CAAC,EAAGJ,YAAY;MAAC,CAAC,CAAC;MAC3D,IAAI,CAACK,KAAK,GAAG,IAAI;IACnB;EAAC;IAAA;IAAA,OAEQ,4BAAmB3C,UAAyB;MACnDA,UAAU,GAAGZ,kBAAkB,CAACY,UAAU,CAAC;MAC3C,IAAM4C,WAAW,GAAG5C,UAAU,CAAC6C,KAAK,EAAE;MACtCD,WAAW,CAACA,WAAW,CAACzC,MAAM,GAAG,CAAC,CAAC,GAAG,IAAI,CAACsB,KAAK;MAChD,OAAOmB,WAAW;IACpB;EAAC;IAAA;IAAA,OAEQ,cAAKvC,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAOrC,IAAI,CAAC,YAAK;QACf,MAAI,CAACsC,cAAc,CAACF,MAAM,EAAEC,MAAM,CAAC;QACnC;QACA,IAAMP,KAAK,GAAGV,mBAAmB,CAACgB,MAAM,CAAC;QACzC,IAAMyC,mBAAmB,GACrB7D,0BAA0B,CAAC,MAAI,CAACyC,UAAU,CAACqB,YAAY,EAAE,CAAC;QAC9D,IAAIrC,MAAc;QAElB,IAAIoC,mBAAmB,IAAI,IAAI,EAAE;UAC/BpC,MAAM,GAAGpC,CAAC,CAAC0E,GAAG,CACVjD,KAAK,EAAE,MAAI,CAACwC,MAAM,CAACU,IAAI,EAAE,EAAEH,mBAAmB,EAC9C,MAAI,CAACL,IAAI,GAAG,MAAI,CAACA,IAAI,CAACQ,IAAI,EAAE,GAAG,IAAI,CAAC;SACzC,MAAM;UACLvC,MAAM,GAAGpC,CAAC,CAAC0E,GAAG,CAACjD,KAAK,EAAE,MAAI,CAACwC,MAAM,CAACU,IAAI,EAAE,CAAC;UACzC,IAAI,MAAI,CAACR,IAAI,IAAI,IAAI,EAAE;YACrB/B,MAAM,GAAGpC,CAAC,CAAC4E,OAAO,CAACxC,MAAM,EAAE,MAAI,CAAC+B,IAAI,CAACQ,IAAI,EAAE,CAAC;;UAE9C,IAAI,MAAI,CAACvB,UAAU,IAAI,IAAI,EAAE;YAC3BhB,MAAM,GAAG,MAAI,CAACgB,UAAU,CAACyB,KAAK,CAACzC,MAAM,CAAC;;;QAI1C,OAAOA,MAAM;MACf,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAMG,MAAM,GAA6B;QACvCY,KAAK,EAAE,IAAI,CAACA,KAAK;QACjBC,UAAU,EAAErD,mBAAmB,CAAC,IAAI,CAACqD,UAAU,CAAC;QAChDC,OAAO,EAAE,IAAI,CAACA,OAAO;QACrBC,iBAAiB,EAAE/C,oBAAoB,CAAC,IAAI,CAAC+C,iBAAiB,CAAC;QAC/DE,eAAe,EAAEjD,oBAAoB,CAAC,IAAI,CAACiD,eAAe,CAAC;QAC3DI,iBAAiB,EAAEnD,oBAAoB,CAAC,IAAI,CAACmD,iBAAiB,CAAC;QAC/DC,eAAe,EAAEpD,oBAAoB,CAAC,IAAI,CAACoD,eAAe,CAAC;QAC3DC,mBAAmB,EAAErD,oBAAoB,CAAC,IAAI,CAACqD,mBAAmB,CAAC;QACnEJ,gBAAgB,EAAExD,mBAAmB,CAAC,IAAI,CAACwD,gBAAgB,CAAC;QAC5DC,cAAc,EAAEzD,mBAAmB,CAAC,IAAI,CAACyD,cAAc;OACxD;MACD,IAAMnB,UAAU,uEAAoB;MACpCC,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA;AAAA,EAxHwBnC,KAAK;AAC9B;AACO2C,eAAS,GAAG,OAAO;AAwH5BrD,aAAa,CAACiD,aAAa,CAACI,KAAK,CAAC;AAOlC,WAAa+B,OAAQ;EAAA;EAAA;EAKnB,iBAAY7D,IAAuB;IAAA;IAAA;IACjCA,IAAI,GAAGA,IAAI,IAAI,EAAE;IACjB,4BAAMA,IAAI;IACV,OAAK4B,SAAS,GAAG,CAAC;MAACkB,OAAO,EAAE;IAAC,CAAC,CAAC;IAC/B,OAAKgB,UAAU,GAAG9D,IAAI,CAAC8D,UAAU;IAAC;EACpC;EAAC;IAAA;IAAA,OAEQ,4BAAmBrD,UAAyB;MACnDA,UAAU,GAAGZ,kBAAkB,CAACY,UAAU,CAAC;MAAC,2CAC1BA,UAAU,CAAC6C,KAAK,CAAC,CAAC,CAAC;QAAA;MAAA;QAArC,oDAAuC;UAAA,IAA5BS,GAAG;UACZ,IAAIA,GAAG,IAAI,IAAI,EAAE;YACf,MAAM,IAAI3E,UAAU,CAChB,+EACQqB,UAAU,CAAC6C,KAAK,CAAC,CAAC,CAAC,qCAAkC,oEACA,yBACvC,CAAC;;;MAE9B;QAAA;MAAA;QAAA;MAAA;MACD,OAAO,CAAC7C,UAAU,CAAC,CAAC,CAAC,EAAEd,SAAS,CAACc,UAAU,EAAE,CAAC,CAAC,CAAC;IAClD;EAAC;IAAA;IAAA,OAEQ,cAAKK,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAOrC,IAAI,CAAC,YAAK;QACf,MAAI,CAACsC,cAAc,CAACF,MAAM,EAAEC,MAAM,CAAC;QAEnC,IAAIP,KAAK,GAAGV,mBAAmB,CAACgB,MAAM,CAAC;QACvC,IAAI,MAAI,CAACgD,UAAU,KAAK,eAAe,IAAItD,KAAK,CAACwD,IAAI,GAAG,CAAC,EAAE;UACzD,IAAMC,WAAW,GAAa,CAAC,CAAC,CAAC;UACjC,KAAK,IAAItD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,KAAK,CAACwD,IAAI,EAAE,EAAErD,CAAC,EAAE;YACnCsD,WAAW,CAACpD,IAAI,CAACF,CAAC,CAAC;;UAErBsD,WAAW,CAACpD,IAAI,CAAC,CAAC,CAAC;UACnBL,KAAK,GAAG7B,SAAS,CAAC6B,KAAK,EAAEyD,WAAW,CAAC;;QAGvC,OAAOlF,CAAC,CAACmF,YAAY,CAAC1D,KAAK,CAAC;MAC9B,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAMc,MAAM,GAA6B,EAAE;MAC3C,IAAI,IAAI,CAACwC,UAAU,IAAI,IAAI,EAAE;QAC3BxC,MAAM,CAAC,YAAY,CAAC,GAAG,IAAI,CAACwC,UAAU;;MAExC,IAAMvC,UAAU,yEAAoB;MACpCC,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA;AAAA,EApD0BnC,KAAK;AAGhC;AACO0E,iBAAS,GAAG,SAAS;AAkD9BpF,aAAa,CAACiD,aAAa,CAACmC,OAAO,CAAC;AASpC,WAAaM,UAAW;EAAA;EAAA;EAKtB,oBAAYnE,IAAyB;IAAA;IAAA;IACnC,4BAAMA,IAAI;IACV,OAAKO,eAAe,GAAG,IAAI;IAC3B,OAAK4B,UAAU,GAAGtD,aAAa,CAACmB,IAAI,CAACmC,UAAU,CAAC;IAAC;EACnD;EAAC;IAAA;IAAA,OAEQ,cAAKrB,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAOrC,IAAI,CAAC,YAAK;QACf,MAAI,CAACsC,cAAc,CAACF,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGV,mBAAmB,CAACgB,MAAM,CAAC;QACzC,OAAO,MAAI,CAACqB,UAAU,CAACyB,KAAK,CAACpD,KAAK,CAAC;MACrC,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAMc,MAAM,GAAG;QAACa,UAAU,EAAErD,mBAAmB,CAAC,IAAI,CAACqD,UAAU;MAAC,CAAC;MACjE,IAAMZ,UAAU,4EAAoB;MACpCC,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA;AAAA,EAxB6BnC,KAAK;AACnC;AACOgF,oBAAS,GAAG,YAAY;AAwBjC1F,aAAa,CAACiD,aAAa,CAACyC,UAAU,CAAC;AAcvC,WAAaC,YAAa;EAAA;EAAA;EAKxB,sBAAYpE,IAA2B;IAAA;IAAA;IACrC,6BAAMA,IAAI;IACV,QAAKqE,CAAC,GAAGrE,IAAI,CAACqE,CAAC;IACf,QAAKzC,SAAS,GAAG,CAAC;MAACC,IAAI,EAAE;IAAC,CAAC,CAAC;IAAC;EAC/B;EAAC;IAAA;IAAA,OAEQ,4BAAmBpB,UAAiB;MAC3C,OAAO,CAACA,UAAU,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC4D,CAAC,EAAE5D,UAAU,CAAC,CAAC,CAAC,CAAC;IAC/C;EAAC;IAAA;IAAA,OAEQ,cAAKK,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAOrC,IAAI,CAAC,YAAK;QACfoC,MAAM,GAAGhB,mBAAmB,CAACgB,MAAM,CAAC;QACpC,OAAO/B,CAAC,CAACuF,MAAM,CAACxD,MAAM,EAAE,OAAI,CAACuD,CAAC,CAAC;MACjC,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAM/C,MAAM,GAAG;QACb+C,CAAC,EAAE,IAAI,CAACA;OACT;MACD,IAAM9C,UAAU,8EAAoB;MACpCC,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA;AAAA,EA7B+BnC,KAAK;AACrC;AACOiF,sBAAS,GAAG,cAAc;AA6BnC3F,aAAa,CAACiD,aAAa,CAAC0C,YAAY,CAAC;AAEzC,WAAaG,OAAQ;EAAA;EAAA;EAKnB,iBAAYvE,IAAsB;IAAA;IAAA;IAChC,6BAAMA,IAAI;IACV,QAAKwE,WAAW,GAAGxE,IAAI,CAACwE,WAAW;IAEnC;IACA,KAAK,IAAI7D,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,QAAK6D,WAAW,CAAC5D,MAAM,EAAE,EAAED,CAAC,EAAE;MAChD,IAAI,QAAK8D,SAAS,CAAC,QAAKD,WAAW,CAAC7D,CAAC,CAAC,CAAC,EAAE;QACvC,QAAK6D,WAAW,CAAC7D,CAAC,CAAC,GAAG,IAAI;;;IAE7B;EACH;EAAC;IAAA;IAAA,OAEO,mBAAUoD,GAAW;MAC3B,OAAOA,GAAG,GAAG,CAAC,IAAIA,GAAG,IAAI,IAAI;IAC/B;IAEA;;;;;;;;;;;;;;EAAA;IAAA;IAAA,OAcQ,6BAAoBtD,UAAiB,EAAE4C,WAAkB;MAC/D,IAAMqB,QAAQ,GAAG,4CAA4C;MAC7D,IAAMC,UAAU,GAAGtB,WAAW,CAACC,KAAK,EAAE;MACtC,IAAIsB,KAAK,GAAG,CAAC;MACb,IAAIC,OAAO,GAAG,IAAI;MAClB,KAAK,IAAIlE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgE,UAAU,CAAC/D,MAAM,EAAE,EAAED,CAAC,EAAE;QAC1C,IAAMoD,GAAG,GAAGY,UAAU,CAAChE,CAAC,CAAC;QACzB,IAAI,IAAI,CAAC8D,SAAS,CAACV,GAAG,CAAC,EAAE;UACvB,IAAIc,OAAO,KAAK,IAAI,EAAE;YACpBA,OAAO,GAAGlE,CAAC;WACZ,MAAM;YACL,MAAM,IAAIvB,UAAU,CAAC,0CAA0C,CAAC;;SAEnE,MAAM;UACLwF,KAAK,IAAIb,GAAG;;;MAIhB,IAAMe,YAAY,GAAGnF,SAAS,CAACc,UAAU,CAAC;MAC1C,IAAIoE,OAAO,KAAK,IAAI,EAAE;QACpB,IAAID,KAAK,KAAK,CAAC,IAAIE,YAAY,GAAGF,KAAK,KAAK,CAAC,EAAE;UAC7C,MAAM,IAAIxF,UAAU,CAACsF,QAAQ,CAAC;;QAEhCC,UAAU,CAACE,OAAO,CAAC,GAAGC,YAAY,GAAGF,KAAK;OAC3C,MAAM,IAAIE,YAAY,KAAKF,KAAK,EAAE;QACjC,MAAM,IAAIxF,UAAU,CAACsF,QAAQ,CAAC;;MAGhC,OAAOC,UAAU;IACnB;EAAC;IAAA;IAAA,OAEQ,4BAAmBlE,UAAiB;MAC3C,IAAIsE,cAAc,GAAG,KAAK;MAC1B,KAAK,IAAIpE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,UAAU,CAACG,MAAM,EAAE,EAAED,CAAC,EAAE;QAC1C,IAAI,IAAI,CAAC8D,SAAS,CAAChE,UAAU,CAACE,CAAC,CAAC,CAAC,EAAE;UACjCoE,cAAc,GAAG,IAAI;UACrB;;;MAIJ,IAAIA,cAAc,EAAE;QAClB,OAAOtE,UAAU,CAAC6C,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC0B,MAAM,CAAC,IAAI,CAACR,WAAW,CAAC;OACvD,MAAM;QACL,OAAO/D,UAAU,CAAC6C,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC0B,MAAM,CAChC,IAAI,CAACC,mBAAmB,CAACxE,UAAU,CAAC6C,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,CAACkB,WAAW,CAAC,CAAC;;IAExE;EAAC;IAAA;IAAA,OAEQ,cAAK1D,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAOrC,IAAI,CAAC,YAAK;QACf,OAAI,CAACsC,cAAc,CAACF,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGV,mBAAmB,CAACgB,MAAM,CAAC;QACzC,IAAML,UAAU,GAAGD,KAAK,CAACE,KAAK;QAC9B,IAAM2C,WAAW,GAAG5C,UAAU,CAAC6C,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC0B,MAAM,CAC7C,OAAI,CAACC,mBAAmB,CAACxE,UAAU,CAAC6C,KAAK,CAAC,CAAC,CAAC,EAAE,OAAI,CAACkB,WAAW,CAAC,CAAC;QACpE,OAAOhG,OAAO,CAACgC,KAAK,EAAE6C,WAAW,CAAC;MACpC,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAM/B,MAAM,GAAG;QACbkD,WAAW,EAAE,IAAI,CAACA;OACnB;MACD,IAAMjD,UAAU,yEAAoB;MACpCC,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA;AAAA,EArG0BnC,KAAK;AAChC;AACOoF,iBAAS,GAAG,SAAS;AAqG9B9F,aAAa,CAACiD,aAAa,CAAC6C,OAAO,CAAC;AAYpC,WAAaW,OAAQ;EAAA;EAAA;EAMnB,iBAAYlF,IAAsB;IAAA;IAAA;IAChC,6BAAMA,IAAI;IACV,IAAIA,IAAI,CAACmF,IAAI,IAAI,IAAI,EAAE;MACrB,MAAM,IAAIC,KAAK,CACX,gEAAgE,GAChE,mBAAmB,CAAC;;IAE1B,IAAI,CAACC,KAAK,CAACC,OAAO,CAACtF,IAAI,CAACmF,IAAI,CAAC,EAAE;MAC7B,MAAM,IAAIC,KAAK,CACX,mEAAmE,aAChEpF,IAAI,CAACmF,IAAI,cAAW,CAAC;;IAG9B;IACA,IAAMI,qBAAqB,GAAG3F,KAAK,CAAC,CAAC,EAAEI,IAAI,CAACmF,IAAI,CAACvE,MAAM,GAAG,CAAC,CAAC;IAC5D,IAAI,CAAChC,IAAI,CAAC4G,WAAW,CAACxF,IAAI,CAACmF,IAAI,CAAC7B,KAAK,EAAE,CAACmC,IAAI,EAAE,EAAEF,qBAAqB,CAAC,EAAE;MACtE,MAAM,IAAIH,KAAK,CACX,8BAA8B,GAAGM,IAAI,CAACC,SAAS,CAAC3F,IAAI,CAACmF,IAAI,CAAC,GAC1D,4DAA4D,CAAC;;IAGnE,QAAKA,IAAI,GAAGnF,IAAI,CAACmF,IAAI;IACrB,QAAKS,kBAAkB,GAAG,CAAC,CAAC,CAAC,CAACZ,MAAM,CAAC,QAAKG,IAAI,CAAC;IAC/C,QAAKvD,SAAS,GAAG,CAAC,IAAI1C,SAAS,CAAC;MAAC2C,IAAI,EAAE,QAAKsD,IAAI,CAACvE,MAAM,GAAG;IAAC,CAAC,CAAC,CAAC;IAAC;EACjE;EAAC;IAAA;IAAA,OAEQ,4BAAmBH,UAAyB;MACnDA,UAAU,GAAGZ,kBAAkB,CAACY,UAAU,CAAC;MAC3C,IAAM4C,WAAW,GAAG5C,UAAU,CAAC6C,KAAK,EAAE;MACtC,IAAI,CAAC6B,IAAI,CAACU,OAAO,CAAC,UAAC9B,GAAW,EAAEpD,CAAS,EAAI;QAC3C0C,WAAW,CAAC1C,CAAC,GAAG,CAAC,CAAC,GAAIF,UAAoB,CAACsD,GAAG,CAAC;MACjD,CAAC,CAAC;MACF,OAAOV,WAAW;IACpB;EAAC;IAAA;IAAA,OAEQ,cAAKvC,MAAuB,EAAEC,MAAc;MACnD,OAAOpC,SAAS,CAACmB,mBAAmB,CAACgB,MAAM,CAAC,EAAE,IAAI,CAAC8E,kBAAkB,CAAC;IACxE;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAMtE,MAAM,GAAG;QACb6D,IAAI,EAAE,IAAI,CAACA;OACZ;MACD,IAAM5D,UAAU,yEAAoB;MACpCC,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;EAAA;AAAA,EApD0BnC,KAAK;AAChC;AACO+F,iBAAS,GAAG,SAAS;AAoD9BzG,aAAa,CAACiD,aAAa,CAACwD,OAAO,CAAC;AASpC,WAAaY,OAAQ;EAAA;EAAA;EAKnB,iBAAY9F,IAAkB;IAAA;IAAA;IAC5B,6BAAMA,IAAI,IAAI,IAAI,GAAG,EAAE,GAAGA,IAAI;IAC9B,QAAKO,eAAe,GAAG,IAAI;IAC3B,IAAIP,IAAI,IAAI,IAAI,EAAE;MAChB,QAAK+F,SAAS,GAAG/F,IAAI,CAAC+F,SAAS,IAAI,IAAI,GAAG,CAAC,GAAG/F,IAAI,CAAC+F,SAAS;KAC7D,MAAM;MACL,QAAKA,SAAS,GAAG,CAAC;;IACnB;EACH;EAAC;IAAA;IAAA,OAEQ,4BAAmBtF,UAAyB;MACnD,OAAOA,UAAU;IACnB;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,IAAMc,UAAU,yEAAoB;MACpC,IAAMD,MAAM,GAAG;QAACyE,SAAS,EAAE,IAAI,CAACA;MAAS,CAAC;MAC1CvE,MAAM,CAACC,MAAM,CAACH,MAAM,EAAEC,UAAU,CAAC;MACjC,OAAOD,MAAM;IACf;EAAC;IAAA;IAAA,OAEQ,qBAAYR,MAAuB,EAAEkF,IAAsB;MAElE,IAAMxF,KAAK,GAAGV,mBAAmB,CAACgB,MAAM,CAAC;MACzC,IAAMmF,IAAI,GAAG,CAAC,CAAC;MACf,OAAO7H,GAAG,CAACG,QAAQ,CAACiC,KAAK,EAAE,IAAI,CAACuF,SAAS,CAAC,EAAEE,IAAI,CAAC;IACnD;EAAC;IAAA;IAAA,OAEQ,cAAKnF,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAOrC,IAAI,CAAC,YAAK;QACf,OAAI,CAACsC,cAAc,CAACF,MAAM,EAAEC,MAAM,CAAC;QACnC,IAAMP,KAAK,GAAGV,mBAAmB,CAACgB,MAAM,CAAC;QACzC,IAAMmF,IAAI,GAAG,CAAC,CAAC;QACf,IAAMC,QAAQ,GAAG,IAAI;QACrB,IAAMC,WAAW,GAAG/H,GAAG,CAACG,QAAQ,CAACiC,KAAK,EAAE,OAAI,CAACuF,SAAS,CAAC,EAAEE,IAAI,EAAEC,QAAQ,CAAC;QACxE,IAAM/E,MAAM,GAAG7C,GAAG,CAACkC,KAAK,EAAEnC,IAAI,CAAC8H,WAAW,EAAE3F,KAAK,CAAC4F,KAAK,CAAC,CAAC;QACzD,OAAOjF,MAAM;MACf,CAAC,CAAC;IACJ;EAAC;EAAA;AAAA,EA3C0BhC,KAAK;AAChC;AACO2G,iBAAS,GAAG,SAAS;AA2C9BrH,aAAa,CAACiD,aAAa,CAACoE,OAAO,CAAC","names":["any","cast","mul","notEqual","reshape","serialization","tidy","transpose","util","getActivation","serializeActivation","K","getConstraint","serializeConstraint","InputSpec","Layer","ValueError","getInitializer","serializeInitializer","getRegularizer","serializeRegularizer","assertPositiveInteger","mapActivationToFusedKernel","arrayProd","range","getExactlyOneShape","getExactlyOneTensor","Dropout","args","rate","Math","max","min","noiseShape","seed","supportsMasking","input","inputShape","shape","i","length","push","inputs","kwargs","invokeCallHook","training","getNoiseShape","output","inTrainPhase","dropout","config","baseConfig","Object","assign","registerClass","SpatialDropout1D","inputSpec","ndim","Dense","batchInputShape","inputDim","batchSize","units","activation","useBias","kernelInitializer","DEFAULT_KERNEL_INITIALIZER","biasInitializer","DEFAULT_BIAS_INITIALIZER","kernelConstraint","biasConstraint","kernelRegularizer","biasRegularizer","activityRegularizer","minNDim","inputLastDim","kernel","addWeight","bias","axes","built","outputShape","slice","fusedActivationName","getClassName","dot","read","biasAdd","apply","Flatten","dataFormat","dim","rank","permutation","batchFlatten","Activation","RepeatVector","n","repeat","Reshape","targetShape","isUnknown","errorMsg","finalShape","known","unknown","originalSize","anyUnknownDims","concat","fixUnknownDimension","Permute","dims","Error","Array","isArray","expectedSortedIndices","arraysEqual","sort","JSON","stringify","dimsIncludingBatch","forEach","Masking","maskValue","mask","axis","keepDims","booleanMask","dtype"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\Toxic-Word-Checker\\node_modules\\@tensorflow\\tfjs-layers\\src\\layers\\core.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\n\nimport {any, cast, mul, notEqual, reshape, serialization, Tensor, tidy, transpose, util} from '@tensorflow/tfjs-core';\n\nimport {Activation as ActivationFn, getActivation, serializeActivation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {DisposeResult, InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {ActivationIdentifier} from '../keras_format/activation_config';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {LayerConfig} from '../keras_format/topology_config';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {assertPositiveInteger, mapActivationToFusedKernel} from '../utils/generic_utils';\nimport {arrayProd, range} from '../utils/math_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface DropoutLayerArgs extends LayerArgs {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /**\n   * Integer array representing the shape of the binary dropout mask that will\n   * be multiplied with the input.\n   *\n   * For instance, if your inputs have shape `(batchSize, timesteps, features)`\n   * and you want the dropout mask to be the same for all timesteps, you can use\n   * `noise_shape=(batch_size, 1, features)`.\n   */\n  noiseShape?: number[];\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class Dropout extends Layer {\n  /** @nocollapse */\n  static className = 'Dropout';\n  private readonly rate: number;\n  private readonly noiseShape: number[];\n  private readonly seed: number;\n\n  constructor(args: DropoutLayerArgs) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0);\n    // So that the scalar doesn't get tidied up between executions.\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  protected getNoiseShape(input: Tensor): Shape {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n    const inputShape = input.shape;\n    const noiseShape: Shape = [];\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(\n          this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n    return noiseShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      if (0 < this.rate && this.rate < 1) {\n        const training =\n            kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(\n            () => K.dropout(input, this.rate, noiseShape, this.seed),\n            () => input, training);\n        return output;\n      }\n      return inputs;\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override dispose(): DisposeResult {\n    return super.dispose();\n  }\n}\nserialization.registerClass(Dropout);\n\nexport declare interface DenseLayerArgs extends LayerArgs {\n  /** Positive integer, dimensionality of the output space. */\n  units: number;\n  /**\n   * Activation function to use.\n   *\n   * If unspecified, no activation is applied.\n   */\n  activation?: ActivationIdentifier;\n  /** Whether to apply a bias. */\n  useBias?: boolean;\n  /**\n   * Initializer for the dense kernel weights matrix.\n   */\n  kernelInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Initializer for the bias vector.\n   */\n  biasInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * If specified, defines inputShape as `[inputDim]`.\n   */\n  inputDim?: number;\n\n  /**\n   * Constraint for the kernel weights.\n   */\n  kernelConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint for the bias vector.\n   */\n  biasConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Regularizer function applied to the dense kernel weights matrix.\n   */\n  kernelRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the bias vector.\n   */\n  biasRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport interface SpatialDropout1DLayerConfig extends LayerConfig {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class SpatialDropout1D extends Dropout {\n  /** @nocollapse */\n  static override className = 'SpatialDropout1D';\n\n  constructor(args: SpatialDropout1DLayerConfig) {\n    super(args);\n    this.inputSpec = [{ndim: 3}];\n  }\n\n  protected override getNoiseShape(input: Tensor): Shape {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n}\nserialization.registerClass(SpatialDropout1D);\n\nexport class Dense extends Layer {\n  /** @nocollapse */\n  static className = 'Dense';\n  private units: number;\n  // Default activation: Linear (none).\n  private activation: ActivationFn = null;\n  private useBias = true;\n  private kernelInitializer: Initializer;\n  private biasInitializer: Initializer;\n  private kernel: LayerVariable = null;\n  private bias: LayerVariable = null;\n\n  readonly DEFAULT_KERNEL_INITIALIZER: InitializerIdentifier = 'glorotNormal';\n  readonly DEFAULT_BIAS_INITIALIZER: InitializerIdentifier = 'zeros';\n  private readonly kernelConstraint?: Constraint;\n  private readonly biasConstraint?: Constraint;\n  private readonly kernelRegularizer?: Regularizer;\n  private readonly biasRegularizer?: Regularizer;\n\n  constructor(args: DenseLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null &&\n        args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n\n    this.inputSpec = [{minNDim: 2}];\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n    if (this.kernel == null) {\n      this.kernel = this.addWeight(\n          'kernel', [inputLastDim, this.units], null, this.kernelInitializer,\n          this.kernelRegularizer, true, this.kernelConstraint);\n      if (this.useBias) {\n        this.bias = this.addWeight(\n            'bias', [this.units], null, this.biasInitializer,\n            this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{minNDim: 2, axes: {[-1]: inputLastDim}}];\n    this.built = true;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Dense layer accepts only a single input.\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName =\n          mapActivationToFusedKernel(this.activation.getClassName());\n      let output: Tensor;\n\n      if (fusedActivationName != null) {\n        output = K.dot(\n            input, this.kernel.read(), fusedActivationName,\n            this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Dense);\n\nexport declare interface FlattenLayerArgs extends LayerArgs {\n  /** Image data format: channelsLast (default) or channelsFirst. */\n  dataFormat?: DataFormat;\n}\n\nexport class Flatten extends Layer {\n  private dataFormat: DataFormat;\n\n  /** @nocollapse */\n  static className = 'Flatten';\n  constructor(args?: FlattenLayerArgs) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{minNDim: 3}];\n    this.dataFormat = args.dataFormat;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(\n            `The shape of the input to \"Flatten\" is not fully defined ` +\n            `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n            `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n            `layer in your model.`);\n      }\n    }\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n\n      let input = getExactlyOneTensor(inputs);\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation: number[] = [0];\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n        permutation.push(1);\n        input = transpose(input, permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {};\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Flatten);\n\nexport declare interface ActivationLayerArgs extends LayerArgs {\n  /**\n   * Name of the activation function to use.\n   */\n  activation: ActivationIdentifier;\n}\n\nexport class Activation extends Layer {\n  /** @nocollapse */\n  static className = 'Activation';\n  activation: ActivationFn;\n\n  constructor(args: ActivationLayerArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {activation: serializeActivation(this.activation)};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Activation);\n\nexport declare interface ReshapeLayerArgs extends LayerArgs {\n  /** The target shape. Does not include the batch axis. */\n  targetShape: Shape;\n}\n\nexport declare interface RepeatVectorLayerArgs extends LayerArgs {\n  /**\n   * The integer number of times to repeat the input.\n   */\n  n: number;\n}\n\nexport class RepeatVector extends Layer {\n  /** @nocollapse */\n  static className = 'RepeatVector';\n  readonly n: number;\n\n  constructor(args: RepeatVectorLayerArgs) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{ndim: 2}];\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      n: this.n,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(RepeatVector);\n\nexport class Reshape extends Layer {\n  /** @nocollapse */\n  static className = 'Reshape';\n  private targetShape: Shape;\n\n  constructor(args: ReshapeLayerArgs) {\n    super(args);\n    this.targetShape = args.targetShape;\n\n    // Make sure that all unknown dimensions are represented as `null`.\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  private isUnknown(dim: number): boolean {\n    return dim < 0 || dim == null;\n  }\n\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n  private fixUnknownDimension(inputShape: Shape, outputShape: Shape): Shape {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape {\n    let anyUnknownDims = false;\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return reshape(input, outputShape);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      targetShape: this.targetShape,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Reshape);\n\nexport declare interface PermuteLayerArgs extends LayerArgs {\n  /**\n   * Array of integers. Permutation pattern. Does not include the\n   * sample (batch) dimension. Index starts at 1.\n   * For instance, `[2, 1]` permutes the first and second dimensions\n   * of the input.\n   */\n  dims: number[];\n}\n\nexport class Permute extends Layer {\n  /** @nocollapse */\n  static className = 'Permute';\n  readonly dims: number[];\n  private readonly dimsIncludingBatch: number[];\n\n  constructor(args: PermuteLayerArgs) {\n    super(args);\n    if (args.dims == null) {\n      throw new Error(\n          'Required configuration field `dims` is missing during Permute ' +\n          'constructor call.');\n    }\n    if (!Array.isArray(args.dims)) {\n      throw new Error(\n          'Permute constructor requires `dims` to be an Array, but received ' +\n          `${args.dims} instead.`);\n    }\n\n    // Check the validity of the permutation indices.\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error(\n          'Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n          ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({ndim: this.dims.length + 1})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim: number, i: number) => {\n      outputShape[i + 1] = (inputShape as Shape)[dim];\n    });\n    return outputShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      dims: this.dims,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Permute);\n\nexport declare interface MaskingArgs extends LayerArgs {\n  /**\n   * Masking Value. Defaults to `0.0`.\n   */\n  maskValue?: number;\n}\n\nexport class Masking extends Layer {\n  /** @nocollapse */\n  static className = 'Masking';\n  maskValue: number;\n\n  constructor(args?: MaskingArgs) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {maskValue: this.maskValue};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]):\n      Tensor {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = mul(input, cast(booleanMask, input.dtype));\n      return output;\n    });\n  }\n}\nserialization.registerClass(Masking);\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}