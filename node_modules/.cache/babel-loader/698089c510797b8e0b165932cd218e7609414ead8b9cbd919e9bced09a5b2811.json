{"ast":null,"code":"import _regeneratorRuntime from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { argMax, clone, dispose, mul, reshape, tensor1d, tidy } from '@tensorflow/tfjs-core';\nfunction standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {\n  var numOutputs = outputNames.length;\n  if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {\n    return outputNames.map(function (name) {\n      return null;\n    });\n  }\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [xWeight[outputNames[0]]];\n    } else {\n      return [xWeight];\n    }\n  }\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(\"Provided \".concat(weightType, \" is an array of \").concat(xWeight.length, \" \") + \"element(s), but the model has \".concat(numOutputs, \" outputs. \") + \"Make sure a set of weights is provided for each model output.\");\n    }\n    return xWeight;\n  } else if (typeof xWeight === 'object' && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === 'object') {\n    var output = [];\n    outputNames.forEach(function (outputName) {\n      if (outputName in xWeight) {\n        output.push(xWeight[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(\"The model has multiple (\".concat(numOutputs, \") outputs, \") + \"so \".concat(weightType, \" must be either an array with \") + \"\".concat(numOutputs, \" elements or an object with \").concat(outputNames, \" keys. \") + \"Provided \".concat(weightType, \" not understood: \").concat(JSON.stringify(xWeight)));\n  }\n}\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\nexport function standardizeClassWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'classWeight');\n}\nexport function standardizeSampleWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'sampleWeight');\n}\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\nexport function standardizeWeights(_x, _x2, _x3, _x4) {\n  return _standardizeWeights.apply(this, arguments);\n}\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\nfunction _standardizeWeights() {\n  _standardizeWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(y, sampleWeight, classWeight, sampleWeightMode) {\n    var yClasses, yClassIndices, classSampleWeight;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) switch (_context.prev = _context.next) {\n        case 0:\n          if (!(sampleWeight != null || sampleWeightMode != null)) {\n            _context.next = 2;\n            break;\n          }\n          throw new Error('Support sampleWeight is not implemented yet');\n        case 2:\n          if (!(classWeight != null)) {\n            _context.next = 15;\n            break;\n          }\n          // Apply class weights per sample.\n          yClasses = tidy(function () {\n            if (y.shape.length === 1) {\n              // Assume class indices.\n              return clone(y);\n            } else if (y.shape.length === 2) {\n              if (y.shape[1] > 1) {\n                // Assume one-hot encoding of classes.\n                var axis = 1;\n                return argMax(y, axis);\n              } else if (y.shape[1] === 1) {\n                // Class index.\n                return reshape(y, [y.shape[0]]);\n              } else {\n                throw new Error(\"Encountered unexpected last-dimension size (\".concat(y.shape[1], \") \") + \"during handling of class weights. The size is expected to be \" + \">= 1.\");\n              }\n            } else {\n              throw new Error(\"Unexpected rank of target (y) tensor (\".concat(y.rank, \") during \") + \"handling of class weights. The rank is expected to be 1 or 2.\");\n            }\n          });\n          _context.t0 = Array;\n          _context.next = 7;\n          return yClasses.data();\n        case 7:\n          _context.t1 = _context.sent;\n          yClassIndices = _context.t0.from.call(_context.t0, _context.t1);\n          dispose(yClasses);\n          classSampleWeight = [];\n          yClassIndices.forEach(function (classIndex) {\n            if (classWeight[classIndex] == null) {\n              throw new Error(\"classWeight must contain all classes in the training data. \" + \"The class \".concat(classIndex, \" exists in the data but not in \") + \"classWeight\");\n            } else {\n              classSampleWeight.push(classWeight[classIndex]);\n            }\n          });\n          return _context.abrupt(\"return\", tensor1d(classSampleWeight, 'float32'));\n        case 15:\n          return _context.abrupt(\"return\", null);\n        case 16:\n        case \"end\":\n          return _context.stop();\n      }\n    }, _callee);\n  }));\n  return _standardizeWeights.apply(this, arguments);\n}\nexport function computeWeightedLoss(losses, sampleWeights) {\n  return mul(losses, sampleWeights);\n}","map":{"version":3,"mappings":";;AAAA;;;;;;;;;AAUA,SAAQA,MAAM,EAAEC,KAAK,EAAEC,OAAO,EAAEC,GAAG,EAAEC,OAAO,EAAoBC,QAAQ,EAAEC,IAAI,QAAO,uBAAuB;AAuB5G,SAASC,+BAA+B,CACpCC,OAAiD,EAAEC,WAAqB,EACxEC,UAAwC;EAC1C,IAAMC,UAAU,GAAGF,WAAW,CAACG,MAAM;EACrC,IAAIJ,OAAO,IAAI,IAAI,IAAKK,KAAK,CAACC,OAAO,CAACN,OAAO,CAAC,IAAIA,OAAO,CAACI,MAAM,KAAK,CAAE,EAAE;IACvE,OAAOH,WAAW,CAACM,GAAG,CAAC,cAAI;MAAA,OAAI,IAAI;IAAA,EAAC;;EAEtC,IAAIJ,UAAU,KAAK,CAAC,EAAE;IACpB,IAAIE,KAAK,CAACC,OAAO,CAACN,OAAO,CAAC,IAAIA,OAAO,CAACI,MAAM,KAAK,CAAC,EAAE;MAClD,OAAOJ,OAAO;KACf,MAAM,IAAI,OAAOA,OAAO,KAAK,QAAQ,IAAIC,WAAW,CAAC,CAAC,CAAC,IAAID,OAAO,EAAE;MACnE,OAAO,CAAEA,OAA0B,CAACC,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC;KACrD,MAAM;MACL,OAAO,CAACD,OAAsB,CAAC;;;EAGnC,IAAIK,KAAK,CAACC,OAAO,CAACN,OAAO,CAAC,EAAE;IAC1B,IAAIA,OAAO,CAACI,MAAM,KAAKD,UAAU,EAAE;MACjC,MAAM,IAAIK,KAAK,CACX,mBAAYN,UAAU,6BAAmBF,OAAO,CAACI,MAAM,iDACtBD,UAAU,eAAY,kEACQ,CAAC;;IAEtE,OAAOH,OAAO;GACf,MAAM,IACH,OAAOA,OAAO,KAAK,QAAQ,IAAIS,MAAM,CAACC,IAAI,CAACV,OAAO,CAAC,CAACI,MAAM,GAAG,CAAC,IAC9D,OAAQJ,OAA0B,CAACS,MAAM,CAACC,IAAI,CAACV,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,KACvD,QAAQ,EAAE;IAChB,IAAMW,MAAM,GAAkB,EAAE;IAChCV,WAAW,CAACW,OAAO,CAAC,oBAAU,EAAG;MAC/B,IAAIC,UAAU,IAAIb,OAAO,EAAE;QACzBW,MAAM,CAACG,IAAI,CAAEd,OAA0B,CAACa,UAAU,CAAC,CAAC;OACrD,MAAM;QACLF,MAAM,CAACG,IAAI,CAAC,IAAI,CAAC;;IAErB,CAAC,CAAC;IACF,OAAOH,MAAM;GACd,MAAM;IACL,MAAM,IAAIH,KAAK,CACX,kCAA2BL,UAAU,gCAC/BD,UAAU,mCAAgC,aAC7CC,UAAU,yCAA+BF,WAAW,YAAS,sBACpDC,UAAU,8BAAoBa,IAAI,CAACC,SAAS,CAAChB,OAAO,CAAC,CAAE,CAAC;;AAE5E;AAEA;;;;;;;;;;;;;AAaA,OAAM,SAAUiB,uBAAuB,CACnCC,WAAqD,EACrDjB,WAAqB;EACvB,OAAOF,+BAA+B,CAClCmB,WAAW,EAAEjB,WAAW,EAAE,aAAa,CAAC;AAC9C;AAEA,OAAM,SAAUkB,wBAAwB,CACpCD,WAAqD,EACrDjB,WAAqB;EACvB,OAAOF,+BAA+B,CAClCmB,WAAW,EAAEjB,WAAW,EAAE,cAAc,CAAC;AAC/C;AAEA;;;;;;;;;;;;;;;;;;AAkBA,gBAAsBmB,kBAAkB;EAAA;AAAA;AAwDxC;;;;;;;AAAA;EAAA,iFAxDO,iBACHC,CAAS,EAAEC,YAAqB,EAAEJ,WAAyB,EAC3DK,gBAA6B;IAAA;IAAA;MAAA;QAAA;UAAA,MAC3BD,YAAY,IAAI,IAAI,IAAIC,gBAAgB,IAAI,IAAI;YAAA;YAAA;UAAA;UAAA,MAG5C,IAAIf,KAAK,CAAC,6CAA6C,CAAC;QAAA;UAAA,MAG5DU,WAAW,IAAI,IAAI;YAAA;YAAA;UAAA;UACrB;UACMM,QAAQ,GAAa1B,IAAI,CAAC,YAAK;YACnC,IAAIuB,CAAC,CAACI,KAAK,CAACrB,MAAM,KAAK,CAAC,EAAE;cACxB;cACA,OAAOX,KAAK,CAAC4B,CAAC,CAAa;aAC5B,MAAM,IAAIA,CAAC,CAACI,KAAK,CAACrB,MAAM,KAAK,CAAC,EAAE;cAC/B,IAAIiB,CAAC,CAACI,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;gBAClB;gBACA,IAAMC,IAAI,GAAG,CAAC;gBACd,OAAOlC,MAAM,CAAC6B,CAAC,EAAEK,IAAI,CAAC;eACvB,MAAM,IAAIL,CAAC,CAACI,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;gBAC3B;gBACA,OAAO7B,OAAO,CAACyB,CAAC,EAAE,CAACA,CAAC,CAACI,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;eAChC,MAAM;gBACL,MAAM,IAAIjB,KAAK,CACX,sDAA+Ca,CAAC,CAACI,KAAK,CAAC,CAAC,CAAC,yEACM,UACxD,CAAC;;aAEf,MAAM;cACL,MAAM,IAAIjB,KAAK,CACX,gDAAyCa,CAAC,CAACM,IAAI,gFACgB,CAAC;;UAExE,CAAC,CAAC;UAAA,cAEoBtB,KAAK;UAAA;UAAA,OAAYmB,QAAQ,CAACI,IAAI,EAAE;QAAA;UAAA;UAAhDC,aAAa,eAASC,IAAI;UAChCpC,OAAO,CAAC8B,QAAQ,CAAC;UACXO,iBAAiB,GAAa,EAAE;UACtCF,aAAa,CAACjB,OAAO,CAAC,oBAAU,EAAG;YACjC,IAAIM,WAAW,CAACc,UAAU,CAAC,IAAI,IAAI,EAAE;cACnC,MAAM,IAAIxB,KAAK,CACX,oFACawB,UAAU,oCAAiC,gBAC3C,CAAC;aACnB,MAAM;cACLD,iBAAiB,CAACjB,IAAI,CAACI,WAAW,CAACc,UAAU,CAAC,CAAC;;UAEnD,CAAC,CAAC;UAAC,iCAEInC,QAAQ,CAACkC,iBAAiB,EAAE,SAAS,CAAC;QAAA;UAAA,iCAEtC,IAAI;QAAA;QAAA;UAAA;MAAA;IAAA;EAAA,CAEd;EAAA;AAAA;AASD,OAAM,SAAUE,mBAAmB,CAACC,MAAc,EAAEC,aAAqB;EACvE,OAAOxC,GAAG,CAACuC,MAAM,EAAEC,aAAa,CAAC;AACnC","names":["argMax","clone","dispose","mul","reshape","tensor1d","tidy","standardizeSampleOrClassWeights","xWeight","outputNames","weightType","numOutputs","length","Array","isArray","map","Error","Object","keys","output","forEach","outputName","push","JSON","stringify","standardizeClassWeights","classWeight","standardizeSampleWeights","standardizeWeights","y","sampleWeight","sampleWeightMode","yClasses","shape","axis","rank","data","yClassIndices","from","classSampleWeight","classIndex","computeWeightedLoss","losses","sampleWeights"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\node_modules\\@tensorflow\\tfjs-layers\\src\\engine\\training_utils.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {argMax, clone, dispose, mul, reshape, Tensor, Tensor1D, tensor1d, tidy} from '@tensorflow/tfjs-core';\n\n/**\n * For multi-class classification problems, this object is designed to store a\n * mapping from class index to the \"weight\" of the class, where higher weighted\n * classes have larger impact on loss, accuracy, and other metrics.\n *\n * This is useful for cases in which you want the model to \"pay more attention\"\n * to examples from an under-represented class, e.g., in unbalanced datasets.\n */\nexport type ClassWeight = {\n  [classIndex: number]: number\n};\n\n/**\n * Class weighting for a model with multiple outputs.\n *\n * This object maps each output name to a class-weighting object.\n */\nexport type ClassWeightMap = {\n  [outputName: string]: ClassWeight\n};\n\nfunction standardizeSampleOrClassWeights(\n    xWeight: ClassWeight|ClassWeight[]|ClassWeightMap, outputNames: string[],\n    weightType: 'sampleWeight'|'classWeight'): ClassWeight[] {\n  const numOutputs = outputNames.length;\n  if (xWeight == null || (Array.isArray(xWeight) && xWeight.length === 0)) {\n    return outputNames.map(name => null);\n  }\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [(xWeight as ClassWeightMap)[outputNames[0]]];\n    } else {\n      return [xWeight as ClassWeight];\n    }\n  }\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(\n          `Provided ${weightType} is an array of ${xWeight.length} ` +\n          `element(s), but the model has ${numOutputs} outputs. ` +\n          `Make sure a set of weights is provided for each model output.`);\n    }\n    return xWeight;\n  } else if (\n      typeof xWeight === 'object' && Object.keys(xWeight).length > 0 &&\n      typeof (xWeight as ClassWeightMap)[Object.keys(xWeight)[0]] ===\n          'object') {\n    const output: ClassWeight[] = [];\n    outputNames.forEach(outputName => {\n      if (outputName in xWeight) {\n        output.push((xWeight as ClassWeightMap)[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(\n        `The model has multiple (${numOutputs}) outputs, ` +\n        `so ${weightType} must be either an array with ` +\n        `${numOutputs} elements or an object with ${outputNames} keys. ` +\n        `Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);\n  }\n}\n\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\nexport function standardizeClassWeights(\n    classWeight: ClassWeight|ClassWeight[]|ClassWeightMap,\n    outputNames: string[]): ClassWeight[] {\n  return standardizeSampleOrClassWeights(\n      classWeight, outputNames, 'classWeight');\n}\n\nexport function standardizeSampleWeights(\n    classWeight: ClassWeight|ClassWeight[]|ClassWeightMap,\n    outputNames: string[]): ClassWeight[] {\n  return standardizeSampleOrClassWeights(\n      classWeight, outputNames, 'sampleWeight');\n}\n\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\nexport async function standardizeWeights(\n    y: Tensor, sampleWeight?: Tensor, classWeight?: ClassWeight,\n    sampleWeightMode?: 'temporal'): Promise<Tensor> {\n  if (sampleWeight != null || sampleWeightMode != null) {\n    // TODO(cais): Once 'temporal' mode is implemented, document it in the doc\n    // string.\n    throw new Error('Support sampleWeight is not implemented yet');\n  }\n\n  if (classWeight != null) {\n    // Apply class weights per sample.\n    const yClasses: Tensor1D = tidy(() => {\n      if (y.shape.length === 1) {\n        // Assume class indices.\n        return clone(y) as Tensor1D;\n      } else if (y.shape.length === 2) {\n        if (y.shape[1] > 1) {\n          // Assume one-hot encoding of classes.\n          const axis = 1;\n          return argMax(y, axis);\n        } else if (y.shape[1] === 1) {\n          // Class index.\n          return reshape(y, [y.shape[0]]);\n        } else {\n          throw new Error(\n              `Encountered unexpected last-dimension size (${y.shape[1]}) ` +\n              `during handling of class weights. The size is expected to be ` +\n              `>= 1.`);\n        }\n      } else {\n        throw new Error(\n            `Unexpected rank of target (y) tensor (${y.rank}) during ` +\n            `handling of class weights. The rank is expected to be 1 or 2.`);\n      }\n    });\n\n    const yClassIndices = Array.from(await yClasses.data());\n    dispose(yClasses);\n    const classSampleWeight: number[] = [];\n    yClassIndices.forEach(classIndex => {\n      if (classWeight[classIndex] == null) {\n        throw new Error(\n            `classWeight must contain all classes in the training data. ` +\n            `The class ${classIndex} exists in the data but not in ` +\n            `classWeight`);\n      } else {\n        classSampleWeight.push(classWeight[classIndex]);\n      }\n    });\n\n    return tensor1d(classSampleWeight, 'float32');\n  } else {\n    return null;\n  }\n}\n\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\nexport function computeWeightedLoss(losses: Tensor, sampleWeights: Tensor) {\n  return mul(losses, sampleWeights);\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}