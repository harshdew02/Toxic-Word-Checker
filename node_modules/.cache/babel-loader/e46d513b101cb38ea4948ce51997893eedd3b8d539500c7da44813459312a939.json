{"ast":null,"code":"import _createClass from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _classCallCheck from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\n/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { useShapeUniforms } from './gpgpu_math';\nexport var Conv2DPackedProgram = /*#__PURE__*/_createClass(function Conv2DPackedProgram(convInfo) {\n  var addBias = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  var activation = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n  var hasPreluActivation = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n  var hasLeakyReluAlpha = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n  _classCallCheck(this, Conv2DPackedProgram);\n  this.variableNames = ['x', 'W'];\n  this.packedInputs = true;\n  this.packedOutput = true;\n  this.customUniforms = [{\n    name: 'pads',\n    type: 'ivec2'\n  }, {\n    name: 'strides',\n    type: 'ivec2'\n  }, {\n    name: 'dilations',\n    type: 'ivec2'\n  }, {\n    name: 'inDims',\n    type: 'ivec2'\n  }];\n  this.outputShape = convInfo.outShape;\n  this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);\n  var padLeft = convInfo.padInfo.left;\n  var strideWidth = convInfo.strideWidth;\n  var dilationWidth = convInfo.dilationWidth;\n  var filterHeight = convInfo.filterHeight;\n  var filterWidth = convInfo.filterWidth;\n  var texelsAcross = filterWidth;\n  var mainLoop = \"\\n       int xR; int xC; int xCOffset;\\n       vec4 wTexel; vec4 previous; vec4 final;\";\n  for (var c = 0; c < filterWidth; c++) {\n    mainLoop += \"\\n           vec4 xTexelC\".concat(c * 2, \";\\n           int xTexelC\").concat(c * 2, \"Ready;\\n           vec4 xTexelC\").concat(c * 2 + 1, \";\\n           int xTexelC\").concat(c * 2 + 1, \"Ready;\\n           vec4 xC\").concat(c, \";\");\n  }\n  /**\n   * This vectorized implementation works by gathering the values needed for\n   * each output channel's dot product into vec4's and then multiplying them\n   * all together (this happens in the final double for-loop below). Most of\n   * the main loop consists of constructing these vec4's with the minimum\n   * number of texture2D calls, which means making use of all four returned\n   * values from a texture2D call at once.\n   */\n  mainLoop += \"\\n     for (int r = 0; r < \".concat(filterHeight, \"; r++) {\\n      for (int d1 = 0; d1 < \").concat(convInfo.inChannels, \"; d1 += 2) {\\n       \");\n  for (var _c = 0; _c < filterWidth; _c++) {\n    mainLoop += \"\\n           xTexelC\".concat(_c * 2, \" = vec4(0.0);\\n           xTexelC\").concat(_c * 2, \"Ready = 0;\\n           xTexelC\").concat(_c * 2 + 1, \" = vec4(0.0);\\n           xTexelC\").concat(_c * 2 + 1, \"Ready = 0;\\n           xC\").concat(_c, \" = vec4(0.0);\");\n  }\n  mainLoop += \"\\n         xR = xRCorner + r * dilations[0];\\n         if (xR >=0 && xR < inDims[0]) {\\n       \";\n  for (var texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n    var colIndex = texelC * 2;\n    mainLoop += \"\\n           xC = xCCorner + \".concat(colIndex * dilationWidth, \";\\n           \");\n    if (strideWidth === 1) {\n      if (colIndex < filterWidth) {\n        // If padding is odd, the outer texels have to be composed.\n        if (padLeft % 2 === 1) {\n          // TODO: Ensure vec4 previous does not result in redundant sample,\n          // and avoid setting xTexelRC's that exceed the boundary in the\n          // first place rather than resetting them to vec4(0)).\n          // To compute xCOffset:\n          // - If padding is odd, we must add 1 to ensure we ask for an\n          // even-numbered row.\n          // - We subtract 2 to access the previous texel.\n          mainLoop += \"\\n                 xCOffset = xC + 1;\\n                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                   xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n\\n                   // Need to manually clear unused channels in case\\n                   // we're reading from recycled texture.\\n                   if (xCOffset + 1 >= inDims[1]) {\\n                     xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                   }\\n                   xTexelC\").concat(colIndex, \"Ready = 1;\\n                 }\\n               \");\n          // This texel has been read in previous iteration if the dilation\n          // is 1.\n          if (dilationWidth === 1 && colIndex > 0) {\n            mainLoop += \"\\n                 xC\".concat(colIndex, \" = vec4(xTexelC\").concat(colIndex - 2, \".zw, xTexelC\").concat(colIndex, \".xy);\\n                 \");\n          } else {\n            mainLoop += \"\\n                   xCOffset = xC + 1 - 2;\\n\\n                   if (xCOffset >= 0 && xCOffset < inDims[1]) {\\n                     previous = getX(batch, xR, xCOffset, d1);\\n\\n                     // Need to manually clear unused channels in case\\n                     // we're reading from recycled texture.\\n                     if (xCOffset + 1 >= inDims[1]) {\\n                       previous.zw = vec2(0.0);\\n                     }\\n\\n                     xC\".concat(colIndex, \" = vec4(previous.zw, xTexelC\").concat(colIndex, \".xy);\\n                   } else {\\n                     xC\").concat(colIndex, \" = vec4(0.0, 0.0, xTexelC\").concat(colIndex, \".xy);\\n                   }\\n                   \");\n          }\n        } else {\n          // Padding is even, so xRC corresponds to a single texel.\n          mainLoop += \"\\n                 if (xC >= 0 && xC < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                   xTexelC\").concat(colIndex, \" = getX(batch, xR, xC, d1);\\n                   if (xC + 1 >= inDims[1]) {\\n                     xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                   }\\n                   xTexelC\").concat(colIndex, \"Ready = 1;\\n                 }\\n\\n                 xC\").concat(colIndex, \" = xTexelC\").concat(colIndex, \";\\n                 \");\n        }\n        if (colIndex + 1 < filterWidth) {\n          // If dilation is even, the second entry should match the first\n          // (either both are composed or both are single samples). But if\n          // dilation is odd, then the second entry should be the opposite\n          // of the first (if the first is composed, the second is a single\n          // sample, and vice versa.)\n          var nextTexelOffset = padLeft % 2 === 0 ? util.nearestLargerEven(dilationWidth) : dilationWidth;\n          if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {\n            mainLoop += \"\\n                   xCOffset = xC + imod(pads[1], 2) + \".concat(nextTexelOffset, \";\\n\\n                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                     xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n\\n                     // Need to manually clear unused channels in case\\n                     // we're reading from recycled texture.\\n                     if (xCOffset + 1 >= inDims[1]) {\\n                       xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                     }\\n                     xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                   }\\n                   \");\n            // If dilation > 1 then the xRC's will not be able to share any\n            // values, so each xRC will require two unique calls to getX.\n            if (dilationWidth > 1) {\n              mainLoop += \"\\n                     xCOffset -= 2;\\n                     if (xCOffset >= 0 && xCOffset < inDims[1]) {\\n                      previous = getX(batch, xR, xCOffset, d1);\\n                      xC\".concat(colIndex + 1, \" = vec4(previous.zw, xTexelC\").concat(colIndex + 1, \".xy);\\n                     } else {\\n                      xC\").concat(colIndex + 1, \" = vec4(0.0, 0.0, xTexelC\").concat(colIndex + 1, \".xy);\\n                     }\\n                     \");\n            } else {\n              mainLoop += \"\\n                     xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".xy);\\n                     \");\n            }\n          } else {\n            // If dilation is 1 and padding is odd, we have already read the\n            // texel when constructing the previous x value. Here we can\n            // simply skip the texture read.\n            if (nextTexelOffset === 1) {\n              mainLoop += \"\\n                     xC\".concat(colIndex + 1, \" = xTexelC\").concat(colIndex, \";\\n                     \");\n            } else {\n              mainLoop += \"\\n                     xCOffset = xC + \".concat(nextTexelOffset, \";\\n\\n                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                       xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n                       if (xCOffset + 1 >= inDims[1]) {\\n                         xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                       }\\n                       xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                     }\\n\\n                     xC\").concat(colIndex + 1, \" = xTexelC\").concat(colIndex + 1, \";\\n                     \");\n            }\n          }\n        }\n      }\n    } else {\n      // stride === 2\n      if (colIndex < filterWidth) {\n        // Depending on whether padLeft is even or odd, we want either the\n        // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n        // even, xC${colIndex +1} is simply the zw channels of texels we've\n        // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n        // need to come from the xy channels of a new texel, hence the `\n        // vec4\n        // final` initialized below.\n        if (padLeft % 2 === 1) {\n          mainLoop += \"\\n                 xCOffset = xC + 1 - strides[1];\\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                   xTexelC\").concat(colIndex, \" = getX(batch, xR, xCOffset, d1);\\n                   // Need to manually clear unused channels in case\\n                   // we're reading from recycled texture.\\n                   if (xCOffset + 1 >= inDims[1]) {\\n                     xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                   }\\n                   xTexelC\").concat(colIndex, \"Ready = 1;\\n                 }\\n\\n                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                   xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xC + 1, d1);\\n                   // Need to manually clear unused channels in case\\n                   // we're reading from recycled texture.\\n                   if (xC + 2 >= inDims[1]) {\\n                     xTexelC\").concat(colIndex + 1, \".zw = vec2(0.0);\\n                   }\\n                   xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                 }\\n\\n                 xC\").concat(colIndex, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".zw);\\n               \");\n          if (colIndex + 1 < filterWidth) {\n            mainLoop += \"\\n                   final = vec4(0.0);\\n                   xCOffset = xC + 1 + strides[1];\\n                   if(xCOffset >= 0 && xCOffset < inDims[1]) {\\n                     final = getX(batch, xR, xCOffset, d1);\\n                   }\\n                   xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex + 1, \".xy, final.xy);\\n                 \");\n          }\n        } else {\n          mainLoop += \"\\n                 if(xC >= 0 && xC < inDims[1] && xTexelC\".concat(colIndex, \"Ready == 0) {\\n                   xTexelC\").concat(colIndex, \" = getX(batch, xR, xC, d1);\\n                   if (xC + 1 >= inDims[1]) {\\n                     xTexelC\").concat(colIndex, \".zw = vec2(0.0);\\n                   }\\n                   xTexelC\").concat(colIndex, \"Ready = 1;\\n                 }\\n\\n                 xCOffset = xC + strides[1];\\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC\").concat(colIndex + 1, \"Ready == 0) {\\n                   xTexelC\").concat(colIndex + 1, \" = getX(batch, xR, xCOffset, d1);\\n                   if (xCOffset + 1 >= inDims[1]) {\\n                     xTexelC\").concat(colIndex + 1, \".zw = vec2(0.);\\n                   }\\n                   xTexelC\").concat(colIndex + 1, \"Ready = 1;\\n                 }\\n\\n                 xC\").concat(colIndex, \" = vec4(\\n                   xTexelC\").concat(colIndex, \".xy, xTexelC\").concat(colIndex + 1, \".xy);\\n               \");\n          if (colIndex + 1 < filterWidth) {\n            mainLoop += \"\\n                   xC\".concat(colIndex + 1, \" = vec4(xTexelC\").concat(colIndex, \".zw, xTexelC\").concat(colIndex + 1, \".zw);\\n                 \");\n          }\n        }\n      }\n    }\n    // localize the dotProd accumulation within the loop, the theory is for\n    // GPU with limited cache, accumulate sum across large amount of\n    // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n    // 50 variables)\n    if (colIndex < filterWidth) {\n      mainLoop += \"\\n             wTexel = getW(r, \".concat(colIndex, \", d1, d2);\\n             dotProd += xC\").concat(colIndex, \".xxzz * vec4(wTexel.xy, wTexel.xy);\\n             if(d1 + 1 < \").concat(convInfo.inChannels, \") {\\n               dotProd += xC\").concat(colIndex, \".yyww * vec4(wTexel.zw, wTexel.zw);\\n             }\\n           \");\n      if (colIndex + 1 < filterWidth) {\n        mainLoop += \"\\n               wTexel = getW(r, \".concat(colIndex + 1, \", d1, d2);\\n               dotProd += xC\").concat(colIndex + 1, \".xxzz * vec4(wTexel.xy, wTexel.xy);\\n               if(d1 + 1 < \").concat(convInfo.inChannels, \") {\\n                 dotProd += xC\").concat(colIndex + 1, \".yyww * vec4(wTexel.zw, wTexel.zw);\\n               }\\n             \");\n      }\n    }\n  }\n  mainLoop += \"\\n     }\\n   \";\n  mainLoop += \"\\n     }\\n   \";\n  mainLoop += \"\\n     }\\n   \";\n  var activationSnippet = '',\n    applyActivationSnippet = '';\n  if (activation) {\n    if (hasPreluActivation) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n           vec4 b = getPreluActivationWeightsAtOutCoords();\\n           \".concat(activation, \"\\n         }\");\n    } else if (hasLeakyReluAlpha) {\n      activationSnippet = \"vec4 activation(vec4 a) {\\n           vec4 b = getLeakyreluAlphaAtOutCoords();\\n           \".concat(activation, \"\\n         }\");\n    } else {\n      activationSnippet = \"vec4 activation(vec4 x) {\\n           \".concat(activation, \"\\n         }\");\n    }\n    applyActivationSnippet = \"result = activation(result);\";\n  }\n  var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n  if (addBias) {\n    this.variableNames.push('bias');\n  }\n  if (hasPreluActivation) {\n    this.variableNames.push('preluActivationWeights');\n  }\n  if (hasLeakyReluAlpha) {\n    this.variableNames.push('leakyreluAlpha');\n  }\n  this.userCode = \"\\n       \".concat(activationSnippet, \"\\n\\n       void main() {\\n         ivec4 coords = getOutputCoords();\\n         int batch = coords.x;\\n         ivec2 xRCCorner = coords.yz * strides - pads;\\n         int d2 = coords.w;\\n         int xRCorner = xRCCorner.x;\\n         int xCCorner = xRCCorner.y;\\n\\n         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\\n         vec4 dotProd = vec4(0.000000000000001);\\n\\n         \").concat(mainLoop, \"\\n\\n         vec4 result = dotProd - vec4(0.000000000000001);\\n         \").concat(addBiasSnippet, \"\\n         \").concat(applyActivationSnippet, \"\\n         setOutput(result);\\n       }\\n     \");\n});","map":{"version":3,"mappings":";;AAAA;;;;;;;;;;;;;;;;AAiBC,SAAsBA,IAAI,QAAO,uBAAuB;AAExD,SAAsBC,gBAAgB,QAAO,cAAc;AAE3D,WAAaC,mBAAmB,6BAc9B,6BACIC,QAAiC,EAER;EAAA,IAFUC,OAAO,uEAAG,KAAK;EAAA,IAClDC,iFAAqB,IAAI;EAAA,IAAEC,kBAAkB,uEAAG,KAAK;EAAA,IACrDC,iBAAiB,uEAAG,KAAK;EAAA;EAhB7B,kBAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC;EAC1B,iBAAY,GAAG,IAAI;EACnB,iBAAY,GAAG,IAAI;EAInB,mBAAc,GAAG,CACf;IAACC,IAAI,EAAE,MAAM;IAAEC,IAAI,EAAE;EAAgB,CAAE,EACvC;IAACD,IAAI,EAAE,SAAS;IAAEC,IAAI,EAAE;EAAgB,CAAE,EAC1C;IAACD,IAAI,EAAE,WAAW;IAAEC,IAAI,EAAE;EAAgB,CAAE,EAC5C;IAACD,IAAI,EAAE,QAAQ;IAAEC,IAAI,EAAE;EAAgB,CAAE,CAC1C;EAMC,IAAI,CAACC,WAAW,GAAGP,QAAQ,CAACQ,QAAQ;EACpC,IAAI,CAACC,mBAAmB,GAAGX,gBAAgB,CAAC,IAAI,CAACS,WAAW,CAACG,MAAM,CAAC;EACpE,IAAMC,OAAO,GAAGX,QAAQ,CAACY,OAAO,CAACC,IAAI;EACrC,IAAMC,WAAW,GAAGd,QAAQ,CAACc,WAAW;EACxC,IAAMC,aAAa,GAAGf,QAAQ,CAACe,aAAa;EAC5C,IAAMC,YAAY,GAAGhB,QAAQ,CAACgB,YAAY;EAC1C,IAAMC,WAAW,GAAGjB,QAAQ,CAACiB,WAAW;EACxC,IAAMC,YAAY,GAAGD,WAAW;EAEhC,IAAIE,QAAQ,2FAE8B;EAE1C,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGH,WAAW,EAAEG,CAAC,EAAE,EAAE;IACpCD,QAAQ,uCACUC,CAAC,GAAG,CAAC,sCACNA,CAAC,GAAG,CAAC,4CACJA,CAAC,GAAG,CAAC,GAAG,CAAC,sCACVA,CAAC,GAAG,CAAC,GAAG,CAAC,uCACbA,CAAC,MAAG;;EAGnB;;;;;;;;EAQAD,QAAQ,yCACcH,YAAY,mDACThB,QAAQ,CAACqB,UAAU,0BACzC;EACH,KAAK,IAAID,EAAC,GAAG,CAAC,EAAEA,EAAC,GAAGH,WAAW,EAAEG,EAAC,EAAE,EAAE;IACpCD,QAAQ,kCACKC,EAAC,GAAG,CAAC,8CACLA,EAAC,GAAG,CAAC,2CACLA,EAAC,GAAG,CAAC,GAAG,CAAC,8CACTA,EAAC,GAAG,CAAC,GAAG,CAAC,sCACdA,EAAC,kBAAe;;EAE1BD,QAAQ,qGAGL;EAEH,KAAK,IAAIG,MAAM,GAAG,CAAC,EAAEA,MAAM,GAAG,CAACJ,YAAY,GAAG,CAAC,IAAI,CAAC,EAAEI,MAAM,EAAE,EAAE;IAC9D,IAAMC,QAAQ,GAAGD,MAAM,GAAG,CAAC;IAE3BH,QAAQ,2CACcI,QAAQ,GAAGR,aAAa,mBACzC;IAEL,IAAID,WAAW,KAAK,CAAC,EAAE;MACrB,IAAIS,QAAQ,GAAGN,WAAW,EAAE;QAC1B;QACA,IAAIN,OAAO,GAAG,CAAC,KAAK,CAAC,EAAE;UACrB;UACA;UACA;UAEA;UACA;UACA;UACA;UAEAQ,QAAQ,0HAGJI,QAAQ,sDACGA,QAAQ,qQAKNA,QAAQ,+EAEVA,QAAQ,oDAEpB;UACH;UACA;UACA,IAAIR,aAAa,KAAK,CAAC,IAAIQ,QAAQ,GAAG,CAAC,EAAE;YACvCJ,QAAQ,mCACFI,QAAQ,4BAAkBA,QAAQ,GAAG,CAAC,yBACxCA,QAAQ,6BACT;WACJ,MAAM;YACLJ,QAAQ,+dAYEI,QAAQ,yCAA+BA,QAAQ,wEAE/CA,QAAQ,sCAA4BA,QAAQ,qDAEjD;;SAER,MAAM;UACL;UACAJ,QAAQ,yEACsCI,QAAQ,sDACvCA,QAAQ,qHAENA,QAAQ,+EAEVA,QAAQ,kEAGfA,QAAQ,uBAAaA,QAAQ,yBAChC;;QAGP,IAAIA,QAAQ,GAAG,CAAC,GAAGN,WAAW,EAAE;UAC9B;UACA;UACA;UACA;UACA;UAEA,IAAMO,eAAe,GAAGb,OAAO,GAAG,CAAC,KAAK,CAAC,GACrCd,IAAI,CAAC4B,iBAAiB,CAACV,aAAa,CAAC,GACrCA,aAAa;UAEjB,IAAKA,aAAa,GAAG,CAAC,KAAK,CAAC,IAAIJ,OAAO,GAAG,CAAC,KAAK,CAAC,IAC5CI,aAAa,GAAG,CAAC,KAAK,CAAC,IAAIJ,OAAO,GAAG,CAAC,KAAK,CAAE,EAAE;YAClDQ,QAAQ,sEACiCK,eAAe,yFAGpDD,QAAQ,GAAG,CAAC,wDACDA,QAAQ,GAAG,CAAC,6QAKVA,QAAQ,GAAG,CAAC,mFAEdA,QAAQ,GAAG,CAAC,0DAEtB;YAEL;YACA;YACA,IAAIR,aAAa,GAAG,CAAC,EAAE;cACrBI,QAAQ,iNAICI,QAAQ,GAAG,CAAC,yCACdA,QAAQ,GAAG,CAAC,2EAEVA,QAAQ,GAAG,CAAC,sCACdA,QAAQ,GAAG,CAAC,yDAEd;aACN,MAAM;cACLJ,QAAQ,uCACAI,QAAQ,GAAG,CAAC,4BAAkBA,QAAQ,yBAC1CA,QAAQ,GAAG,CAAC,iCACX;;WAGR,MAAM;YACL;YACA;YACA;YACA,IAAIC,eAAe,KAAK,CAAC,EAAE;cACzBL,QAAQ,uCACAI,QAAQ,GAAG,CAAC,uBAAaA,QAAQ,6BACpC;aACN,MAAM;cACLJ,QAAQ,qDACcK,eAAe,2FAGjCD,QAAQ,GAAG,CAAC,0DACDA,QAAQ,GAAG,CAAC,yIAEVA,QAAQ,GAAG,CAAC,uFAEdA,QAAQ,GAAG,CAAC,0EAGnBA,QAAQ,GAAG,CAAC,uBAAaA,QAAQ,GAAG,CAAC,6BACxC;;;;;KAKd,MAAM;MAAG;MACR,IAAIA,QAAQ,GAAGN,WAAW,EAAE;QAC1B;QACA;QACA;QACA;QACA;QACA;QACA;QACA,IAAIN,OAAO,GAAG,CAAC,KAAK,CAAC,EAAE;UACrBQ,QAAQ,sIAGJI,QAAQ,sDACGA,QAAQ,mQAINA,QAAQ,+EAEVA,QAAQ,+GAInBA,QAAQ,GAAG,CAAC,sDACDA,QAAQ,GAAG,CAAC,2PAIVA,QAAQ,GAAG,CAAC,+EAEdA,QAAQ,GAAG,CAAC,kEAGnBA,QAAQ,4BAAkBA,QAAQ,yBACtCA,QAAQ,GAAG,CAAC,2BACb;UAEH,IAAIA,QAAQ,GAAG,CAAC,GAAGN,WAAW,EAAE;YAC9BE,QAAQ,mRAMAI,QAAQ,GAAG,CAAC,4BAAkBA,QAAQ,GAAG,CAAC,uCAC/C;;SAEN,MAAM;UACLJ,QAAQ,wEACqCI,QAAQ,sDACtCA,QAAQ,qHAENA,QAAQ,+EAEVA,QAAQ,iKAKnBA,QAAQ,GAAG,CAAC,sDACDA,QAAQ,GAAG,CAAC,iIAEVA,QAAQ,GAAG,CAAC,8EAEdA,QAAQ,GAAG,CAAC,kEAGnBA,QAAQ,iDACDA,QAAQ,yBAAeA,QAAQ,GAAG,CAAC,2BAC/C;UAEH,IAAIA,QAAQ,GAAG,CAAC,GAAGN,WAAW,EAAE;YAC9BE,QAAQ,qCACAI,QAAQ,GAAG,CAAC,4BAAkBA,QAAQ,yBAC1CA,QAAQ,GAAG,CAAC,6BACb;;;;;IAMX;IACA;IACA;IACA;IACA,IAAIA,QAAQ,GAAGN,WAAW,EAAE;MAC1BE,QAAQ,8CACeI,QAAQ,mDACZA,QAAQ,2EACTvB,QAAQ,CAACqB,UAAU,8CAChBE,QAAQ,qEAE1B;MAEH,IAAIA,QAAQ,GAAG,CAAC,GAAGN,WAAW,EAAE;QAC9BE,QAAQ,gDACeI,QAAQ,GAAG,CAAC,qDAChBA,QAAQ,GAAG,CAAC,6EACbvB,QAAQ,CAACqB,UAAU,gDAChBE,QAAQ,GAAG,CAAC,yEAE9B;;;;EAITJ,QAAQ,mBAET;EACDA,QAAQ,mBAEP;EACDA,QAAQ,mBAEP;EAEC,IAAIO,iBAAiB,GAAG,EAAE;IAAEC,sBAAsB,GAAG,EAAE;EACvD,IAAIzB,UAAU,EAAE;IACd,IAAIC,kBAAkB,EAAE;MACtBuB,iBAAiB,gHAEbxB,UAAU,iBACZ;KACH,MAAM,IAAIE,iBAAiB,EAAE;MAC5BsB,iBAAiB,wGAEbxB,UAAU,iBACZ;KACH,MAAM;MACLwB,iBAAiB,mDACbxB,UAAU,iBACZ;;IAGJyB,sBAAsB,iCAAiC;;EAGzD,IAAMC,cAAc,GAAG3B,OAAO,GAAG,iCAAiC,GAAG,EAAE;EACvE,IAAIA,OAAO,EAAE;IACX,IAAI,CAAC4B,aAAa,CAACC,IAAI,CAAC,MAAM,CAAC;;EAGjC,IAAI3B,kBAAkB,EAAE;IACtB,IAAI,CAAC0B,aAAa,CAACC,IAAI,CAAC,wBAAwB,CAAC;;EAEnD,IAAI1B,iBAAiB,EAAE;IACrB,IAAI,CAACyB,aAAa,CAACC,IAAI,CAAC,gBAAgB,CAAC;;EAG3C,IAAI,CAACC,QAAQ,sBACTL,iBAAiB,yaAafP,QAAQ,qFAGRS,cAAc,wBACdD,sBAAsB,mDAG3B;AACH,CAAC","names":["util","useShapeUniforms","Conv2DPackedProgram","convInfo","addBias","activation","hasPreluActivation","hasLeakyReluAlpha","name","type","outputShape","outShape","enableShapeUniforms","length","padLeft","padInfo","left","strideWidth","dilationWidth","filterHeight","filterWidth","texelsAcross","mainLoop","c","inChannels","texelC","colIndex","nextTexelOffset","nearestLargerEven","activationSnippet","applyActivationSnippet","addBiasSnippet","variableNames","push","userCode"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\node_modules\\@tensorflow\\tfjs-backend-webgl\\src\\conv_packed_gpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n import {backend_util, util} from '@tensorflow/tfjs-core';\n\n import {GPGPUProgram, useShapeUniforms} from './gpgpu_math';\n\n export class Conv2DPackedProgram implements GPGPUProgram {\n   variableNames = ['x', 'W'];\n   packedInputs = true;\n   packedOutput = true;\n   outputShape: number[];\n   userCode: string;\n   enableShapeUniforms: boolean;\n   customUniforms = [\n     {name: 'pads', type: 'ivec2' as const },\n     {name: 'strides', type: 'ivec2' as const },\n     {name: 'dilations', type: 'ivec2' as const },\n     {name: 'inDims', type: 'ivec2' as const },\n   ];\n\n   constructor(\n       convInfo: backend_util.Conv2DInfo, addBias = false,\n       activation: string = null, hasPreluActivation = false,\n       hasLeakyReluAlpha = false) {\n     this.outputShape = convInfo.outShape;\n     this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);\n     const padLeft = convInfo.padInfo.left;\n     const strideWidth = convInfo.strideWidth;\n     const dilationWidth = convInfo.dilationWidth;\n     const filterHeight = convInfo.filterHeight;\n     const filterWidth = convInfo.filterWidth;\n     const texelsAcross = filterWidth;\n\n     let mainLoop = `\n       int xR; int xC; int xCOffset;\n       vec4 wTexel; vec4 previous; vec4 final;`;\n\n     for (let c = 0; c < filterWidth; c++) {\n       mainLoop += `\n           vec4 xTexelC${c * 2};\n           int xTexelC${c * 2}Ready;\n           vec4 xTexelC${c * 2 + 1};\n           int xTexelC${c * 2 + 1}Ready;\n           vec4 xC${c};`;\n     }\n\n     /**\n      * This vectorized implementation works by gathering the values needed for\n      * each output channel's dot product into vec4's and then multiplying them\n      * all together (this happens in the final double for-loop below). Most of\n      * the main loop consists of constructing these vec4's with the minimum\n      * number of texture2D calls, which means making use of all four returned\n      * values from a texture2D call at once.\n      */\n     mainLoop += `\n     for (int r = 0; r < ${filterHeight}; r++) {\n      for (int d1 = 0; d1 < ${convInfo.inChannels}; d1 += 2) {\n       `;\n     for (let c = 0; c < filterWidth; c++) {\n       mainLoop += `\n           xTexelC${c * 2} = vec4(0.0);\n           xTexelC${c * 2}Ready = 0;\n           xTexelC${c * 2 + 1} = vec4(0.0);\n           xTexelC${c * 2 + 1}Ready = 0;\n           xC${c} = vec4(0.0);`;\n     }\n     mainLoop += `\n         xR = xRCorner + r * dilations[0];\n         if (xR >=0 && xR < inDims[0]) {\n       `;\n\n     for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {\n       const colIndex = texelC * 2;\n\n       mainLoop += `\n           xC = xCCorner + ${colIndex * dilationWidth};\n           `;\n\n       if (strideWidth === 1) {\n         if (colIndex < filterWidth) {\n           // If padding is odd, the outer texels have to be composed.\n           if (padLeft % 2 === 1) {\n             // TODO: Ensure vec4 previous does not result in redundant sample,\n             // and avoid setting xTexelRC's that exceed the boundary in the\n             // first place rather than resetting them to vec4(0)).\n\n             // To compute xCOffset:\n             // - If padding is odd, we must add 1 to ensure we ask for an\n             // even-numbered row.\n             // - We subtract 2 to access the previous texel.\n\n             mainLoop += `\n                 xCOffset = xC + 1;\n                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                 colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n               `;\n             // This texel has been read in previous iteration if the dilation\n             // is 1.\n             if (dilationWidth === 1 && colIndex > 0) {\n               mainLoop += `\n                 xC${colIndex} = vec4(xTexelC${colIndex - 2}.zw, xTexelC${\n                   colIndex}.xy);\n                 `;\n             } else {\n               mainLoop += `\n                   xCOffset = xC + 1 - 2;\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                     previous = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       previous.zw = vec2(0.0);\n                     }\n\n                     xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);\n                   } else {\n                     xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);\n                   }\n                   `;\n             }\n           } else {\n             // Padding is even, so xRC corresponds to a single texel.\n             mainLoop += `\n                 if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n\n                 xC${colIndex} = xTexelC${colIndex};\n                 `;\n           }\n\n           if (colIndex + 1 < filterWidth) {\n             // If dilation is even, the second entry should match the first\n             // (either both are composed or both are single samples). But if\n             // dilation is odd, then the second entry should be the opposite\n             // of the first (if the first is composed, the second is a single\n             // sample, and vice versa.)\n\n             const nextTexelOffset = padLeft % 2 === 0 ?\n                 util.nearestLargerEven(dilationWidth) :\n                 dilationWidth;\n\n             if ((dilationWidth % 2 === 0 && padLeft % 2 === 1) ||\n                 (dilationWidth % 2 !== 0 && padLeft % 2 !== 1)) {\n               mainLoop += `\n                   xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};\n\n                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                   colIndex + 1}Ready == 0) {\n                     xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n\n                     // Need to manually clear unused channels in case\n                     // we're reading from recycled texture.\n                     if (xCOffset + 1 >= inDims[1]) {\n                       xTexelC${colIndex + 1}.zw = vec2(0.0);\n                     }\n                     xTexelC${colIndex + 1}Ready = 1;\n                   }\n                   `;\n\n               // If dilation > 1 then the xRC's will not be able to share any\n               // values, so each xRC will require two unique calls to getX.\n               if (dilationWidth > 1) {\n                 mainLoop += `\n                     xCOffset -= 2;\n                     if (xCOffset >= 0 && xCOffset < inDims[1]) {\n                      previous = getX(batch, xR, xCOffset, d1);\n                      xC${colIndex + 1} = vec4(previous.zw, xTexelC${\n                        colIndex + 1}.xy);\n                     } else {\n                      xC${colIndex + 1} = vec4(0.0, 0.0, xTexelC${\n                        colIndex + 1}.xy);\n                     }\n                     `;\n               } else {\n                 mainLoop += `\n                     xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                     colIndex + 1}.xy);\n                     `;\n               }\n\n             } else {\n               // If dilation is 1 and padding is odd, we have already read the\n               // texel when constructing the previous x value. Here we can\n               // simply skip the texture read.\n               if (nextTexelOffset === 1) {\n                 mainLoop += `\n                     xC${colIndex + 1} = xTexelC${colIndex};\n                     `;\n               } else {\n                 mainLoop += `\n                     xCOffset = xC + ${nextTexelOffset};\n\n                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                     colIndex + 1}Ready == 0) {\n                       xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n                       if (xCOffset + 1 >= inDims[1]) {\n                         xTexelC${colIndex + 1}.zw = vec2(0.0);\n                       }\n                       xTexelC${colIndex + 1}Ready = 1;\n                     }\n\n                     xC${colIndex + 1} = xTexelC${colIndex + 1};\n                     `;\n               }\n             }\n           }\n         }\n       } else {  // stride === 2\n         if (colIndex < filterWidth) {\n           // Depending on whether padLeft is even or odd, we want either the\n           // xy or zw channels from X texels for xC${colIndex}. If padLeft is\n           // even, xC${colIndex +1} is simply the zw channels of texels we've\n           // already sampled. But if padLeft is odd, xC{$c + 1}.zw will\n           // need to come from the xy channels of a new texel, hence the `\n           // vec4\n           // final` initialized below.\n           if (padLeft % 2 === 1) {\n             mainLoop += `\n                 xCOffset = xC + 1 - strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                 colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n\n                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${\n                 colIndex + 1}Ready == 0) {\n                   xTexelC${colIndex + 1} = getX(batch, xR, xC + 1, d1);\n                   // Need to manually clear unused channels in case\n                   // we're reading from recycled texture.\n                   if (xC + 2 >= inDims[1]) {\n                     xTexelC${colIndex + 1}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex + 1}Ready = 1;\n                 }\n\n                 xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                 colIndex + 1}.zw);\n               `;\n\n             if (colIndex + 1 < filterWidth) {\n               mainLoop += `\n                   final = vec4(0.0);\n                   xCOffset = xC + 1 + strides[1];\n                   if(xCOffset >= 0 && xCOffset < inDims[1]) {\n                     final = getX(batch, xR, xCOffset, d1);\n                   }\n                   xC${colIndex + 1} = vec4(xTexelC${colIndex + 1}.xy, final.xy);\n                 `;\n             }\n           } else {\n             mainLoop += `\n                 if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {\n                   xTexelC${colIndex} = getX(batch, xR, xC, d1);\n                   if (xC + 1 >= inDims[1]) {\n                     xTexelC${colIndex}.zw = vec2(0.0);\n                   }\n                   xTexelC${colIndex}Ready = 1;\n                 }\n\n                 xCOffset = xC + strides[1];\n                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${\n                 colIndex + 1}Ready == 0) {\n                   xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);\n                   if (xCOffset + 1 >= inDims[1]) {\n                     xTexelC${colIndex + 1}.zw = vec2(0.);\n                   }\n                   xTexelC${colIndex + 1}Ready = 1;\n                 }\n\n                 xC${colIndex} = vec4(\n                   xTexelC${colIndex}.xy, xTexelC${colIndex + 1}.xy);\n               `;\n\n             if (colIndex + 1 < filterWidth) {\n               mainLoop += `\n                   xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${\n                   colIndex + 1}.zw);\n                 `;\n             }\n           }\n         }\n       }\n\n       // localize the dotProd accumulation within the loop, the theory is for\n       // GPU with limited cache, accumulate sum across large amount of\n       // veriables will cause lots of cache misses. (i.e. 5x5 filter will have\n       // 50 variables)\n       if (colIndex < filterWidth) {\n         mainLoop += `\n             wTexel = getW(r, ${colIndex}, d1, d2);\n             dotProd += xC${colIndex}.xxzz * vec4(wTexel.xy, wTexel.xy);\n             if(d1 + 1 < ${convInfo.inChannels}) {\n               dotProd += xC${colIndex}.yyww * vec4(wTexel.zw, wTexel.zw);\n             }\n           `;\n\n         if (colIndex + 1 < filterWidth) {\n           mainLoop += `\n               wTexel = getW(r, ${colIndex + 1}, d1, d2);\n               dotProd += xC${colIndex + 1}.xxzz * vec4(wTexel.xy, wTexel.xy);\n               if(d1 + 1 < ${convInfo.inChannels}) {\n                 dotProd += xC${colIndex + 1}.yyww * vec4(wTexel.zw, wTexel.zw);\n               }\n             `;\n         }\n       }\n     }\n     mainLoop += `\n     }\n   `;\n   mainLoop += `\n     }\n   `;\n   mainLoop += `\n     }\n   `;\n\n     let activationSnippet = '', applyActivationSnippet = '';\n     if (activation) {\n       if (hasPreluActivation) {\n         activationSnippet = `vec4 activation(vec4 a) {\n           vec4 b = getPreluActivationWeightsAtOutCoords();\n           ${activation}\n         }`;\n       } else if (hasLeakyReluAlpha) {\n         activationSnippet = `vec4 activation(vec4 a) {\n           vec4 b = getLeakyreluAlphaAtOutCoords();\n           ${activation}\n         }`;\n       } else {\n         activationSnippet = `vec4 activation(vec4 x) {\n           ${activation}\n         }`;\n       }\n\n       applyActivationSnippet = `result = activation(result);`;\n     }\n\n     const addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n     if (addBias) {\n       this.variableNames.push('bias');\n     }\n\n     if (hasPreluActivation) {\n       this.variableNames.push('preluActivationWeights');\n     }\n     if (hasLeakyReluAlpha) {\n       this.variableNames.push('leakyreluAlpha');\n     }\n\n     this.userCode = `\n       ${activationSnippet}\n\n       void main() {\n         ivec4 coords = getOutputCoords();\n         int batch = coords.x;\n         ivec2 xRCCorner = coords.yz * strides - pads;\n         int d2 = coords.w;\n         int xRCorner = xRCCorner.x;\n         int xCCorner = xRCCorner.y;\n\n         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n         vec4 dotProd = vec4(0.000000000000001);\n\n         ${mainLoop}\n\n         vec4 result = dotProd - vec4(0.000000000000001);\n         ${addBiasSnippet}\n         ${applyActivationSnippet}\n         setOutput(result);\n       }\n     `;\n   }\n }\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}