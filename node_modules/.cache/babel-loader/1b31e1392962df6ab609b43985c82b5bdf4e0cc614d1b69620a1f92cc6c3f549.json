{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { FusedBatchNorm, util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nexport function batchNorm(args) {\n  var inputs = args.inputs,\n    backend = args.backend,\n    attrs = args.attrs;\n  var x = inputs.x,\n    scale = inputs.scale,\n    offset = inputs.offset,\n    mean = inputs.mean,\n    variance = inputs.variance;\n  util.assert(mean.shape.length === variance.shape.length, function () {\n    return 'Batch normalization gradient requires mean and variance to have ' + 'equal ranks.';\n  });\n  util.assert(offset == null || mean.shape.length === offset.shape.length, function () {\n    return 'Batch normalization gradient requires mean and offset to have ' + 'equal ranks.';\n  });\n  util.assert(scale == null || mean.shape.length === scale.shape.length, function () {\n    return 'Batch normalization gradient requires mean and scale to have ' + 'equal ranks.';\n  });\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n  var varianceEpsilon = attrs.varianceEpsilon;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n  var xVals = backend.data.get(x.dataId).values;\n  var mVals = backend.data.get(mean.dataId).values;\n  var varVals = backend.data.get(variance.dataId).values;\n  var sVals = scale ? backend.data.get(scale.dataId).values : new Float32Array([1]);\n  var offVals = offset ? backend.data.get(offset.dataId).values : new Float32Array([0]);\n  var outVals = new Float32Array(xVals.length);\n  var offValsLength = offVals.length;\n  var sValsLength = sVals.length;\n  var varValsLength = varVals.length;\n  var mValsLength = mVals.length;\n  var offi = 0;\n  var mi = 0;\n  var si = 0;\n  var vi = 0;\n  for (var i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] + (xVals[i] - mVals[mi++]) * sVals[si++] / Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\nexport var batchNormConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNorm\n};","map":{"version":3,"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,cAAc,EAA+FC,IAAI,QAAO,uBAAuB;AAGvJ,SAAQC,gBAAgB,QAAO,aAAa;AAE5C,OAAM,SAAUC,SAAS,CAACC,IAIzB;EACC,IAAOC,MAAM,GAAoBD,IAAI,CAA9BC,MAAM;IAAEC,OAAO,GAAWF,IAAI,CAAtBE,OAAO;IAAEC,KAAK,GAAIH,IAAI,CAAbG,KAAK;EAC7B,IAAOC,CAAC,GAAmCH,MAAM,CAA1CG,CAAC;IAAEC,KAAK,GAA4BJ,MAAM,CAAvCI,KAAK;IAAEC,MAAM,GAAoBL,MAAM,CAAhCK,MAAM;IAAEC,IAAI,GAAcN,MAAM,CAAxBM,IAAI;IAAEC,QAAQ,GAAIP,MAAM,CAAlBO,QAAQ;EAEvCX,IAAI,CAACY,MAAM,CACPF,IAAI,CAACG,KAAK,CAACC,MAAM,KAAKH,QAAQ,CAACE,KAAK,CAACC,MAAM,EAC3C;IAAA,OAAM,kEAAkE,GACpE,cAAc;EAAA,EAAC;EACvBd,IAAI,CAACY,MAAM,CACPH,MAAM,IAAI,IAAI,IAAIC,IAAI,CAACG,KAAK,CAACC,MAAM,KAAKL,MAAM,CAACI,KAAK,CAACC,MAAM,EAC3D;IAAA,OAAM,gEAAgE,GAClE,cAAc;EAAA,EAAC;EACvBd,IAAI,CAACY,MAAM,CACPJ,KAAK,IAAI,IAAI,IAAIE,IAAI,CAACG,KAAK,CAACC,MAAM,KAAKN,KAAK,CAACK,KAAK,CAACC,MAAM,EACzD;IAAA,OAAM,+DAA+D,GACjE,cAAc;EAAA,EAAC;EAEvBb,gBAAgB,CAAC,CAACM,CAAC,EAAEG,IAAI,EAAEC,QAAQ,EAAEH,KAAK,EAAEC,MAAM,CAAC,EAAE,WAAW,CAAC;EAEjE,IAAKM,eAAe,GAAIT,KAAK,CAAxBS,eAAe;EACpB,IAAIA,eAAe,IAAI,IAAI,EAAE;IAC3BA,eAAe,GAAG,KAAK;;EAGzB,IAAMC,KAAK,GAAGX,OAAO,CAACY,IAAI,CAACC,GAAG,CAACX,CAAC,CAACY,MAAM,CAAC,CAACC,MAAoB;EAC7D,IAAMC,KAAK,GAAGhB,OAAO,CAACY,IAAI,CAACC,GAAG,CAACR,IAAI,CAACS,MAAM,CAAC,CAACC,MAAoB;EAChE,IAAME,OAAO,GAAGjB,OAAO,CAACY,IAAI,CAACC,GAAG,CAACP,QAAQ,CAACQ,MAAM,CAAC,CAACC,MAAoB;EACtE,IAAMG,KAAK,GAAGf,KAAK,GAAGH,OAAO,CAACY,IAAI,CAACC,GAAG,CAACV,KAAK,CAACW,MAAM,CAAC,CAACC,MAAoB,GACnD,IAAII,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;EAC3C,IAAMC,OAAO,GAAGhB,MAAM,GAClBJ,OAAO,CAACY,IAAI,CAACC,GAAG,CAACT,MAAM,CAACU,MAAM,CAAC,CAACC,MAAoB,GACpD,IAAII,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;EACzB,IAAME,OAAO,GAAG,IAAIF,YAAY,CAACR,KAAK,CAACF,MAAM,CAAC;EAE9C,IAAMa,aAAa,GAAGF,OAAO,CAACX,MAAM;EACpC,IAAMc,WAAW,GAAGL,KAAK,CAACT,MAAM;EAChC,IAAMe,aAAa,GAAGP,OAAO,CAACR,MAAM;EACpC,IAAMgB,WAAW,GAAGT,KAAK,CAACP,MAAM;EAEhC,IAAIiB,IAAI,GAAG,CAAC;EACZ,IAAIC,EAAE,GAAG,CAAC;EACV,IAAIC,EAAE,GAAG,CAAC;EACV,IAAIC,EAAE,GAAG,CAAC;EACV,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGnB,KAAK,CAACF,MAAM,EAAE,EAAEqB,CAAC,EAAE;IACrCT,OAAO,CAACS,CAAC,CAAC,GAAGV,OAAO,CAACM,IAAI,EAAE,CAAC,GACxB,CAACf,KAAK,CAACmB,CAAC,CAAC,GAAGd,KAAK,CAACW,EAAE,EAAE,CAAC,IAAIT,KAAK,CAACU,EAAE,EAAE,CAAC,GAClCG,IAAI,CAACC,IAAI,CAACf,OAAO,CAACY,EAAE,EAAE,CAAC,GAAGnB,eAAe,CAAC;IAClD,IAAIgB,IAAI,IAAIJ,aAAa,EAAE;MACzBI,IAAI,GAAG,CAAC;;IAEV,IAAIC,EAAE,IAAIF,WAAW,EAAE;MACrBE,EAAE,GAAG,CAAC;;IAER,IAAIC,EAAE,IAAIL,WAAW,EAAE;MACrBK,EAAE,GAAG,CAAC;;IAER,IAAIC,EAAE,IAAIL,aAAa,EAAE;MACvBK,EAAE,GAAG,CAAC;;;EAGV,OAAO7B,OAAO,CAACiC,cAAc,CAAC/B,CAAC,CAACM,KAAK,EAAEN,CAAC,CAACgC,KAAK,EAAEb,OAAO,CAAC;AAC1D;AAEA,OAAO,IAAMc,eAAe,GAAiB;EAC3CC,UAAU,EAAE1C,cAAc;EAC1B2C,WAAW,EAAE,KAAK;EAClBC,UAAU,EAAEzC;CACb","names":["FusedBatchNorm","util","assertNotComplex","batchNorm","args","inputs","backend","attrs","x","scale","offset","mean","variance","assert","shape","length","varianceEpsilon","xVals","data","get","dataId","values","mVals","varVals","sVals","Float32Array","offVals","outVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","i","Math","sqrt","makeTensorInfo","dtype","batchNormConfig","kernelName","backendName","kernelFunc"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\node_modules\\@tensorflow\\tfjs-backend-cpu\\src\\kernels\\BatchNorm.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function batchNorm(args: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendCPU,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, scale, offset, mean, variance} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const mVals = backend.data.get(mean.dataId).values as TypedArray;\n  const varVals = backend.data.get(variance.dataId).values as TypedArray;\n  const sVals = scale ? backend.data.get(scale.dataId).values as TypedArray :\n                        new Float32Array([1]);\n  const offVals = offset ?\n      backend.data.get(offset.dataId).values as TypedArray :\n      new Float32Array([0]);\n  const outVals = new Float32Array(xVals.length);\n\n  const offValsLength = offVals.length;\n  const sValsLength = sVals.length;\n  const varValsLength = varVals.length;\n  const mValsLength = mVals.length;\n\n  let offi = 0;\n  let mi = 0;\n  let si = 0;\n  let vi = 0;\n  for (let i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] +\n        (xVals[i] - mVals[mi++]) * sVals[si++] /\n            Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNorm as unknown as KernelFunc,\n};\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}