{"ast":null,"code":"import _regeneratorRuntime from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _classCallCheck from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport { env } from '@tensorflow/tfjs-core';\nimport { LazyIterator, OneToManyIterator } from './lazy_iterator';\nimport { StringIterator } from './string_iterator';\nexport var ByteChunkIterator = /*#__PURE__*/function (_LazyIterator) {\n  _inherits(ByteChunkIterator, _LazyIterator);\n  var _super = _createSuper(ByteChunkIterator);\n  function ByteChunkIterator() {\n    _classCallCheck(this, ByteChunkIterator);\n    return _super.apply(this, arguments);\n  }\n  _createClass(ByteChunkIterator, [{\n    key: \"decodeUTF8\",\n    value:\n    /**\n     * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n     *\n     * The byte arrays producetd from the ByteChunkIterator on which this is\n     * called will be interpreted as concatenated.  No assumptions are made about\n     * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n     * character may span the boundary between chunks.  This naturally happens,\n     * for instance, when reading fixed-size byte arrays from a file.\n     */\n    function decodeUTF8() {\n      return new Utf8Iterator(this);\n    }\n  }]);\n  return ByteChunkIterator;\n}(LazyIterator);\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\nvar Utf8Iterator = /*#__PURE__*/function (_StringIterator) {\n  _inherits(Utf8Iterator, _StringIterator);\n  var _super2 = _createSuper(Utf8Iterator);\n  function Utf8Iterator(upstream) {\n    var _this;\n    _classCallCheck(this, Utf8Iterator);\n    _this = _super2.call(this);\n    _this.upstream = upstream;\n    _this.impl = new Utf8IteratorImpl(upstream);\n    return _this;\n  }\n  _createClass(Utf8Iterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return this.impl.summary();\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              return _context.abrupt(\"return\", this.impl.next());\n            case 1:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function next() {\n        return _next.apply(this, arguments);\n      }\n      return next;\n    }()\n  }]);\n  return Utf8Iterator;\n}(StringIterator);\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\nvar Utf8IteratorImpl = /*#__PURE__*/function (_OneToManyIterator) {\n  _inherits(Utf8IteratorImpl, _OneToManyIterator);\n  var _super3 = _createSuper(Utf8IteratorImpl);\n  function Utf8IteratorImpl(upstream) {\n    var _this2;\n    _classCallCheck(this, Utf8IteratorImpl);\n    _this2 = _super3.call(this);\n    _this2.upstream = upstream;\n    if (env().get('IS_BROWSER')) {\n      _this2.decoder = new TextDecoder('utf-8');\n    } else {\n      // tslint:disable-next-line:no-require-imports\n      var _require = require('string_decoder'),\n        StringDecoder = _require.StringDecoder;\n      _this2.decoder = new StringDecoder('utf8');\n    }\n    return _this2;\n  }\n  _createClass(Utf8IteratorImpl, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Utf8\");\n    }\n  }, {\n    key: \"pump\",\n    value: function () {\n      var _pump = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2() {\n        var chunkResult, chunk, text;\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) switch (_context2.prev = _context2.next) {\n            case 0:\n              _context2.next = 2;\n              return this.upstream.next();\n            case 2:\n              chunkResult = _context2.sent;\n              if (!chunkResult.done) {\n                _context2.next = 7;\n                break;\n              }\n              return _context2.abrupt(\"return\", false);\n            case 7:\n              chunk = chunkResult.value;\n            case 8:\n              if (env().get('IS_BROWSER')) {\n                text = this.decoder.decode(chunk, {\n                  stream: true\n                });\n              } else {\n                text = this.decoder.write(Buffer.from(chunk.buffer));\n              }\n              this.outputQueue.push(text);\n              return _context2.abrupt(\"return\", true);\n            case 11:\n            case \"end\":\n              return _context2.stop();\n          }\n        }, _callee2, this);\n      }));\n      function pump() {\n        return _pump.apply(this, arguments);\n      }\n      return pump;\n    }()\n  }]);\n  return Utf8IteratorImpl;\n}(OneToManyIterator);","map":{"version":3,"mappings":";;;;;;AAAA;;;;;;;;;;;;;;;;;AAkBA,SAAQA,GAAG,QAAO,uBAAuB;AACzC,SAAQC,YAAY,EAAEC,iBAAiB,QAAO,iBAAiB;AAC/D,SAAQC,cAAc,QAAO,mBAAmB;AAEhD,WAAsBC,iBAAkB;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA;IACtC;;;;;;;;;IASA,sBAAU;MACR,OAAO,IAAIC,YAAY,CAAC,IAAI,CAAC;IAC/B;EAAC;EAAA;AAAA,EAZ6CJ,YAAwB;AAexE;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA,IAEMI,YAAa;EAAA;EAAA;EAGjB,sBAAsBC,QAAkC;IAAA;IAAA;IACtD;IADoB,cAAQ,GAARA,QAAQ;IAE5B,MAAKC,IAAI,GAAG,IAAIC,gBAAgB,CAACF,QAAQ,CAAC;IAAC;EAC7C;EAAC;IAAA;IAAA,OAED,mBAAO;MACL,OAAO,IAAI,CAACC,IAAI,CAACE,OAAO,EAAE;IAC5B;EAAC;IAAA;IAAA;MAAA,uEAED;QAAA;UAAA;YAAA;cAAA,iCACS,IAAI,CAACF,IAAI,CAACG,IAAI,EAAE;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA,CACxB;MAAA;QAAA;MAAA;MAAA;IAAA;EAAA;EAAA;AAAA,EAdwBP,cAAc;AAiBzC;;;;;;;;;;;;;;;;;;;;;;AAAA,IAsBMK,gBAAiB;EAAA;EAAA;EAMrB,0BAA+BF,QAAkC;IAAA;IAAA;IAC/D;IAD6B,eAAQ,GAARA,QAAQ;IAErC,IAAIN,GAAG,EAAE,CAACW,GAAG,CAAC,YAAY,CAAC,EAAE;MAC3B,OAAKC,OAAO,GAAG,IAAIC,WAAW,CAAC,OAAO,CAAC;KACxC,MAAM;MACL;MACA,eAAwBC,OAAO,CAAC,gBAAgB,CAAC;QAA1CC,aAAa,YAAbA,aAAa;MACpB,OAAKH,OAAO,GAAG,IAAIG,aAAa,CAAC,MAAM,CAAC;;IACzC;EACH;EAAC;IAAA;IAAA,OACD,mBAAO;MACL,iBAAU,IAAI,CAACT,QAAQ,CAACG,OAAO,EAAE;IACnC;EAAC;IAAA;IAAA;MAAA,uEAED;QAAA;QAAA;UAAA;YAAA;cAAA;cAAA,OAC4B,IAAI,CAACH,QAAQ,CAACI,IAAI,EAAE;YAAA;cAAxCM,WAAW;cAAA,KAEbA,WAAW,CAACC,IAAI;gBAAA;gBAAA;cAAA;cAAA,kCACX,KAAK;YAAA;cAEZC,KAAK,GAAGF,WAAW,CAACG,KAAK;YAAC;cAI5B,IAAInB,GAAG,EAAE,CAACW,GAAG,CAAC,YAAY,CAAC,EAAE;gBAC3BS,IAAI,GAAG,IAAI,CAACR,OAAO,CAACS,MAAM,CAACH,KAAK,EAAE;kBAACI,MAAM,EAAE;gBAAI,CAAC,CAAC;eAClD,MAAM;gBACLF,IAAI,GAAG,IAAI,CAACR,OAAO,CAACW,KAAK,CAACC,MAAM,CAACC,IAAI,CAACP,KAAK,CAACQ,MAAM,CAAC,CAAC;;cAEtD,IAAI,CAACC,WAAW,CAACC,IAAI,CAACR,IAAI,CAAC;cAAC,kCACrB,IAAI;YAAA;YAAA;cAAA;UAAA;QAAA;MAAA,CACZ;MAAA;QAAA;MAAA;MAAA;IAAA;EAAA;EAAA;AAAA,EArC4BlB,iBAAyB","names":["env","LazyIterator","OneToManyIterator","StringIterator","ByteChunkIterator","Utf8Iterator","upstream","impl","Utf8IteratorImpl","summary","next","get","decoder","TextDecoder","require","StringDecoder","chunkResult","done","chunk","value","text","decode","stream","write","Buffer","from","buffer","outputQueue","push"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\node_modules\\@tensorflow\\tfjs-data\\src\\iterators\\byte_chunk_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\nimport {LazyIterator, OneToManyIterator} from './lazy_iterator';\nimport {StringIterator} from './string_iterator';\n\nexport abstract class ByteChunkIterator extends LazyIterator<Uint8Array> {\n  /**\n   * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n   *\n   * The byte arrays producetd from the ByteChunkIterator on which this is\n   * called will be interpreted as concatenated.  No assumptions are made about\n   * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n   * character may span the boundary between chunks.  This naturally happens,\n   * for instance, when reading fixed-size byte arrays from a file.\n   */\n  decodeUTF8(): StringIterator {\n    return new Utf8Iterator(this);\n  }\n}\n\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\n\nclass Utf8Iterator extends StringIterator {\n  private impl: Utf8IteratorImpl;\n\n  constructor(protected upstream: LazyIterator<Uint8Array>) {\n    super();\n    this.impl = new Utf8IteratorImpl(upstream);\n  }\n\n  summary() {\n    return this.impl.summary();\n  }\n\n  async next() {\n    return this.impl.next();\n  }\n}\n\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\nclass Utf8IteratorImpl extends OneToManyIterator<string> {\n  // `decoder` as `any` here to dynamically assign value based on the\n  // environment.\n  // tslint:disable-next-line:no-any\n  decoder: any;\n\n  constructor(protected readonly upstream: LazyIterator<Uint8Array>) {\n    super();\n    if (env().get('IS_BROWSER')) {\n      this.decoder = new TextDecoder('utf-8');\n    } else {\n      // tslint:disable-next-line:no-require-imports\n      const {StringDecoder} = require('string_decoder');\n      this.decoder = new StringDecoder('utf8');\n    }\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Utf8`;\n  }\n\n  async pump(): Promise<boolean> {\n    const chunkResult = await this.upstream.next();\n    let chunk;\n    if (chunkResult.done) {\n      return false;\n    } else {\n      chunk = chunkResult.value;\n    }\n\n    let text: string;\n    if (env().get('IS_BROWSER')) {\n      text = this.decoder.decode(chunk, {stream: true});\n    } else {\n      text = this.decoder.write(Buffer.from(chunk.buffer));\n    }\n    this.outputQueue.push(text);\n    return true;\n  }\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}