{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Optimizers.\n */\nimport { train } from '@tensorflow/tfjs-core';\nimport { epsilon } from './backend/common';\nimport { ValueError } from './errors';\n// Add (de)serialize()\n// Porting note: This diverges from the PyKeras implementation and may need to\n// change based on (de)serialization requirements.\nexport function getOptimizer(identifier) {\n  var optimizerMap = {\n    'Adagrad': function Adagrad() {\n      return train.adagrad(0.01);\n    },\n    'Adadelta': function Adadelta() {\n      return train.adadelta(1, 0.95, epsilon());\n    },\n    'Adam': function Adam() {\n      return train.adam(0.001, 0.9, 0.999, epsilon());\n    },\n    'Adamax': function Adamax() {\n      return train.adamax(0.002, 0.9, 0.999, epsilon(), 0);\n    },\n    'RMSProp': function RMSProp() {\n      return train.rmsprop(0.001, 0.9, 0, epsilon());\n    },\n    'SGD': function SGD() {\n      return train.sgd(0.01);\n    }\n  };\n  optimizerMap['adagrad'] = optimizerMap['Adagrad'];\n  optimizerMap['adadelta'] = optimizerMap['Adadelta'];\n  optimizerMap['adam'] = optimizerMap['Adam'];\n  optimizerMap['adamax'] = optimizerMap['Adamax'];\n  optimizerMap['rmsprop'] = optimizerMap['RMSProp'];\n  optimizerMap['sgd'] = optimizerMap['SGD'];\n  if (identifier in optimizerMap) {\n    return optimizerMap[identifier]();\n  }\n  throw new ValueError(\"Unknown Optimizer \".concat(identifier));\n}","map":{"version":3,"mappings":"AAAA;;;;;;;;;AAUA;;;AAIA,SAAmBA,KAAK,QAAO,uBAAuB;AAEtD,SAAQC,OAAO,QAAO,kBAAkB;AAExC,SAAQC,UAAU,QAAO,UAAU;AAEnC;AAEA;AACA;AACA,OAAM,SAAUC,YAAY,CAACC,UAAkB;EAC7C,IAAMC,YAAY,GAA+C;IAC/D,SAAS,EAAE;MAAA,OAAML,KAAK,CAACM,OAAO,CAAC,IAAI,CAAC;IAAA;IACpC,UAAU,EAAE;MAAA,OAAMN,KAAK,CAACO,QAAQ,CAAC,CAAC,EAAE,IAAI,EAAEN,OAAO,EAAE,CAAC;IAAA;IACpD,MAAM,EAAE;MAAA,OAAMD,KAAK,CAACQ,IAAI,CAAC,KAAK,EAAE,GAAG,EAAE,KAAK,EAAEP,OAAO,EAAE,CAAC;IAAA;IACtD,QAAQ,EAAE;MAAA,OAAMD,KAAK,CAACS,MAAM,CAAC,KAAK,EAAE,GAAG,EAAE,KAAK,EAAER,OAAO,EAAE,EAAE,CAAC,CAAC;IAAA;IAC7D,SAAS,EAAE;MAAA,OAAMD,KAAK,CAACU,OAAO,CAAC,KAAK,EAAE,GAAG,EAAE,CAAC,EAAET,OAAO,EAAE,CAAC;IAAA;IACxD,KAAK,EAAE;MAAA,OAAMD,KAAK,CAACW,GAAG,CAAC,IAAI,CAAC;IAAA;GAC7B;EACDN,YAAY,CAAC,SAAS,CAAC,GAAGA,YAAY,CAAC,SAAS,CAAC;EACjDA,YAAY,CAAC,UAAU,CAAC,GAAGA,YAAY,CAAC,UAAU,CAAC;EACnDA,YAAY,CAAC,MAAM,CAAC,GAAGA,YAAY,CAAC,MAAM,CAAC;EAC3CA,YAAY,CAAC,QAAQ,CAAC,GAAGA,YAAY,CAAC,QAAQ,CAAC;EAC/CA,YAAY,CAAC,SAAS,CAAC,GAAGA,YAAY,CAAC,SAAS,CAAC;EACjDA,YAAY,CAAC,KAAK,CAAC,GAAGA,YAAY,CAAC,KAAK,CAAC;EAEzC,IAAID,UAAU,IAAIC,YAAY,EAAE;IAC9B,OAAOA,YAAY,CAACD,UAAU,CAAC,EAAE;;EAEnC,MAAM,IAAIF,UAAU,6BAAsBE,UAAU,EAAG;AACzD","names":["train","epsilon","ValueError","getOptimizer","identifier","optimizerMap","adagrad","adadelta","adam","adamax","rmsprop","sgd"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\Toxic-Word-Checker\\node_modules\\@tensorflow\\tfjs-layers\\src\\optimizers.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Optimizers.\n */\n\nimport {Optimizer, train} from '@tensorflow/tfjs-core';\n\nimport {epsilon} from './backend/common';\n\nimport {ValueError} from './errors';\n\n// Add (de)serialize()\n\n// Porting note: This diverges from the PyKeras implementation and may need to\n// change based on (de)serialization requirements.\nexport function getOptimizer(identifier: string): Optimizer {\n  const optimizerMap: {[optimizerName: string]: () => Optimizer} = {\n    'Adagrad': () => train.adagrad(0.01),\n    'Adadelta': () => train.adadelta(1, 0.95, epsilon()),\n    'Adam': () => train.adam(0.001, 0.9, 0.999, epsilon()),\n    'Adamax': () => train.adamax(0.002, 0.9, 0.999, epsilon(), 0),\n    'RMSProp': () => train.rmsprop(0.001, 0.9, 0, epsilon()),\n    'SGD': () => train.sgd(0.01)\n  };\n  optimizerMap['adagrad'] = optimizerMap['Adagrad'];\n  optimizerMap['adadelta'] = optimizerMap['Adadelta'];\n  optimizerMap['adam'] = optimizerMap['Adam'];\n  optimizerMap['adamax'] = optimizerMap['Adamax'];\n  optimizerMap['rmsprop'] = optimizerMap['RMSProp'];\n  optimizerMap['sgd'] = optimizerMap['SGD'];\n\n  if (identifier in optimizerMap) {\n    return optimizerMap[identifier]();\n  }\n  throw new ValueError(`Unknown Optimizer ${identifier}`);\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}