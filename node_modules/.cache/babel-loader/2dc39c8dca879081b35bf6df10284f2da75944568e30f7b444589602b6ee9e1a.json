{"ast":null,"code":"import _regeneratorRuntime from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport _classCallCheck from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original source: keras/callbacks.py */\nimport { BaseCallback } from './base_callbacks';\nimport { LayersModel } from './engine/training';\nimport { NotImplementedError } from './errors';\nimport { resolveScalarsInLogs } from './logs';\nexport var Callback = /*#__PURE__*/function (_BaseCallback) {\n  _inherits(Callback, _BaseCallback);\n  var _super = _createSuper(Callback);\n  function Callback() {\n    var _this;\n    _classCallCheck(this, Callback);\n    _this = _super.apply(this, arguments);\n    /** Instance of `keras.models.Model`. Reference of the model being trained. */\n    _this.model = null;\n    return _this;\n  }\n  _createClass(Callback, [{\n    key: \"setModel\",\n    value: function setModel(model) {\n      if (!(model instanceof LayersModel)) {\n        throw new Error('model must be a LayersModel, not some other Container');\n      }\n      this.model = model;\n    }\n  }]);\n  return Callback;\n}(BaseCallback);\nfunction less(currVal, prevVal) {\n  return currVal < prevVal;\n}\nfunction greater(currVal, prevVal) {\n  return currVal > prevVal;\n}\n/**\n * A Callback that stops training when a monitored quantity has stopped\n * improving.\n */\nexport var EarlyStopping = /*#__PURE__*/function (_Callback) {\n  _inherits(EarlyStopping, _Callback);\n  var _super2 = _createSuper(EarlyStopping);\n  function EarlyStopping(args) {\n    var _this2;\n    _classCallCheck(this, EarlyStopping);\n    _this2 = _super2.call(this);\n    if (args == null) {\n      args = {};\n    }\n    if (args.restoreBestWeights) {\n      throw new NotImplementedError('restoreBestWeights = True is not implemented in EarlyStopping yet.');\n    }\n    _this2.monitor = args.monitor || 'val_loss';\n    _this2.minDelta = Math.abs(args.minDelta || 0);\n    _this2.patience = args.patience || 0;\n    _this2.verbose = args.verbose || 0;\n    _this2.mode = args.mode || 'auto';\n    _this2.baseline = args.baseline;\n    if (['auto', 'min', 'max'].indexOf(_this2.mode) === -1) {\n      console.warn(\"EarlyStopping mode '\".concat(_this2.mode, \"' is invalid. \") + \"Falling back to mode 'auto'.\");\n      _this2.mode = 'auto';\n    }\n    if (_this2.mode === 'min') {\n      _this2.monitorFunc = less;\n    } else if (_this2.mode === 'max') {\n      _this2.monitorFunc = greater;\n    } else {\n      // For mode === 'auto'.\n      if (_this2.monitor.indexOf('acc') !== -1) {\n        _this2.monitorFunc = greater;\n      } else {\n        _this2.monitorFunc = less;\n      }\n    }\n    if (_this2.monitorFunc === less) {\n      _this2.minDelta *= -1;\n    }\n    return _this2;\n  }\n  _createClass(EarlyStopping, [{\n    key: \"onTrainBegin\",\n    value: function () {\n      var _onTrainBegin = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(logs) {\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              this.wait = 0;\n              this.stoppedEpoch = 0;\n              if (this.baseline != null) {\n                this.best = this.baseline;\n              } else {\n                this.best = this.monitorFunc === less ? Infinity : -Infinity;\n              }\n            case 3:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function onTrainBegin(_x) {\n        return _onTrainBegin.apply(this, arguments);\n      }\n      return onTrainBegin;\n    }()\n  }, {\n    key: \"onEpochEnd\",\n    value: function () {\n      var _onEpochEnd = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(epoch, logs) {\n        var current;\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) switch (_context2.prev = _context2.next) {\n            case 0:\n              _context2.next = 2;\n              return resolveScalarsInLogs(logs);\n            case 2:\n              current = this.getMonitorValue(logs);\n              if (!(current == null)) {\n                _context2.next = 5;\n                break;\n              }\n              return _context2.abrupt(\"return\");\n            case 5:\n              if (this.monitorFunc(current - this.minDelta, this.best)) {\n                this.best = current;\n                this.wait = 0;\n                // TODO(cais): Logic for restoreBestWeights.\n              } else {\n                this.wait++;\n                if (this.wait >= this.patience) {\n                  this.stoppedEpoch = epoch;\n                  this.model.stopTraining = true;\n                }\n                // TODO(cais): Logic for restoreBestWeights.\n              }\n            case 6:\n            case \"end\":\n              return _context2.stop();\n          }\n        }, _callee2, this);\n      }));\n      function onEpochEnd(_x2, _x3) {\n        return _onEpochEnd.apply(this, arguments);\n      }\n      return onEpochEnd;\n    }()\n  }, {\n    key: \"onTrainEnd\",\n    value: function () {\n      var _onTrainEnd = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(logs) {\n        return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n          while (1) switch (_context3.prev = _context3.next) {\n            case 0:\n              if (this.stoppedEpoch > 0 && this.verbose) {\n                console.log(\"Epoch \".concat(this.stoppedEpoch, \": early stopping.\"));\n              }\n            case 1:\n            case \"end\":\n              return _context3.stop();\n          }\n        }, _callee3, this);\n      }));\n      function onTrainEnd(_x4) {\n        return _onTrainEnd.apply(this, arguments);\n      }\n      return onTrainEnd;\n    }()\n  }, {\n    key: \"getMonitorValue\",\n    value: function getMonitorValue(logs) {\n      if (logs == null) {\n        logs = {};\n      }\n      var monitorValue = logs[this.monitor];\n      if (monitorValue == null) {\n        console.warn(\"Metric for EarlyStopping \".concat(this.monitor, \" is not available. \") + \"Available metrics are: \".concat(Object.keys(logs)));\n      }\n      return monitorValue;\n    }\n  }]);\n  return EarlyStopping;\n}(Callback);\n/**\n * Factory function for a Callback that stops training when a monitored\n * quantity has stopped improving.\n *\n * Early stopping is a type of regularization, and protects model against\n * overfitting.\n *\n * The following example based on fake data illustrates how this callback\n * can be used during `tf.LayersModel.fit()`:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense({\n *   units: 3,\n *   activation: 'softmax',\n *   kernelInitializer: 'ones',\n *   inputShape: [2]\n * }));\n * const xs = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const ys = tf.tensor2d([[1, 0, 0], [0, 1, 0]], [2, 3]);\n * const xsVal = tf.tensor2d([4, 3, 2, 1], [2, 2]);\n * const ysVal = tf.tensor2d([[0, 0, 1], [0, 1, 0]], [2, 3]);\n * model.compile(\n *     {loss: 'categoricalCrossentropy', optimizer: 'sgd', metrics: ['acc']});\n *\n * // Without the EarlyStopping callback, the val_acc value would be:\n * //   0.5, 0.5, 0.5, 0.5, ...\n * // With val_acc being monitored, training should stop after the 2nd epoch.\n * const history = await model.fit(xs, ys, {\n *   epochs: 10,\n *   validationData: [xsVal, ysVal],\n *   callbacks: tf.callbacks.earlyStopping({monitor: 'val_acc'})\n * });\n *\n * // Expect to see a length-2 array.\n * console.log(history.history.val_acc);\n * ```\n *\n * @doc {\n *   heading: 'Callbacks',\n *   namespace: 'callbacks'\n * }\n */\nexport function earlyStopping(args) {\n  return new EarlyStopping(args);\n}\nexport var callbacks = {\n  earlyStopping: earlyStopping\n};","map":{"version":3,"mappings":";;;;;;AAAA;;;;;;;;;AAUA;AAEA,SAAQA,YAAY,QAAO,kBAAkB;AAE7C,SAAQC,WAAW,QAAO,mBAAmB;AAC7C,SAAQC,mBAAmB,QAAO,UAAU;AAC5C,SAAcC,oBAAoB,QAAO,QAAQ;AAEjD,WAAsBC,QAAS;EAAA;EAAA;EAA/B;IAAA;IAAA;;IACE;IACA,WAAK,GAAgB,IAAI;IAAC;EAQ5B;EAAC;IAAA;IAAA,OANU,kBAASC,KAAgB;MAChC,IAAI,EAAEA,KAAK,YAAYJ,WAAW,CAAC,EAAE;QACnC,MAAM,IAAIK,KAAK,CAAC,uDAAuD,CAAC;;MAE1E,IAAI,CAACD,KAAK,GAAGA,KAAK;IACpB;EAAC;EAAA;AAAA,EAToCL,YAAY;AAsEnD,SAASO,IAAI,CAACC,OAAe,EAAEC,OAAe;EAC5C,OAAOD,OAAO,GAAGC,OAAO;AAC1B;AAEA,SAASC,OAAO,CAACF,OAAe,EAAEC,OAAe;EAC/C,OAAOD,OAAO,GAAGC,OAAO;AAC1B;AAEA;;;;AAIA,WAAaE,aAAc;EAAA;EAAA;EAczB,uBAAYC,IAAgC;IAAA;IAAA;IAC1C;IACA,IAAIA,IAAI,IAAI,IAAI,EAAE;MAChBA,IAAI,GAAG,EAAE;;IAEX,IAAIA,IAAI,CAACC,kBAAkB,EAAE;MAC3B,MAAM,IAAIX,mBAAmB,CACzB,oEAAoE,CAAC;;IAG3E,OAAKY,OAAO,GAAGF,IAAI,CAACE,OAAO,IAAI,UAAU;IACzC,OAAKC,QAAQ,GAAGC,IAAI,CAACC,GAAG,CAACL,IAAI,CAACG,QAAQ,IAAI,CAAC,CAAC;IAC5C,OAAKG,QAAQ,GAAGN,IAAI,CAACM,QAAQ,IAAI,CAAC;IAClC,OAAKC,OAAO,GAAGP,IAAI,CAACO,OAAO,IAAI,CAAC;IAChC,OAAKC,IAAI,GAAGR,IAAI,CAACQ,IAAI,IAAI,MAAM;IAC/B,OAAKC,QAAQ,GAAGT,IAAI,CAACS,QAAQ;IAE7B,IAAI,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,CAACC,OAAO,CAAC,OAAKF,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;MACpDG,OAAO,CAACC,IAAI,CACR,8BAAuB,OAAKJ,IAAI,oDACF,CAAC;MACnC,OAAKA,IAAI,GAAG,MAAM;;IAGpB,IAAI,OAAKA,IAAI,KAAK,KAAK,EAAE;MACvB,OAAKK,WAAW,GAAGlB,IAAI;KACxB,MAAM,IAAI,OAAKa,IAAI,KAAK,KAAK,EAAE;MAC9B,OAAKK,WAAW,GAAGf,OAAO;KAC3B,MAAM;MACL;MACA,IAAI,OAAKI,OAAO,CAACQ,OAAO,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE;QACtC,OAAKG,WAAW,GAAGf,OAAO;OAC3B,MAAM;QACL,OAAKe,WAAW,GAAGlB,IAAI;;;IAI3B,IAAI,OAAKkB,WAAW,KAAKlB,IAAI,EAAE;MAC7B,OAAKQ,QAAQ,IAAI,CAAC,CAAC;;IACpB;EACH;EAAC;IAAA;IAAA;MAAA,+EAEQ,iBAAmBW,IAAW;QAAA;UAAA;YAAA;cACrC,IAAI,CAACC,IAAI,GAAG,CAAC;cACb,IAAI,CAACC,YAAY,GAAG,CAAC;cACrB,IAAI,IAAI,CAACP,QAAQ,IAAI,IAAI,EAAE;gBACzB,IAAI,CAACQ,IAAI,GAAG,IAAI,CAACR,QAAQ;eAC1B,MAAM;gBACL,IAAI,CAACQ,IAAI,GAAG,IAAI,CAACJ,WAAW,KAAKlB,IAAI,GAAGuB,QAAQ,GAAG,CAACA,QAAQ;;YAC7D;YAAA;cAAA;UAAA;QAAA;MAAA,CACF;MAAA;QAAA;MAAA;MAAA;IAAA;EAAA;IAAA;IAAA;MAAA,6EAEQ,kBAAiBC,KAAa,EAAEL,IAAW;QAAA;QAAA;UAAA;YAAA;cAAA;cAAA,OAC5CvB,oBAAoB,CAACuB,IAAI,CAAC;YAAA;cAC1BM,OAAO,GAAG,IAAI,CAACC,eAAe,CAACP,IAAI,CAAC;cAAA,MACtCM,OAAO,IAAI,IAAI;gBAAA;gBAAA;cAAA;cAAA;YAAA;cAInB,IAAI,IAAI,CAACP,WAAW,CAACO,OAAO,GAAG,IAAI,CAACjB,QAAQ,EAAE,IAAI,CAACc,IAAI,CAAC,EAAE;gBACxD,IAAI,CAACA,IAAI,GAAGG,OAAO;gBACnB,IAAI,CAACL,IAAI,GAAG,CAAC;gBACb;eACD,MAAM;gBACL,IAAI,CAACA,IAAI,EAAE;gBACX,IAAI,IAAI,CAACA,IAAI,IAAI,IAAI,CAACT,QAAQ,EAAE;kBAC9B,IAAI,CAACU,YAAY,GAAGG,KAAK;kBACzB,IAAI,CAAC1B,KAAK,CAAC6B,YAAY,GAAG,IAAI;;gBAEhC;;YACD;YAAA;cAAA;UAAA;QAAA;MAAA,CACF;MAAA;QAAA;MAAA;MAAA;IAAA;EAAA;IAAA;IAAA;MAAA,6EAEQ,kBAAiBR,IAAW;QAAA;UAAA;YAAA;cACnC,IAAI,IAAI,CAACE,YAAY,GAAG,CAAC,IAAI,IAAI,CAACT,OAAO,EAAE;gBACzCI,OAAO,CAACY,GAAG,iBAAU,IAAI,CAACP,YAAY,uBAAoB;;YAC3D;YAAA;cAAA;UAAA;QAAA;MAAA,CACF;MAAA;QAAA;MAAA;MAAA;IAAA;EAAA;IAAA;IAAA,OAEO,yBAAgBF,IAAU;MAChC,IAAIA,IAAI,IAAI,IAAI,EAAE;QAChBA,IAAI,GAAG,EAAE;;MAEX,IAAMU,YAAY,GAAGV,IAAI,CAAC,IAAI,CAACZ,OAAO,CAAC;MACvC,IAAIsB,YAAY,IAAI,IAAI,EAAE;QACxBb,OAAO,CAACC,IAAI,CACR,mCAA4B,IAAI,CAACV,OAAO,4DACduB,MAAM,CAACC,IAAI,CAACZ,IAAI,CAAC,CAAE,CAAC;;MAEpD,OAAOU,YAAY;IACrB;EAAC;EAAA;AAAA,EAxGgChC,QAAQ;AA2G3C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2CA,OAAM,SAAUmC,aAAa,CAAC3B,IAAgC;EAC5D,OAAO,IAAID,aAAa,CAACC,IAAI,CAAC;AAChC;AAEA,OAAO,IAAM4B,SAAS,GAAG;EAACD,aAAa,EAAbA;AAAa,CAAC","names":["BaseCallback","LayersModel","NotImplementedError","resolveScalarsInLogs","Callback","model","Error","less","currVal","prevVal","greater","EarlyStopping","args","restoreBestWeights","monitor","minDelta","Math","abs","patience","verbose","mode","baseline","indexOf","console","warn","monitorFunc","logs","wait","stoppedEpoch","best","Infinity","epoch","current","getMonitorValue","stopTraining","log","monitorValue","Object","keys","earlyStopping","callbacks"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\Toxic-Word-Checker\\node_modules\\@tensorflow\\tfjs-layers\\src\\callbacks.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original source: keras/callbacks.py */\n\nimport {BaseCallback} from './base_callbacks';\nimport {Container} from './engine/container';\nimport {LayersModel} from './engine/training';\nimport {NotImplementedError} from './errors';\nimport {Logs, resolveScalarsInLogs} from './logs';\n\nexport abstract class Callback extends BaseCallback {\n  /** Instance of `keras.models.Model`. Reference of the model being trained. */\n  model: LayersModel = null;\n\n  override setModel(model: Container): void {\n    if (!(model instanceof LayersModel)) {\n      throw new Error('model must be a LayersModel, not some other Container');\n    }\n    this.model = model;\n  }\n}\n\nexport interface EarlyStoppingCallbackArgs {\n  /**\n   * Quantity to be monitored.\n   *\n   * Defaults to 'val_loss'.\n   */\n  monitor?: string;\n\n  /**\n   * Minimum change in the monitored quantity to qualify as improvement,\n   * i.e., an absolute change of less than `minDelta` will count as no\n   * improvement.\n   *\n   * Defaults to 0.\n   */\n  minDelta?: number;\n\n  /**\n   * Number of epochs with no improvement after which training will be stopped.\n   *\n   * Defaults to 0.\n   */\n  patience?: number;\n\n  /** Verbosity mode. */\n  verbose?: number;\n\n  /**\n   * Mode: one of 'min', 'max', and 'auto'.\n   * - In 'min' mode, training will be stopped when the quantity monitored has\n   *   stopped decreasing.\n   * - In 'max' mode, training will be stopped when the quantity monitored has\n   *   stopped increasing.\n   * - In 'auto' mode, the direction is inferred automatically from the name of\n   *   the monitored quantity.\n   *\n   * Defaults to 'auto'.\n   */\n  mode?: 'auto'|'min'|'max';\n\n  /**\n   * Baseline value of the monitored quantity.\n   *\n   * If specified, training will be stopped if the model doesn't show\n   * improvement over the baseline.\n   */\n  baseline?: number;\n\n  /**\n   * Whether to restore model weights from the epoch with the best value\n   * of the monitored quantity. If `False`, the model weights obtained at the\n   * last step of training are used.\n   *\n   * **`True` is not supported yet.**\n   */\n  restoreBestWeights?: boolean;\n}\n\nfunction less(currVal: number, prevVal: number) {\n  return currVal < prevVal;\n}\n\nfunction greater(currVal: number, prevVal: number) {\n  return currVal > prevVal;\n}\n\n/**\n * A Callback that stops training when a monitored quantity has stopped\n * improving.\n */\nexport class EarlyStopping extends Callback {\n  protected readonly monitor: string;\n  protected readonly minDelta: number;\n  protected readonly patience: number;\n  protected readonly baseline: number;\n  protected readonly verbose: number;\n  protected readonly mode: 'auto'|'min'|'max';\n\n  protected monitorFunc: (currVal: number, prevVal: number) => boolean;\n\n  private wait: number;\n  private stoppedEpoch: number;\n  private best: number;\n\n  constructor(args?: EarlyStoppingCallbackArgs) {\n    super();\n    if (args == null) {\n      args = {};\n    }\n    if (args.restoreBestWeights) {\n      throw new NotImplementedError(\n          'restoreBestWeights = True is not implemented in EarlyStopping yet.');\n    }\n\n    this.monitor = args.monitor || 'val_loss';\n    this.minDelta = Math.abs(args.minDelta || 0);\n    this.patience = args.patience || 0;\n    this.verbose = args.verbose || 0;\n    this.mode = args.mode || 'auto';\n    this.baseline = args.baseline;\n\n    if (['auto', 'min', 'max'].indexOf(this.mode) === -1) {\n      console.warn(\n          `EarlyStopping mode '${this.mode}' is invalid. ` +\n          `Falling back to mode 'auto'.`);\n      this.mode = 'auto';\n    }\n\n    if (this.mode === 'min') {\n      this.monitorFunc = less;\n    } else if (this.mode === 'max') {\n      this.monitorFunc = greater;\n    } else {\n      // For mode === 'auto'.\n      if (this.monitor.indexOf('acc') !== -1) {\n        this.monitorFunc = greater;\n      } else {\n        this.monitorFunc = less;\n      }\n    }\n\n    if (this.monitorFunc === less) {\n      this.minDelta *= -1;\n    }\n  }\n\n  override async onTrainBegin(logs?: Logs) {\n    this.wait = 0;\n    this.stoppedEpoch = 0;\n    if (this.baseline != null) {\n      this.best = this.baseline;\n    } else {\n      this.best = this.monitorFunc === less ? Infinity : -Infinity;\n    }\n  }\n\n  override async onEpochEnd(epoch: number, logs?: Logs) {\n    await resolveScalarsInLogs(logs);\n    const current = this.getMonitorValue(logs);\n    if (current == null) {\n      return;\n    }\n\n    if (this.monitorFunc(current - this.minDelta, this.best)) {\n      this.best = current;\n      this.wait = 0;\n      // TODO(cais): Logic for restoreBestWeights.\n    } else {\n      this.wait++;\n      if (this.wait >= this.patience) {\n        this.stoppedEpoch = epoch;\n        this.model.stopTraining = true;\n      }\n      // TODO(cais): Logic for restoreBestWeights.\n    }\n  }\n\n  override async onTrainEnd(logs?: Logs) {\n    if (this.stoppedEpoch > 0 && this.verbose) {\n      console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);\n    }\n  }\n\n  private getMonitorValue(logs: Logs) {\n    if (logs == null) {\n      logs = {};\n    }\n    const monitorValue = logs[this.monitor];\n    if (monitorValue == null) {\n      console.warn(\n          `Metric for EarlyStopping ${this.monitor} is not available. ` +\n          `Available metrics are: ${Object.keys(logs)}`);\n    }\n    return monitorValue;\n  }\n}\n\n/**\n * Factory function for a Callback that stops training when a monitored\n * quantity has stopped improving.\n *\n * Early stopping is a type of regularization, and protects model against\n * overfitting.\n *\n * The following example based on fake data illustrates how this callback\n * can be used during `tf.LayersModel.fit()`:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense({\n *   units: 3,\n *   activation: 'softmax',\n *   kernelInitializer: 'ones',\n *   inputShape: [2]\n * }));\n * const xs = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const ys = tf.tensor2d([[1, 0, 0], [0, 1, 0]], [2, 3]);\n * const xsVal = tf.tensor2d([4, 3, 2, 1], [2, 2]);\n * const ysVal = tf.tensor2d([[0, 0, 1], [0, 1, 0]], [2, 3]);\n * model.compile(\n *     {loss: 'categoricalCrossentropy', optimizer: 'sgd', metrics: ['acc']});\n *\n * // Without the EarlyStopping callback, the val_acc value would be:\n * //   0.5, 0.5, 0.5, 0.5, ...\n * // With val_acc being monitored, training should stop after the 2nd epoch.\n * const history = await model.fit(xs, ys, {\n *   epochs: 10,\n *   validationData: [xsVal, ysVal],\n *   callbacks: tf.callbacks.earlyStopping({monitor: 'val_acc'})\n * });\n *\n * // Expect to see a length-2 array.\n * console.log(history.history.val_acc);\n * ```\n *\n * @doc {\n *   heading: 'Callbacks',\n *   namespace: 'callbacks'\n * }\n */\nexport function earlyStopping(args?: EarlyStoppingCallbackArgs) {\n  return new EarlyStopping(args);\n}\n\nexport const callbacks = {earlyStopping};\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}