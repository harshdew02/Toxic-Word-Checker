{"ast":null,"code":"import _slicedToArray from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\nimport _toConsumableArray from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\nimport _get from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get.js\";\nimport _getPrototypeOf from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf.js\";\nimport _createClass from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _classCallCheck from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _inherits from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __rest = this && this.__rest || function (s, e) {\n  var t = {};\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\") for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n    if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];\n  }\n  return t;\n};\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { InputSpec } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { Initializer } from '../initializers';\nimport { convOutputLength, normalizeArray } from '../utils/conv_utils';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\nimport { generateDropoutMask, LSTMCell, RNN, RNNCell } from './recurrent';\nvar ConvRNN2DCell = /*#__PURE__*/function (_RNNCell) {\n  _inherits(ConvRNN2DCell, _RNNCell);\n  var _super = _createSuper(ConvRNN2DCell);\n  function ConvRNN2DCell() {\n    _classCallCheck(this, ConvRNN2DCell);\n    return _super.apply(this, arguments);\n  }\n  return _createClass(ConvRNN2DCell);\n}(RNNCell);\n/**\n * Base class for convolutional-recurrent layers.\n */\nvar ConvRNN2D = /*#__PURE__*/function (_RNN) {\n  _inherits(ConvRNN2D, _RNN);\n  var _super2 = _createSuper(ConvRNN2D);\n  function ConvRNN2D(args) {\n    var _this;\n    _classCallCheck(this, ConvRNN2D);\n    if (args.unroll) {\n      throw new NotImplementedError('Unrolling is not possible with convolutional RNNs.');\n    }\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError('It is not possible at the moment to stack convolutional cells.');\n    }\n    _this = _super2.call(this, args);\n    _this.inputSpec = [new InputSpec({\n      ndim: 5\n    })];\n    return _this;\n  }\n  _createClass(ConvRNN2D, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this2 = this;\n      return tfc.tidy(function () {\n        if (_this2.cell.dropoutMask != null) {\n          tfc.dispose(_this2.cell.dropoutMask);\n          _this2.cell.dropoutMask = null;\n        }\n        if (_this2.cell.recurrentDropoutMask != null) {\n          tfc.dispose(_this2.cell.recurrentDropoutMask);\n          _this2.cell.recurrentDropoutMask = null;\n        }\n        if (kwargs && kwargs['constants']) {\n          throw new ValueError('ConvRNN2D cell does not support constants');\n        }\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _get(_getPrototypeOf(ConvRNN2D.prototype), \"call\", _this2).call(_this2, inputs, {\n          mask: mask,\n          training: training,\n          initialState: initialState\n        });\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      var outShape = this.computeSingleOutputShape(inputShape);\n      if (!this.returnSequences) {\n        outShape = [outShape[0]].concat(_toConsumableArray(outShape.slice(2)));\n      }\n      if (this.returnState) {\n        outShape = [outShape].concat(_toConsumableArray(Array(2).fill([inputShape[0]].concat(_toConsumableArray(outShape.slice(-3))))));\n      }\n      return outShape;\n    }\n  }, {\n    key: \"getInitialState\",\n    value: function getInitialState(inputs) {\n      var _this3 = this;\n      return tfc.tidy(function () {\n        var stateSize = _this3.cell.stateSize;\n        var inputShape = inputs.shape;\n        var outputShape = _this3.computeSingleOutputShape(inputShape);\n        var stateShape = [outputShape[0]].concat(_toConsumableArray(outputShape.slice(2)));\n        var initialState = tfc.zeros(stateShape);\n        if (Array.isArray(stateSize)) {\n          return Array(stateSize.length).fill(initialState);\n        }\n        return [initialState];\n      });\n    }\n  }, {\n    key: \"resetStates\",\n    value: function resetStates(states) {\n      var _this4 = this;\n      var training = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n      tfc.tidy(function () {\n        if (!_this4.stateful) {\n          throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n        }\n        var inputShape = _this4.inputSpec[0].shape;\n        var outputShape = _this4.computeSingleOutputShape(inputShape);\n        var stateShape = [outputShape[0]].concat(_toConsumableArray(outputShape.slice(2)));\n        var batchSize = inputShape[0];\n        if (batchSize == null) {\n          throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' + 'the batch size of your input tensors: \\n' + '- If using a Sequential model, specify the batch size by ' + 'passing a `batchInputShape` option to your first layer.\\n' + '- If using the functional API, specify the batch size by ' + 'passing a `batchShape` option to your Input layer.');\n        }\n        // Initialize state if null.\n        if (_this4.getStates() == null) {\n          if (Array.isArray(_this4.cell.stateSize)) {\n            _this4.states_ = _this4.cell.stateSize.map(function () {\n              return tfc.zeros(stateShape);\n            });\n          } else {\n            _this4.states_ = [tfc.zeros(stateShape)];\n          }\n        } else if (states == null) {\n          // Dispose old state tensors.\n          tfc.dispose(_this4.states_);\n          // For stateful RNNs, fully dispose kept old states.\n          if (_this4.keptStates != null) {\n            tfc.dispose(_this4.keptStates);\n            _this4.keptStates = [];\n          }\n          if (Array.isArray(_this4.cell.stateSize)) {\n            _this4.states_ = _this4.cell.stateSize.map(function () {\n              return tfc.zeros(stateShape);\n            });\n          } else {\n            _this4.states_[0] = tfc.zeros(stateShape);\n          }\n        } else {\n          if (!Array.isArray(states)) {\n            states = [states];\n          }\n          if (states.length !== _this4.states_.length) {\n            throw new ValueError(\"Layer \".concat(_this4.name, \" expects \").concat(_this4.states_.length, \" state(s), \") + \"but it received \".concat(states.length, \" state value(s). Input \") + \"received: \".concat(states));\n          }\n          if (training) {\n            // Store old state tensors for complete disposal later, i.e., during\n            // the next no-arg call to this method. We do not dispose the old\n            // states immediately because that BPTT (among other things) require\n            // them.\n            _this4.keptStates.push(_this4.states_.slice());\n          } else {\n            tfc.dispose(_this4.states_);\n          }\n          for (var index = 0; index < _this4.states_.length; ++index) {\n            var value = states[index];\n            var expectedShape = stateShape;\n            if (!util.arraysEqual(value.shape, expectedShape)) {\n              throw new ValueError(\"State \".concat(index, \" is incompatible with layer \").concat(_this4.name, \": \") + \"expected shape=\".concat(expectedShape, \", received shape=\").concat(value.shape));\n            }\n            _this4.states_[index] = value;\n          }\n        }\n        _this4.states_ = _this4.states_.map(function (state) {\n          return tfc.keep(state.clone());\n        });\n      });\n    }\n  }, {\n    key: \"computeSingleOutputShape\",\n    value: function computeSingleOutputShape(inputShape) {\n      var _this$cell = this.cell,\n        dataFormat = _this$cell.dataFormat,\n        filters = _this$cell.filters,\n        kernelSize = _this$cell.kernelSize,\n        padding = _this$cell.padding,\n        strides = _this$cell.strides,\n        dilationRate = _this$cell.dilationRate;\n      var isChannelsFirst = dataFormat === 'channelsFirst';\n      var h = inputShape[isChannelsFirst ? 3 : 2];\n      var w = inputShape[isChannelsFirst ? 4 : 3];\n      var hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);\n      var wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);\n      var outShape = [].concat(_toConsumableArray(inputShape.slice(0, 2)), _toConsumableArray(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters]));\n      return outShape;\n    }\n  }]);\n  return ConvRNN2D;\n}(RNN);\n/** @nocollapse */\nConvRNN2D.className = 'ConvRNN2D';\nexport var ConvLSTM2DCell = /*#__PURE__*/function (_LSTMCell) {\n  _inherits(ConvLSTM2DCell, _LSTMCell);\n  var _super3 = _createSuper(ConvLSTM2DCell);\n  function ConvLSTM2DCell(args) {\n    var _this5;\n    _classCallCheck(this, ConvLSTM2DCell);\n    var filters = args.filters,\n      kernelSize = args.kernelSize,\n      strides = args.strides,\n      padding = args.padding,\n      dataFormat = args.dataFormat,\n      dilationRate = args.dilationRate;\n    _this5 = _super3.call(this, Object.assign(Object.assign({}, args), {\n      units: filters\n    }));\n    _this5.filters = filters;\n    assertPositiveInteger(_this5.filters, 'filters');\n    _this5.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n    _this5.kernelSize.forEach(function (size) {\n      return assertPositiveInteger(size, 'kernelSize');\n    });\n    _this5.strides = normalizeArray(strides || 1, 2, 'strides');\n    _this5.strides.forEach(function (stride) {\n      return assertPositiveInteger(stride, 'strides');\n    });\n    _this5.padding = padding || 'valid';\n    checkPaddingMode(_this5.padding);\n    _this5.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(_this5.dataFormat);\n    _this5.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n    _this5.dilationRate.forEach(function (rate) {\n      return assertPositiveInteger(rate, 'dilationRate');\n    });\n    return _this5;\n  }\n  _createClass(ConvLSTM2DCell, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      var _a;\n      inputShape = getExactlyOneShape(inputShape);\n      var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n      if (inputShape[channelAxis] == null) {\n        throw new ValueError(\"The channel dimension of the input should be defined. \" + \"Found \".concat(inputShape[channelAxis]));\n      }\n      var inputDim = inputShape[channelAxis];\n      var numOfKernels = 4;\n      var kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n      this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n      var recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n      this.recurrentKernel = this.addWeight('recurrent_kernel', recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n      if (this.useBias) {\n        var biasInitializer;\n        if (this.unitForgetBias) {\n          var init = this.biasInitializer;\n          var filters = this.filters;\n          biasInitializer = new (_a = /*#__PURE__*/function (_Initializer) {\n            _inherits(CustomInit, _Initializer);\n            var _super4 = _createSuper(CustomInit);\n            function CustomInit() {\n              _classCallCheck(this, CustomInit);\n              return _super4.apply(this, arguments);\n            }\n            _createClass(CustomInit, [{\n              key: \"apply\",\n              value: function apply(shape, dtype) {\n                var biasI = init.apply([filters]);\n                var biasF = tfc.ones([filters]);\n                var biasCAndO = init.apply([filters * 2]);\n                return K.concatenate([biasI, biasF, biasCAndO]);\n              }\n            }]);\n            return CustomInit;\n          }(Initializer), /** @nocollapse */\n          _a.className = 'CustomInit', _a)();\n        } else {\n          biasInitializer = this.biasInitializer;\n        }\n        this.bias = this.addWeight('bias', [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      }\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this6 = this;\n      return tfc.tidy(function () {\n        if (inputs.length !== 3) {\n          throw new ValueError(\"ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got \" + \"\".concat(inputs.length, \".\"));\n        }\n        var training = kwargs['training'] || false;\n        var x = inputs[0]; // Current input\n        var hTMinus1 = inputs[1]; // Previous memory state.\n        var cTMinus1 = inputs[2]; // Previous carry state.\n        var numOfKernels = 4;\n        if (0 < _this6.dropout && _this6.dropout < 1 && _this6.dropoutMask == null) {\n          _this6.dropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(x);\n            },\n            rate: _this6.dropout,\n            training: training,\n            count: numOfKernels,\n            dropoutFunc: _this6.dropoutFunc\n          });\n        }\n        var dropoutMask = _this6.dropoutMask;\n        var applyDropout = function applyDropout(x, mask, index) {\n          if (!mask || !mask[index]) {\n            return x;\n          }\n          return tfc.mul(mask[index], x);\n        };\n        var xI = applyDropout(x, dropoutMask, 0);\n        var xF = applyDropout(x, dropoutMask, 1);\n        var xC = applyDropout(x, dropoutMask, 2);\n        var xO = applyDropout(x, dropoutMask, 3);\n        if (0 < _this6.recurrentDropout && _this6.recurrentDropout < 1 && _this6.recurrentDropoutMask == null) {\n          _this6.recurrentDropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(hTMinus1);\n            },\n            rate: _this6.recurrentDropout,\n            training: training,\n            count: numOfKernels,\n            dropoutFunc: _this6.dropoutFunc\n          });\n        }\n        var recDropoutMask = _this6.recurrentDropoutMask;\n        var hI = applyDropout(hTMinus1, recDropoutMask, 0);\n        var hF = applyDropout(hTMinus1, recDropoutMask, 1);\n        var hC = applyDropout(hTMinus1, recDropoutMask, 2);\n        var hO = applyDropout(hTMinus1, recDropoutMask, 3);\n        var kernelChannelAxis = 3;\n        var _tfc$split = tfc.split(_this6.kernel.read(), numOfKernels, kernelChannelAxis),\n          _tfc$split2 = _slicedToArray(_tfc$split, 4),\n          kernelI = _tfc$split2[0],\n          kernelF = _tfc$split2[1],\n          kernelC = _tfc$split2[2],\n          kernelO = _tfc$split2[3];\n        var _ref = _this6.useBias ? tfc.split(_this6.bias.read(), numOfKernels) : [null, null, null, null],\n          _ref2 = _slicedToArray(_ref, 4),\n          biasI = _ref2[0],\n          biasF = _ref2[1],\n          biasC = _ref2[2],\n          biasO = _ref2[3];\n        xI = _this6.inputConv(xI, kernelI, biasI, _this6.padding);\n        xF = _this6.inputConv(xF, kernelF, biasF, _this6.padding);\n        xC = _this6.inputConv(xC, kernelC, biasC, _this6.padding);\n        xO = _this6.inputConv(xO, kernelO, biasO, _this6.padding);\n        var _tfc$split3 = tfc.split(_this6.recurrentKernel.read(), numOfKernels, kernelChannelAxis),\n          _tfc$split4 = _slicedToArray(_tfc$split3, 4),\n          recKernelI = _tfc$split4[0],\n          recKernelF = _tfc$split4[1],\n          recKernelC = _tfc$split4[2],\n          recKernelO = _tfc$split4[3];\n        hI = _this6.recurrentConv(hI, recKernelI);\n        hF = _this6.recurrentConv(hF, recKernelF);\n        hC = _this6.recurrentConv(hC, recKernelC);\n        hO = _this6.recurrentConv(hO, recKernelO);\n        var i = _this6.recurrentActivation.apply(tfc.add(xI, hI));\n        var f = _this6.recurrentActivation.apply(tfc.add(xF, hF));\n        var c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, _this6.activation.apply(tfc.add(xC, hC))));\n        var h = tfc.mul(_this6.recurrentActivation.apply(tfc.add(xO, hO)), _this6.activation.apply(c));\n        return [h, h, c];\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var _a = _get(_getPrototypeOf(ConvLSTM2DCell.prototype), \"getConfig\", this).call(this),\n        _ = _a['units'],\n        baseConfig = __rest(_a, ['units']);\n      var config = {\n        filters: this.filters,\n        kernelSize: this.kernelSize,\n        padding: this.padding,\n        dataFormat: this.dataFormat,\n        dilationRate: this.dilationRate,\n        strides: this.strides\n      };\n      return Object.assign(Object.assign({}, baseConfig), config);\n    }\n  }, {\n    key: \"inputConv\",\n    value: function inputConv(x, w, b, padding) {\n      var out = tfc.conv2d(x, w, this.strides, padding || 'valid', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC', this.dilationRate);\n      if (b) {\n        return K.biasAdd(out, b, this.dataFormat);\n      }\n      return out;\n    }\n  }, {\n    key: \"recurrentConv\",\n    value: function recurrentConv(x, w) {\n      var strides = 1;\n      return tfc.conv2d(x, w, strides, 'same', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n    }\n  }]);\n  return ConvLSTM2DCell;\n}(LSTMCell);\n/** @nocollapse */\nConvLSTM2DCell.className = 'ConvLSTM2DCell';\ntfc.serialization.registerClass(ConvLSTM2DCell);\nexport var ConvLSTM2D = /*#__PURE__*/function (_ConvRNN2D) {\n  _inherits(ConvLSTM2D, _ConvRNN2D);\n  var _super5 = _createSuper(ConvLSTM2D);\n  function ConvLSTM2D(args) {\n    _classCallCheck(this, ConvLSTM2D);\n    var cell = new ConvLSTM2DCell(args);\n    return _super5.call(this, Object.assign(Object.assign({}, args), {\n      cell: cell\n    }));\n  }\n  /** @nocollapse */\n  _createClass(ConvLSTM2D, null, [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      return new cls(config);\n    }\n  }]);\n  return ConvLSTM2D;\n}(ConvRNN2D);\n/** @nocollapse */\nConvLSTM2D.className = 'ConvLSTM2D';\ntfc.serialization.registerClass(ConvLSTM2D);","map":{"version":3,"mappings":";;;;;;;;AAAA;;;;;;;;;;;;;;;;;AAUA,OAAO,KAAKA,GAAG,MAAM,uBAAuB;AAC5C,SAAgBC,IAAI,QAAO,uBAAuB;AAGlD,OAAO,KAAKC,CAAC,MAAM,yBAAyB;AAC5C,SAAQC,eAAe,EAAEC,gBAAgB,QAAO,WAAW;AAE3D,SAAQC,SAAS,QAAO,oBAAoB;AAC5C,SAAQC,cAAc,EAAEC,mBAAmB,EAAEC,UAAU,QAAO,WAAW;AACzE,SAAQC,WAAW,QAAO,iBAAiB;AAI3C,SAAQC,gBAAgB,EAAEC,cAAc,QAAO,qBAAqB;AACpE,SAAQC,qBAAqB,QAAO,wBAAwB;AAC5D,SAAQC,kBAAkB,QAAO,sBAAsB;AAEvD,SAA0BC,mBAAmB,EAAEC,QAAQ,EAAoCC,GAAG,EAAEC,OAAO,QAA6C,aAAa;AAAC,IAsDnJC,aAAc;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;AAAA,EAAQD,OAAO;AA8B5C;;;AAAA,IAGME,SAAU;EAAA;EAAA;EAMd,mBAAYC,IAAwB;IAAA;IAAA;IAClC,IAAIA,IAAI,CAACC,MAAM,EAAE;MACf,MAAM,IAAId,mBAAmB,CACzB,oDAAoD,CAAC;;IAG3D,IAAIe,KAAK,CAACC,OAAO,CAACH,IAAI,CAACI,IAAI,CAAC,EAAE;MAC5B,MAAM,IAAIjB,mBAAmB,CACzB,gEAAgE,CAAC;;IAGvE,2BAAMa,IAAoB;IAE1B,MAAKK,SAAS,GAAG,CAAC,IAAIpB,SAAS,CAAC;MAACqB,IAAI,EAAE;IAAC,CAAC,CAAC,CAAC;IAAC;EAC9C;EAAC;IAAA;IAAA,OAEQ,cAAKC,MAAuB,EAAEC,MAAc;MAAA;MACnD,OAAO5B,GAAG,CAAC6B,IAAI,CAAC,YAAK;QACnB,IAAI,MAAI,CAACL,IAAI,CAACM,WAAW,IAAI,IAAI,EAAE;UACjC9B,GAAG,CAAC+B,OAAO,CAAC,MAAI,CAACP,IAAI,CAACM,WAAW,CAAC;UAElC,MAAI,CAACN,IAAI,CAACM,WAAW,GAAG,IAAI;;QAG9B,IAAI,MAAI,CAACN,IAAI,CAACQ,oBAAoB,IAAI,IAAI,EAAE;UAC1ChC,GAAG,CAAC+B,OAAO,CAAC,MAAI,CAACP,IAAI,CAACQ,oBAAoB,CAAC;UAE3C,MAAI,CAACR,IAAI,CAACQ,oBAAoB,GAAG,IAAI;;QAGvC,IAAIJ,MAAM,IAAIA,MAAM,CAAC,WAAW,CAAC,EAAE;UACjC,MAAM,IAAIpB,UAAU,CAAC,2CAA2C,CAAC;;QAGnE,IAAMyB,IAAI,GAAGL,MAAM,IAAI,IAAI,GAAG,IAAI,GAAGA,MAAM,CAAC,MAAM,CAAC;QAEnD,IAAMM,QAAQ,GAAGN,MAAM,IAAI,IAAI,GAAG,IAAI,GAAGA,MAAM,CAAC,UAAU,CAAC;QAE3D,IAAMO,YAAY,GACdP,MAAM,IAAI,IAAI,GAAG,IAAI,GAAGA,MAAM,CAAC,cAAc,CAAC;QAElD,+EAAkBD,MAAM,EAAE;UAACM,IAAI,EAAJA,IAAI;UAAEC,QAAQ,EAARA,QAAQ;UAAEC,YAAY,EAAZA;QAAY,CAAC;MAC1D,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,4BAAmBC,UAAiB;MAC3C,IAAIC,QAAQ,GAAU,IAAI,CAACC,wBAAwB,CAACF,UAAU,CAAC;MAE/D,IAAI,CAAC,IAAI,CAACG,eAAe,EAAE;QACzBF,QAAQ,IAAIA,QAAQ,CAAC,CAAC,CAAC,4BAAKA,QAAQ,CAACG,KAAK,CAAC,CAAC,CAAC,EAAC;;MAGhD,IAAI,IAAI,CAACC,WAAW,EAAE;QACpBJ,QAAQ,IACHA,QAAQ,4BAAKf,KAAK,CAAC,CAAC,CAAC,CAACoB,IAAI,EAAEN,UAAU,CAAC,CAAC,CAAC,4BAAKC,QAAQ,CAACG,KAAK,CAAC,CAAC,CAAC,CAAC,GAAE,EAAC;;MAG1E,OAAOH,QAAQ;IACjB;EAAC;IAAA;IAAA,OAEQ,yBAAgBV,MAAkB;MAAA;MACzC,OAAO3B,GAAG,CAAC6B,IAAI,CAAC,YAAK;QACnB,IAAOc,SAAS,GAAI,MAAI,CAACnB,IAAI,CAAtBmB,SAAS;QAEhB,IAAMP,UAAU,GAAGT,MAAM,CAACiB,KAAK;QAE/B,IAAMC,WAAW,GAAG,MAAI,CAACP,wBAAwB,CAACF,UAAU,CAAC;QAE7D,IAAMU,UAAU,IAAID,WAAW,CAAC,CAAC,CAAC,4BAAKA,WAAW,CAACL,KAAK,CAAC,CAAC,CAAC,EAAC;QAE5D,IAAML,YAAY,GAAGnC,GAAG,CAAC+C,KAAK,CAACD,UAAU,CAAC;QAE1C,IAAIxB,KAAK,CAACC,OAAO,CAACoB,SAAS,CAAC,EAAE;UAC5B,OAAOrB,KAAK,CAACqB,SAAS,CAACK,MAAM,CAAC,CAACN,IAAI,CAACP,YAAY,CAAC;;QAGnD,OAAO,CAACA,YAAY,CAAC;MACvB,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAYc,MAAwB,EAAkB;MAAA;MAAA,IAAhBf,QAAQ,uEAAG,KAAK;MAC7DlC,GAAG,CAAC6B,IAAI,CAAC,YAAK;QACZ,IAAI,CAAC,MAAI,CAACqB,QAAQ,EAAE;UAClB,MAAM,IAAI5C,cAAc,CACpB,iEAAiE,CAAC;;QAGxE,IAAM8B,UAAU,GAAG,MAAI,CAACX,SAAS,CAAC,CAAC,CAAC,CAACmB,KAAK;QAE1C,IAAMC,WAAW,GAAG,MAAI,CAACP,wBAAwB,CAACF,UAAU,CAAC;QAE7D,IAAMU,UAAU,IAAID,WAAW,CAAC,CAAC,CAAC,4BAAKA,WAAW,CAACL,KAAK,CAAC,CAAC,CAAC,EAAC;QAE5D,IAAMW,SAAS,GAAGf,UAAU,CAAC,CAAC,CAAC;QAE/B,IAAIe,SAAS,IAAI,IAAI,EAAE;UACrB,MAAM,IAAI3C,UAAU,CAChB,kEAAkE,GAClE,0CAA0C,GAC1C,2DAA2D,GAC3D,2DAA2D,GAC3D,2DAA2D,GAC3D,oDAAoD,CAAC;;QAG3D;QACA,IAAI,MAAI,CAAC4C,SAAS,EAAE,IAAI,IAAI,EAAE;UAC5B,IAAI9B,KAAK,CAACC,OAAO,CAAC,MAAI,CAACC,IAAI,CAACmB,SAAS,CAAC,EAAE;YACtC,MAAI,CAACU,OAAO,GAAG,MAAI,CAAC7B,IAAI,CAACmB,SAAS,CAACW,GAAG,CAAC;cAAA,OAAMtD,GAAG,CAAC+C,KAAK,CAACD,UAAU,CAAC;YAAA,EAAC;WACpE,MAAM;YACL,MAAI,CAACO,OAAO,GAAG,CAACrD,GAAG,CAAC+C,KAAK,CAACD,UAAU,CAAC,CAAC;;SAEzC,MAAM,IAAIG,MAAM,IAAI,IAAI,EAAE;UACzB;UACAjD,GAAG,CAAC+B,OAAO,CAAC,MAAI,CAACsB,OAAO,CAAC;UAEzB;UACA,IAAI,MAAI,CAACE,UAAU,IAAI,IAAI,EAAE;YAC3BvD,GAAG,CAAC+B,OAAO,CAAC,MAAI,CAACwB,UAAU,CAAC;YAC5B,MAAI,CAACA,UAAU,GAAG,EAAE;;UAGtB,IAAIjC,KAAK,CAACC,OAAO,CAAC,MAAI,CAACC,IAAI,CAACmB,SAAS,CAAC,EAAE;YACtC,MAAI,CAACU,OAAO,GAAG,MAAI,CAAC7B,IAAI,CAACmB,SAAS,CAACW,GAAG,CAAC;cAAA,OAAMtD,GAAG,CAAC+C,KAAK,CAACD,UAAU,CAAC;YAAA,EAAC;WACpE,MAAM;YACL,MAAI,CAACO,OAAO,CAAC,CAAC,CAAC,GAAGrD,GAAG,CAAC+C,KAAK,CAACD,UAAU,CAAC;;SAE1C,MAAM;UACL,IAAI,CAACxB,KAAK,CAACC,OAAO,CAAC0B,MAAM,CAAC,EAAE;YAC1BA,MAAM,GAAG,CAACA,MAAM,CAAC;;UAGnB,IAAIA,MAAM,CAACD,MAAM,KAAK,MAAI,CAACK,OAAO,CAACL,MAAM,EAAE;YACzC,MAAM,IAAIxC,UAAU,CAChB,gBAAS,MAAI,CAACgD,IAAI,sBAAY,MAAI,CAACH,OAAO,CAACL,MAAM,6CAC9BC,MAAM,CAACD,MAAM,4BAAyB,uBAC5CC,MAAM,CAAE,CAAC;;UAG5B,IAAIf,QAAQ,EAAE;YACZ;YACA;YACA;YACA;YACA,MAAI,CAACqB,UAAU,CAACE,IAAI,CAAC,MAAI,CAACJ,OAAO,CAACb,KAAK,EAAE,CAAC;WAC3C,MAAM;YACLxC,GAAG,CAAC+B,OAAO,CAAC,MAAI,CAACsB,OAAO,CAAC;;UAG3B,KAAK,IAAIK,KAAK,GAAG,CAAC,EAAEA,KAAK,GAAG,MAAI,CAACL,OAAO,CAACL,MAAM,EAAE,EAAEU,KAAK,EAAE;YACxD,IAAMC,KAAK,GAAGV,MAAM,CAACS,KAAK,CAAC;YAE3B,IAAME,aAAa,GAAGd,UAAU;YAEhC,IAAI,CAAC7C,IAAI,CAAC4D,WAAW,CAACF,KAAK,CAACf,KAAK,EAAEgB,aAAa,CAAC,EAAE;cACjD,MAAM,IAAIpD,UAAU,CAChB,gBAASkD,KAAK,yCAA+B,MAAI,CAACF,IAAI,mCACpCI,aAAa,8BAC3BD,KAAK,CAACf,KAAK,CAAE,CAAC;;YAGxB,MAAI,CAACS,OAAO,CAACK,KAAK,CAAC,GAAGC,KAAK;;;QAI/B,MAAI,CAACN,OAAO,GAAG,MAAI,CAACA,OAAO,CAACC,GAAG,CAAC,eAAK;UAAA,OAAItD,GAAG,CAAC8D,IAAI,CAACC,KAAK,CAACC,KAAK,EAAE,CAAC;QAAA,EAAC;MACnE,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAES,kCAAyB5B,UAAiB;MAClD,iBACI,IAAI,CAACZ,IAAI;QADNyC,UAAU,cAAVA,UAAU;QAAEC,OAAO,cAAPA,OAAO;QAAEC,UAAU,cAAVA,UAAU;QAAEC,OAAO,cAAPA,OAAO;QAAEC,OAAO,cAAPA,OAAO;QAAEC,YAAY,cAAZA,YAAY;MAGtE,IAAMC,eAAe,GAAGN,UAAU,KAAK,eAAe;MAEtD,IAAMO,CAAC,GAAGpC,UAAU,CAACmC,eAAe,GAAG,CAAC,GAAG,CAAC,CAAC;MAC7C,IAAME,CAAC,GAAGrC,UAAU,CAACmC,eAAe,GAAG,CAAC,GAAG,CAAC,CAAC;MAE7C,IAAMG,IAAI,GAAGhE,gBAAgB,CACzB8D,CAAC,EAAEL,UAAU,CAAC,CAAC,CAAC,EAAEC,OAAO,EAAEC,OAAO,CAAC,CAAC,CAAC,EAAEC,YAAY,CAAC,CAAC,CAAC,CAAC;MAC3D,IAAMK,IAAI,GAAGjE,gBAAgB,CACzB+D,CAAC,EAAEN,UAAU,CAAC,CAAC,CAAC,EAAEC,OAAO,EAAEC,OAAO,CAAC,CAAC,CAAC,EAAEC,YAAY,CAAC,CAAC,CAAC,CAAC;MAE3D,IAAMjC,QAAQ,gCACTD,UAAU,CAACI,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,sBACrB+B,eAAe,GAAG,CAACL,OAAO,EAAEQ,IAAI,EAAEC,IAAI,CAAC,GAAG,CAACD,IAAI,EAAEC,IAAI,EAAET,OAAO,CAAC,EACpE;MAED,OAAO7B,QAAQ;IACjB;EAAC;EAAA;AAAA,EAnMqBrB,GAAG;AACzB;AACgBG,mBAAS,GAAG,WAAW;AAuMzC,WAAayD,cAAe;EAAA;EAAA;EAW1B,wBAAYxD,IAAwB;IAAA;IAAA;IAClC,IACE8C,OAAO,GAML9C,IAAI,CANN8C,OAAO;MACPC,UAAU,GAKR/C,IAAI,CALN+C,UAAU;MACVE,OAAO,GAILjD,IAAI,CAJNiD,OAAO;MACPD,OAAO,GAGLhD,IAAI,CAHNgD,OAAO;MACPH,UAAU,GAER7C,IAAI,CAFN6C,UAAU;MACVK,YAAY,GACVlD,IAAI,CADNkD,YAAY;IAGd,4BAAKO,gCAAKzD,IAAI;MAAE0D,KAAK,EAAEZ;IAAO;IAE9B,OAAKA,OAAO,GAAGA,OAAO;IACtBtD,qBAAqB,CAAC,OAAKsD,OAAO,EAAE,SAAS,CAAC;IAE9C,OAAKC,UAAU,GAAGxD,cAAc,CAACwD,UAAU,EAAE,CAAC,EAAE,YAAY,CAAC;IAC7D,OAAKA,UAAU,CAACY,OAAO,CAAC,cAAI;MAAA,OAAInE,qBAAqB,CAACoE,IAAI,EAAE,YAAY,CAAC;IAAA,EAAC;IAE1E,OAAKX,OAAO,GAAG1D,cAAc,CAAC0D,OAAO,IAAI,CAAC,EAAE,CAAC,EAAE,SAAS,CAAC;IACzD,OAAKA,OAAO,CAACU,OAAO,CAAC,gBAAM;MAAA,OAAInE,qBAAqB,CAACqE,MAAM,EAAE,SAAS,CAAC;IAAA,EAAC;IAExE,OAAKb,OAAO,GAAGA,OAAO,IAAI,OAAO;IACjChE,gBAAgB,CAAC,OAAKgE,OAAO,CAAC;IAE9B,OAAKH,UAAU,GAAGA,UAAU,IAAI,cAAc;IAC9C9D,eAAe,CAAC,OAAK8D,UAAU,CAAC;IAEhC,OAAKK,YAAY,GAAG3D,cAAc,CAAC2D,YAAY,IAAI,CAAC,EAAE,CAAC,EAAE,cAAc,CAAC;IACxE,OAAKA,YAAY,CAACS,OAAO,CACrB,cAAI;MAAA,OAAInE,qBAAqB,CAACsE,IAAI,EAAE,cAAc,CAAC;IAAA,EAAC;IAAC;EAC3D;EAAC;IAAA;IAAA,OAEe,eAAM9C,UAAyB;;MAC7CA,UAAU,GAAGvB,kBAAkB,CAACuB,UAAU,CAAC;MAE3C,IAAM+C,WAAW,GACb,IAAI,CAAClB,UAAU,KAAK,eAAe,GAAG,CAAC,GAAG7B,UAAU,CAACY,MAAM,GAAG,CAAC;MAEnE,IAAIZ,UAAU,CAAC+C,WAAW,CAAC,IAAI,IAAI,EAAE;QACnC,MAAM,IAAI3E,UAAU,CAChB,2EACS4B,UAAU,CAAC+C,WAAW,CAAC,CAAE,CAAC;;MAGzC,IAAMC,QAAQ,GAAGhD,UAAU,CAAC+C,WAAW,CAAC;MAExC,IAAME,YAAY,GAAG,CAAC;MAEtB,IAAMC,WAAW,GACb,IAAI,CAACnB,UAAU,CAACoB,MAAM,CAAC,CAACH,QAAQ,EAAE,IAAI,CAAClB,OAAO,GAAGmB,YAAY,CAAC,CAAC;MAEnE,IAAI,CAACG,MAAM,GAAG,IAAI,CAACC,SAAS,CACxB,QAAQ,EAAEH,WAAW,EAAE,IAAI,EAAE,IAAI,CAACI,iBAAiB,EACnD,IAAI,CAACC,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAACC,gBAAgB,CAAC;MAExD,IAAMC,oBAAoB,GACtB,IAAI,CAAC1B,UAAU,CAACoB,MAAM,CAAC,CAAC,IAAI,CAACrB,OAAO,EAAE,IAAI,CAACA,OAAO,GAAGmB,YAAY,CAAC,CAAC;MAEvE,IAAI,CAACS,eAAe,GAAG,IAAI,CAACL,SAAS,CACjC,kBAAkB,EAAEI,oBAAoB,EAAE,IAAI,EAC9C,IAAI,CAACE,oBAAoB,EAAE,IAAI,CAACC,oBAAoB,EAAE,IAAI,EAC1D,IAAI,CAACC,mBAAmB,CAAC;MAE7B,IAAI,IAAI,CAACC,OAAO,EAAE;QAChB,IAAIC,eAA4B;QAEhC,IAAI,IAAI,CAACC,cAAc,EAAE;UACvB,IAAMC,IAAI,GAAG,IAAI,CAACF,eAAe;UAEjC,IAAMjC,OAAO,GAAG,IAAI,CAACA,OAAO;UAE5BiC,eAAe,GAAG,KAAIG;YAAA;YAAA;YAAA;cAAA;cAAA;YAAA;YAAA;cAAA;cAAA,OAIpB,eAAM1D,KAAY,EAAE2D,KAAgB;gBAClC,IAAMC,KAAK,GAAGH,IAAI,CAACI,KAAK,CAAC,CAACvC,OAAO,CAAC,CAAC;gBACnC,IAAMwC,KAAK,GAAG1G,GAAG,CAAC2G,IAAI,CAAC,CAACzC,OAAO,CAAC,CAAC;gBACjC,IAAM0C,SAAS,GAAGP,IAAI,CAACI,KAAK,CAAC,CAACvC,OAAO,GAAG,CAAC,CAAC,CAAC;gBAC3C,OAAOhE,CAAC,CAAC2G,WAAW,CAAC,CAACL,KAAK,EAAEE,KAAK,EAAEE,SAAS,CAAC,CAAC;cACjD;YAAC;YAAA;UAAA,EAT6CnG,WAAW,CAU1D,EATC;UACO6F,YAAS,GAAG,YAAa,OAQ9B;SACL,MAAM;UACLH,eAAe,GAAG,IAAI,CAACA,eAAe;;QAGxC,IAAI,CAACW,IAAI,GAAG,IAAI,CAACrB,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAACvB,OAAO,GAAGmB,YAAY,CAAC,EAAE,IAAI,EAAEc,eAAe,EAC5D,IAAI,CAACY,eAAe,EAAE,IAAI,EAAE,IAAI,CAACC,cAAc,CAAC;;MAGtD,IAAI,CAACC,KAAK,GAAG,IAAI;IACnB;EAAC;IAAA;IAAA,OAEQ,cAAKtF,MAAoB,EAAEC,MAAc;MAAA;MAChD,OAAO5B,GAAG,CAAC6B,IAAI,CAAC,YAAK;QACnB,IAAIF,MAAM,CAACqB,MAAM,KAAK,CAAC,EAAE;UACvB,MAAM,IAAIxC,UAAU,CAChB,0EACGmB,MAAM,CAACqB,MAAM,MAAG,CAAC;;QAG1B,IAAMd,QAAQ,GAAGN,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK;QAE5C,IAAMsF,CAAC,GAAGvF,MAAM,CAAC,CAAC,CAAC,CAAC,CAAS;QAC7B,IAAMwF,QAAQ,GAAGxF,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE;QAC7B,IAAMyF,QAAQ,GAAGzF,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE;QAE7B,IAAM0D,YAAY,GAAG,CAAC;QAItB,IAAI,CAAC,GAAG,MAAI,CAACgC,OAAO,IAAI,MAAI,CAACA,OAAO,GAAG,CAAC,IAAI,MAAI,CAACvF,WAAW,IAAI,IAAI,EAAE;UACpE,MAAI,CAACA,WAAW,GAAGhB,mBAAmB,CAAC;YAClB6F,IAAI,EAAE;cAAA,OAAM3G,GAAG,CAACsH,QAAQ,CAACJ,CAAC,CAAC;YAAA;YAC3BhC,IAAI,EAAE,MAAI,CAACmC,OAAO;YAClBnF,QAAQ,EAARA,QAAQ;YACRqF,KAAK,EAAElC,YAAY;YACnBmC,WAAW,EAAE,MAAI,CAACA;WACnB,CAAiB;;QAGvC,IAAM1F,WAAW,GAAG,MAAI,CAACA,WAA2B;QAEpD,IAAM2F,YAAY,GACd,SADEA,YAAY,CACbP,CAAa,EAAEjF,IAAkB,EAAEyB,KAAa,EAAI;UACnD,IAAI,CAACzB,IAAI,IAAI,CAACA,IAAI,CAACyB,KAAK,CAAC,EAAE;YACzB,OAAOwD,CAAC;;UAGV,OAAOlH,GAAG,CAAC0H,GAAG,CAACzF,IAAI,CAACyB,KAAK,CAAC,EAAEwD,CAAC,CAAC;QAChC,CAAC;QAEL,IAAIS,EAAE,GAAGF,YAAY,CAACP,CAAC,EAAEpF,WAAW,EAAE,CAAC,CAAC;QACxC,IAAI8F,EAAE,GAAGH,YAAY,CAACP,CAAC,EAAEpF,WAAW,EAAE,CAAC,CAAC;QACxC,IAAI+F,EAAE,GAAGJ,YAAY,CAACP,CAAC,EAAEpF,WAAW,EAAE,CAAC,CAAC;QACxC,IAAIgG,EAAE,GAAGL,YAAY,CAACP,CAAC,EAAEpF,WAAW,EAAE,CAAC,CAAC;QAExC,IAAI,CAAC,GAAG,MAAI,CAACiG,gBAAgB,IAAI,MAAI,CAACA,gBAAgB,GAAG,CAAC,IACtD,MAAI,CAAC/F,oBAAoB,IAAI,IAAI,EAAE;UACrC,MAAI,CAACA,oBAAoB,GAAGlB,mBAAmB,CAAC;YAClB6F,IAAI,EAAE;cAAA,OAAM3G,GAAG,CAACsH,QAAQ,CAACH,QAAQ,CAAC;YAAA;YAClCjC,IAAI,EAAE,MAAI,CAAC6C,gBAAgB;YAC3B7F,QAAQ,EAARA,QAAQ;YACRqF,KAAK,EAAElC,YAAY;YACnBmC,WAAW,EAAE,MAAI,CAACA;WACnB,CAAiB;;QAGhD,IAAMQ,cAAc,GAAG,MAAI,CAAChG,oBAAoC;QAEhE,IAAIiG,EAAE,GAAGR,YAAY,CAACN,QAAQ,EAAEa,cAAc,EAAE,CAAC,CAAC;QAClD,IAAIE,EAAE,GAAGT,YAAY,CAACN,QAAQ,EAAEa,cAAc,EAAE,CAAC,CAAC;QAClD,IAAIG,EAAE,GAAGV,YAAY,CAACN,QAAQ,EAAEa,cAAc,EAAE,CAAC,CAAC;QAClD,IAAII,EAAE,GAAGX,YAAY,CAACN,QAAQ,EAAEa,cAAc,EAAE,CAAC,CAAC;QAElD,IAAMK,iBAAiB,GAAG,CAAC;QAE3B,iBACIrI,GAAG,CAACsI,KAAK,CAAC,MAAI,CAAC9C,MAAM,CAAC+C,IAAI,EAAE,EAAElD,YAAY,EAAEgD,iBAAiB,CAAC;UAAA;UAD3DG,OAAO;UAAEC,OAAO;UAAEC,OAAO;UAAEC,OAAO;QAGzC,WAAmD,MAAI,CAACzC,OAAO,GAC3DlG,GAAG,CAACsI,KAAK,CAAC,MAAI,CAACxB,IAAI,CAACyB,IAAI,EAAE,EAAElD,YAAY,CAAC,GACzC,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC;UAAA;UAFrBmB,KAAK;UAAEE,KAAK;UAAEkC,KAAK;UAAEC,KAAK;QAIjClB,EAAE,GAAG,MAAI,CAACmB,SAAS,CAACnB,EAAE,EAAEa,OAAO,EAAEhC,KAAK,EAAE,MAAI,CAACpC,OAAO,CAAC;QACrDwD,EAAE,GAAG,MAAI,CAACkB,SAAS,CAAClB,EAAE,EAAEa,OAAO,EAAE/B,KAAK,EAAE,MAAI,CAACtC,OAAO,CAAC;QACrDyD,EAAE,GAAG,MAAI,CAACiB,SAAS,CAACjB,EAAE,EAAEa,OAAO,EAAEE,KAAK,EAAE,MAAI,CAACxE,OAAO,CAAC;QACrD0D,EAAE,GAAG,MAAI,CAACgB,SAAS,CAAChB,EAAE,EAAEa,OAAO,EAAEE,KAAK,EAAE,MAAI,CAACzE,OAAO,CAAC;QAErD,kBACIpE,GAAG,CAACsI,KAAK,CACL,MAAI,CAACxC,eAAe,CAACyC,IAAI,EAAE,EAAElD,YAAY,EAAEgD,iBAAiB,CAAC;UAAA;UAF9DU,UAAU;UAAEC,UAAU;UAAEC,UAAU;UAAEC,UAAU;QAIrDjB,EAAE,GAAG,MAAI,CAACkB,aAAa,CAAClB,EAAE,EAAEc,UAAU,CAAC;QACvCb,EAAE,GAAG,MAAI,CAACiB,aAAa,CAACjB,EAAE,EAAEc,UAAU,CAAC;QACvCb,EAAE,GAAG,MAAI,CAACgB,aAAa,CAAChB,EAAE,EAAEc,UAAU,CAAC;QACvCb,EAAE,GAAG,MAAI,CAACe,aAAa,CAACf,EAAE,EAAEc,UAAU,CAAC;QAEvC,IAAME,CAAC,GAAG,MAAI,CAACC,mBAAmB,CAAC5C,KAAK,CAACzG,GAAG,CAACsJ,GAAG,CAAC3B,EAAE,EAAEM,EAAE,CAAC,CAAC;QACzD,IAAMsB,CAAC,GAAG,MAAI,CAACF,mBAAmB,CAAC5C,KAAK,CAACzG,GAAG,CAACsJ,GAAG,CAAC1B,EAAE,EAAEM,EAAE,CAAC,CAAC;QACzD,IAAMsB,CAAC,GAAGxJ,GAAG,CAACsJ,GAAG,CACbtJ,GAAG,CAAC0H,GAAG,CAAC6B,CAAC,EAAEnC,QAAQ,CAAC,EACpBpH,GAAG,CAAC0H,GAAG,CAAC0B,CAAC,EAAE,MAAI,CAACK,UAAU,CAAChD,KAAK,CAACzG,GAAG,CAACsJ,GAAG,CAACzB,EAAE,EAAEM,EAAE,CAAC,CAAC,CAAC,CAAC;QACvD,IAAM3D,CAAC,GAAGxE,GAAG,CAAC0H,GAAG,CACb,MAAI,CAAC2B,mBAAmB,CAAC5C,KAAK,CAACzG,GAAG,CAACsJ,GAAG,CAACxB,EAAE,EAAEM,EAAE,CAAC,CAAC,EAC/C,MAAI,CAACqB,UAAU,CAAChD,KAAK,CAAC+C,CAAC,CAAC,CAAC;QAE7B,OAAO,CAAChF,CAAC,EAAEA,CAAC,EAAEgF,CAAC,CAAC;MAClB,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MACV;QAAUE,CAAC,KAAoC,CAA9C,OAAO;QAAQC,UAAU,cAA1B,SAA2B,CAAoB;MAErD,IAAMC,MAAM,GAAiC;QAC3C1F,OAAO,EAAE,IAAI,CAACA,OAAO;QACrBC,UAAU,EAAE,IAAI,CAACA,UAAU;QAC3BC,OAAO,EAAE,IAAI,CAACA,OAAO;QACrBH,UAAU,EAAE,IAAI,CAACA,UAAU;QAC3BK,YAAY,EAAE,IAAI,CAACA,YAAY;QAC/BD,OAAO,EAAE,IAAI,CAACA;OACf;MAED,uCAAWsF,UAAU,GAAKC,MAAM;IAClC;EAAC;IAAA;IAAA,OAED,mBAAU1C,CAAS,EAAEzC,CAAS,EAAEoF,CAAU,EAAEzF,OAAqB;MAC/D,IAAM0F,GAAG,GAAG9J,GAAG,CAAC+J,MAAM,CAClB7C,CAAiB,EAAEzC,CAAiB,EAAE,IAAI,CAACJ,OAA2B,EACrED,OAAO,IAAI,OAAO,EACnB,IAAI,CAACH,UAAU,KAAK,eAAe,GAAG,MAAM,GAAG,MAAM,EACrD,IAAI,CAACK,YAAgC,CAAC;MAE1C,IAAIuF,CAAC,EAAE;QACL,OAAO3J,CAAC,CAAC8J,OAAO,CAACF,GAAG,EAAED,CAAC,EAAE,IAAI,CAAC5F,UAAU,CAAiB;;MAG3D,OAAO6F,GAAG;IACZ;EAAC;IAAA;IAAA,OAED,uBAAc5C,CAAS,EAAEzC,CAAS;MAChC,IAAMJ,OAAO,GAAG,CAAC;MAEjB,OAAOrE,GAAG,CAAC+J,MAAM,CACb7C,CAAiB,EAAEzC,CAAiB,EAAEJ,OAAO,EAAE,MAAM,EACrD,IAAI,CAACJ,UAAU,KAAK,eAAe,GAAG,MAAM,GAAG,MAAM,CAAC;IAC5D;EAAC;EAAA;AAAA,EA9OiClD,QAAQ;AAC1C;AACgB6D,wBAAS,GAAG,gBAAgB;AA+O9C5E,GAAG,CAACiK,aAAa,CAACC,aAAa,CAACtF,cAAc,CAAC;AAK/C,WAAauF,UAAW;EAAA;EAAA;EAItB,oBAAY/I,IAAoB;IAAA;IAC9B,IAAMI,IAAI,GAAG,IAAIoD,cAAc,CAACxD,IAAI,CAAC;IAAC,0BAEhCyD,gCAAIzD,IAAI;MAAEI,IAAI,EAAJA;IAAI,EAAuB;EAC7C;EAEA;EAAA;IAAA;IAAA,OACA,oBACI4I,GAAiD,EACjDR,MAAoC;MACtC,OAAO,IAAIQ,GAAG,CAACR,MAAM,CAAC;IACxB;EAAC;EAAA;AAAA,EAf6BzI,SAAS;AACvC;AACgBgJ,oBAAS,GAAG,YAAY;AAgB1CnK,GAAG,CAACiK,aAAa,CAACC,aAAa,CAACC,UAAU,CAAC","names":["tfc","util","K","checkDataFormat","checkPaddingMode","InputSpec","AttributeError","NotImplementedError","ValueError","Initializer","convOutputLength","normalizeArray","assertPositiveInteger","getExactlyOneShape","generateDropoutMask","LSTMCell","RNN","RNNCell","ConvRNN2DCell","ConvRNN2D","args","unroll","Array","isArray","cell","inputSpec","ndim","inputs","kwargs","tidy","dropoutMask","dispose","recurrentDropoutMask","mask","training","initialState","inputShape","outShape","computeSingleOutputShape","returnSequences","slice","returnState","fill","stateSize","shape","outputShape","stateShape","zeros","length","states","stateful","batchSize","getStates","states_","map","keptStates","name","push","index","value","expectedShape","arraysEqual","keep","state","clone","dataFormat","filters","kernelSize","padding","strides","dilationRate","isChannelsFirst","h","w","hOut","wOut","ConvLSTM2DCell","Object","units","forEach","size","stride","rate","channelAxis","inputDim","numOfKernels","kernelShape","concat","kernel","addWeight","kernelInitializer","kernelRegularizer","kernelConstraint","recurrentKernelShape","recurrentKernel","recurrentInitializer","recurrentRegularizer","recurrentConstraint","useBias","biasInitializer","unitForgetBias","init","_a","dtype","biasI","apply","biasF","ones","biasCAndO","concatenate","bias","biasRegularizer","biasConstraint","built","x","hTMinus1","cTMinus1","dropout","onesLike","count","dropoutFunc","applyDropout","mul","xI","xF","xC","xO","recurrentDropout","recDropoutMask","hI","hF","hC","hO","kernelChannelAxis","split","read","kernelI","kernelF","kernelC","kernelO","biasC","biasO","inputConv","recKernelI","recKernelF","recKernelC","recKernelO","recurrentConv","i","recurrentActivation","add","f","c","activation","_","baseConfig","config","b","out","conv2d","biasAdd","serialization","registerClass","ConvLSTM2D","cls"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\node_modules\\@tensorflow\\tfjs-layers\\src\\layers\\convolutional_recurrent.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\nimport {Activation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {checkDataFormat, checkPaddingMode} from '../common';\nimport {Constraint} from '../constraints';\nimport {InputSpec} from '../engine/topology';\nimport {AttributeError, NotImplementedError, ValueError} from '../errors';\nimport {Initializer} from '../initializers';\nimport {DataFormat, DataType, PaddingMode, Shape} from '../keras_format/common';\nimport {Regularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {convOutputLength, normalizeArray} from '../utils/conv_utils';\nimport {assertPositiveInteger} from '../utils/generic_utils';\nimport {getExactlyOneShape} from '../utils/types_utils';\n\nimport {BaseRNNLayerArgs, generateDropoutMask, LSTMCell, LSTMCellLayerArgs, LSTMLayerArgs, RNN, RNNCell, RNNLayerArgs, SimpleRNNCellLayerArgs} from './recurrent';\n\ndeclare interface ConvRNN2DCellArgs extends\n    Omit<SimpleRNNCellLayerArgs, 'units'> {\n  /**\n   * The dimensionality of the output space (i.e. the number of filters in the\n   * convolution).\n   */\n  filters: number;\n\n  /**\n   * The dimensions of the convolution window. If kernelSize is a number, the\n   * convolutional window will be square.\n   */\n  kernelSize: number|number[];\n\n  /**\n   * The strides of the convolution in each dimension. If strides is a number,\n   * strides in both dimensions are equal.\n   *\n   * Specifying any stride value != 1 is incompatible with specifying any\n   * `dilationRate` value != 1.\n   */\n  strides?: number|number[];\n\n  /**\n   * Padding mode.\n   */\n  padding?: PaddingMode;\n\n  /**\n   * Format of the data, which determines the ordering of the dimensions in\n   * the inputs.\n   *\n   * `channels_last` corresponds to inputs with shape\n   *   `(batch, ..., channels)`\n   *\n   *  `channels_first` corresponds to inputs with shape `(batch, channels,\n   * ...)`.\n   *\n   * Defaults to `channels_last`.\n   */\n  dataFormat?: DataFormat;\n\n  /**\n   * The dilation rate to use for the dilated convolution in each dimension.\n   * Should be an integer or array of two or three integers.\n   *\n   * Currently, specifying any `dilationRate` value != 1 is incompatible with\n   * specifying any `strides` value != 1.\n   */\n  dilationRate?: number|[number]|[number, number];\n}\n\nabstract class ConvRNN2DCell extends RNNCell {\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  readonly activation: Activation;\n  readonly useBias: boolean;\n\n  readonly kernelInitializer: Initializer;\n  readonly recurrentInitializer: Initializer;\n  readonly biasInitializer: Initializer;\n\n  readonly kernelConstraint: Constraint;\n  readonly recurrentConstraint: Constraint;\n  readonly biasConstraint: Constraint;\n\n  readonly kernelRegularizer: Regularizer;\n  readonly recurrentRegularizer: Regularizer;\n  readonly biasRegularizer: Regularizer;\n\n  readonly dropout: number;\n  readonly recurrentDropout: number;\n}\n\ndeclare interface ConvRNN2DLayerArgs extends BaseRNNLayerArgs,\n                                             ConvRNN2DCellArgs {}\n\n/**\n * Base class for convolutional-recurrent layers.\n */\nclass ConvRNN2D extends RNN {\n  /** @nocollapse */\n  static override className = 'ConvRNN2D';\n\n  declare readonly cell: ConvRNN2DCell;\n\n  constructor(args: ConvRNN2DLayerArgs) {\n    if (args.unroll) {\n      throw new NotImplementedError(\n          'Unrolling is not possible with convolutional RNNs.');\n    }\n\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError(\n          'It is not possible at the moment to stack convolutional cells.');\n    }\n\n    super(args as RNNLayerArgs);\n\n    this.inputSpec = [new InputSpec({ndim: 5})];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tfc.tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n\n        this.cell.dropoutMask = null;\n      }\n\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n\n        this.cell.recurrentDropoutMask = null;\n      }\n\n      if (kwargs && kwargs['constants']) {\n        throw new ValueError('ConvRNN2D cell does not support constants');\n      }\n\n      const mask = kwargs == null ? null : kwargs['mask'];\n\n      const training = kwargs == null ? null : kwargs['training'];\n\n      const initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n\n      return super.call(inputs, {mask, training, initialState});\n    });\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape|Shape[] {\n    let outShape: Shape = this.computeSingleOutputShape(inputShape);\n\n    if (!this.returnSequences) {\n      outShape = [outShape[0], ...outShape.slice(2)];\n    }\n\n    if (this.returnState) {\n      outShape =\n          [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n    }\n\n    return outShape;\n  }\n\n  override getInitialState(inputs: tfc.Tensor): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      const {stateSize} = this.cell;\n\n      const inputShape = inputs.shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const initialState = tfc.zeros(stateShape);\n\n      if (Array.isArray(stateSize)) {\n        return Array(stateSize.length).fill(initialState);\n      }\n\n      return [initialState];\n    });\n  }\n\n  override resetStates(states?: Tensor|Tensor[], training = false): void {\n    tfc.tidy(() => {\n      if (!this.stateful) {\n        throw new AttributeError(\n            'Cannot call resetStates() on an RNN Layer that is not stateful.');\n      }\n\n      const inputShape = this.inputSpec[0].shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const batchSize = inputShape[0];\n\n      if (batchSize == null) {\n        throw new ValueError(\n            'If an RNN is stateful, it needs to know its batch size. Specify ' +\n            'the batch size of your input tensors: \\n' +\n            '- If using a Sequential model, specify the batch size by ' +\n            'passing a `batchInputShape` option to your first layer.\\n' +\n            '- If using the functional API, specify the batch size by ' +\n            'passing a `batchShape` option to your Input layer.');\n      }\n\n      // Initialize state if null.\n      if (this.getStates() == null) {\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_ = [tfc.zeros(stateShape)];\n        }\n      } else if (states == null) {\n        // Dispose old state tensors.\n        tfc.dispose(this.states_);\n\n        // For stateful RNNs, fully dispose kept old states.\n        if (this.keptStates != null) {\n          tfc.dispose(this.keptStates);\n          this.keptStates = [];\n        }\n\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_[0] = tfc.zeros(stateShape);\n        }\n      } else {\n        if (!Array.isArray(states)) {\n          states = [states];\n        }\n\n        if (states.length !== this.states_.length) {\n          throw new ValueError(\n              `Layer ${this.name} expects ${this.states_.length} state(s), ` +\n              `but it received ${states.length} state value(s). Input ` +\n              `received: ${states}`);\n        }\n\n        if (training) {\n          // Store old state tensors for complete disposal later, i.e., during\n          // the next no-arg call to this method. We do not dispose the old\n          // states immediately because that BPTT (among other things) require\n          // them.\n          this.keptStates.push(this.states_.slice());\n        } else {\n          tfc.dispose(this.states_);\n        }\n\n        for (let index = 0; index < this.states_.length; ++index) {\n          const value = states[index];\n\n          const expectedShape = stateShape;\n\n          if (!util.arraysEqual(value.shape, expectedShape)) {\n            throw new ValueError(\n                `State ${index} is incompatible with layer ${this.name}: ` +\n                `expected shape=${expectedShape}, received shape=${\n                    value.shape}`);\n          }\n\n          this.states_[index] = value;\n        }\n      }\n\n      this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n    });\n  }\n\n  protected computeSingleOutputShape(inputShape: Shape): Shape {\n    const {dataFormat, filters, kernelSize, padding, strides, dilationRate} =\n        this.cell;\n\n    const isChannelsFirst = dataFormat === 'channelsFirst';\n\n    const h = inputShape[isChannelsFirst ? 3 : 2];\n    const w = inputShape[isChannelsFirst ? 4 : 3];\n\n    const hOut = convOutputLength(\n        h, kernelSize[0], padding, strides[0], dilationRate[0]);\n    const wOut = convOutputLength(\n        w, kernelSize[1], padding, strides[1], dilationRate[1]);\n\n    const outShape: Shape = [\n      ...inputShape.slice(0, 2),\n      ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])\n    ];\n\n    return outShape;\n  }\n}\n\nexport declare interface ConvLSTM2DCellArgs extends\n    Omit<LSTMCellLayerArgs, 'units'>, ConvRNN2DCellArgs {}\n\nexport class ConvLSTM2DCell extends LSTMCell implements ConvRNN2DCell {\n  /** @nocollapse */\n  static override className = 'ConvLSTM2DCell';\n\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  constructor(args: ConvLSTM2DCellArgs) {\n    const {\n      filters,\n      kernelSize,\n      strides,\n      padding,\n      dataFormat,\n      dilationRate,\n    } = args;\n\n    super({...args, units: filters});\n\n    this.filters = filters;\n    assertPositiveInteger(this.filters, 'filters');\n\n    this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n    this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n\n    this.strides = normalizeArray(strides || 1, 2, 'strides');\n    this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n\n    this.padding = padding || 'valid';\n    checkPaddingMode(this.padding);\n\n    this.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(this.dataFormat);\n\n    this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n    this.dilationRate.forEach(\n        rate => assertPositiveInteger(rate, 'dilationRate'));\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n\n    const channelAxis =\n        this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError(\n          `The channel dimension of the input should be defined. ` +\n          `Found ${inputShape[channelAxis]}`);\n    }\n\n    const inputDim = inputShape[channelAxis];\n\n    const numOfKernels = 4;\n\n    const kernelShape =\n        this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n\n    this.kernel = this.addWeight(\n        'kernel', kernelShape, null, this.kernelInitializer,\n        this.kernelRegularizer, true, this.kernelConstraint);\n\n    const recurrentKernelShape =\n        this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n\n    this.recurrentKernel = this.addWeight(\n        'recurrent_kernel', recurrentKernelShape, null,\n        this.recurrentInitializer, this.recurrentRegularizer, true,\n        this.recurrentConstraint);\n\n    if (this.useBias) {\n      let biasInitializer: Initializer;\n\n      if (this.unitForgetBias) {\n        const init = this.biasInitializer;\n\n        const filters = this.filters;\n\n        biasInitializer = new (class CustomInit extends Initializer {\n          /** @nocollapse */\n          static className = 'CustomInit';\n\n          apply(shape: Shape, dtype?: DataType): tfc.Tensor {\n            const biasI = init.apply([filters]);\n            const biasF = tfc.ones([filters]);\n            const biasCAndO = init.apply([filters * 2]);\n            return K.concatenate([biasI, biasF, biasCAndO]);\n          }\n        })();\n      } else {\n        biasInitializer = this.biasInitializer;\n      }\n\n      this.bias = this.addWeight(\n          'bias', [this.filters * numOfKernels], null, biasInitializer,\n          this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.built = true;\n  }\n\n  override call(inputs: tfc.Tensor[], kwargs: Kwargs): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      if (inputs.length !== 3) {\n        throw new ValueError(\n            `ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` +\n            `${inputs.length}.`);\n      }\n\n      const training = kwargs['training'] || false;\n\n      const x = inputs[0];         // Current input\n      const hTMinus1 = inputs[1];  // Previous memory state.\n      const cTMinus1 = inputs[2];  // Previous carry state.\n\n      const numOfKernels = 4;\n\n      type DropoutMasks = [tfc.Tensor, tfc.Tensor, tfc.Tensor, tfc.Tensor];\n\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n                             ones: () => tfc.onesLike(x),\n                             rate: this.dropout,\n                             training,\n                             count: numOfKernels,\n                             dropoutFunc: this.dropoutFunc\n                           }) as tfc.Tensor[];\n      }\n\n      const dropoutMask = this.dropoutMask as DropoutMasks;\n\n      const applyDropout =\n          (x: tfc.Tensor, mask: tfc.Tensor[], index: number) => {\n            if (!mask || !mask[index]) {\n              return x;\n            }\n\n            return tfc.mul(mask[index], x);\n          };\n\n      let xI = applyDropout(x, dropoutMask, 0);\n      let xF = applyDropout(x, dropoutMask, 1);\n      let xC = applyDropout(x, dropoutMask, 2);\n      let xO = applyDropout(x, dropoutMask, 3);\n\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n          this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n                                      ones: () => tfc.onesLike(hTMinus1),\n                                      rate: this.recurrentDropout,\n                                      training,\n                                      count: numOfKernels,\n                                      dropoutFunc: this.dropoutFunc\n                                    }) as tfc.Tensor[];\n      }\n\n      const recDropoutMask = this.recurrentDropoutMask as DropoutMasks;\n\n      let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n      let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n      let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n      let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n\n      const kernelChannelAxis = 3;\n\n      const [kernelI, kernelF, kernelC, kernelO]: tfc.Tensor[] =\n          tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n\n      const [biasI, biasF, biasC, biasO]: tfc.Tensor[] = this.useBias ?\n          tfc.split(this.bias.read(), numOfKernels) :\n          [null, null, null, null];\n\n      xI = this.inputConv(xI, kernelI, biasI, this.padding);\n      xF = this.inputConv(xF, kernelF, biasF, this.padding);\n      xC = this.inputConv(xC, kernelC, biasC, this.padding);\n      xO = this.inputConv(xO, kernelO, biasO, this.padding);\n\n      const [recKernelI, recKernelF, recKernelC, recKernelO]: tfc.Tensor[] =\n          tfc.split(\n              this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n\n      hI = this.recurrentConv(hI, recKernelI);\n      hF = this.recurrentConv(hF, recKernelF);\n      hC = this.recurrentConv(hC, recKernelC);\n      hO = this.recurrentConv(hO, recKernelO);\n\n      const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n      const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n      const c = tfc.add(\n          tfc.mul(f, cTMinus1),\n          tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n      const h = tfc.mul(\n          this.recurrentActivation.apply(tfc.add(xO, hO)),\n          this.activation.apply(c));\n\n      return [h, h, c];\n    });\n  }\n\n  override getConfig(): tfc.serialization.ConfigDict {\n    const {'units': _, ...baseConfig} = super.getConfig();\n\n    const config: tfc.serialization.ConfigDict = {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides,\n    };\n\n    return {...baseConfig, ...config};\n  }\n\n  inputConv(x: Tensor, w: Tensor, b?: Tensor, padding?: PaddingMode) {\n    const out = tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, this.strides as [number, number],\n        (padding || 'valid') as 'same' | 'valid',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC',\n        this.dilationRate as [number, number]);\n\n    if (b) {\n      return K.biasAdd(out, b, this.dataFormat) as tfc.Tensor3D;\n    }\n\n    return out;\n  }\n\n  recurrentConv(x: Tensor, w: Tensor) {\n    const strides = 1;\n\n    return tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, strides, 'same',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2DCell);\n\nexport declare interface ConvLSTM2DArgs extends\n    Omit<LSTMLayerArgs, 'units'|'cell'>, ConvRNN2DLayerArgs {}\n\nexport class ConvLSTM2D extends ConvRNN2D {\n  /** @nocollapse */\n  static override className = 'ConvLSTM2D';\n\n  constructor(args: ConvLSTM2DArgs) {\n    const cell = new ConvLSTM2DCell(args);\n\n    super({...args, cell} as ConvRNN2DLayerArgs);\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends tfc.serialization.Serializable>(\n      cls: tfc.serialization.SerializableConstructor<T>,\n      config: tfc.serialization.ConfigDict): T {\n    return new cls(config);\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2D);\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}