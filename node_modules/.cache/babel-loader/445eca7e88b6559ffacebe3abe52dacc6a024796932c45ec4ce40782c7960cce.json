{"ast":null,"code":"import _classCallCheck from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"E:/react-detect-toxicity-in-a-chat-app-youtube-2/Toxic-Word-Checker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { eye, linalg, mul, ones, randomUniform, scalar, serialization, tidy, transpose, truncatedNormal, zeros } from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport { checkDataFormat } from './common';\nimport { NotImplementedError, ValueError } from './errors';\nimport { VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES } from './keras_format/initializer_config';\nimport { checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject } from './utils/generic_utils';\nimport { arrayProd } from './utils/math_utils';\nexport function checkFanMode(value) {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\nexport function checkDistribution(value) {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nexport var Initializer = /*#__PURE__*/function (_serialization$Serial) {\n  _inherits(Initializer, _serialization$Serial);\n  var _super = _createSuper(Initializer);\n  function Initializer() {\n    _classCallCheck(this, Initializer);\n    return _super.apply(this, arguments);\n  }\n  _createClass(Initializer, [{\n    key: \"fromConfigUsesCustomObjects\",\n    value: function fromConfigUsesCustomObjects() {\n      return false;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {};\n    }\n  }]);\n  return Initializer;\n}(serialization.Serializable);\nexport var Zeros = /*#__PURE__*/function (_Initializer) {\n  _inherits(Zeros, _Initializer);\n  var _super2 = _createSuper(Zeros);\n  function Zeros() {\n    _classCallCheck(this, Zeros);\n    return _super2.apply(this, arguments);\n  }\n  _createClass(Zeros, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      return zeros(shape, dtype);\n    }\n  }]);\n  return Zeros;\n}(Initializer);\n/** @nocollapse */\nZeros.className = 'Zeros';\nserialization.registerClass(Zeros);\nexport var Ones = /*#__PURE__*/function (_Initializer2) {\n  _inherits(Ones, _Initializer2);\n  var _super3 = _createSuper(Ones);\n  function Ones() {\n    _classCallCheck(this, Ones);\n    return _super3.apply(this, arguments);\n  }\n  _createClass(Ones, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      return ones(shape, dtype);\n    }\n  }]);\n  return Ones;\n}(Initializer);\n/** @nocollapse */\nOnes.className = 'Ones';\nserialization.registerClass(Ones);\nexport var Constant = /*#__PURE__*/function (_Initializer3) {\n  _inherits(Constant, _Initializer3);\n  var _super4 = _createSuper(Constant);\n  function Constant(args) {\n    var _this;\n    _classCallCheck(this, Constant);\n    _this = _super4.call(this);\n    if (typeof args !== 'object') {\n      throw new ValueError(\"Expected argument of type ConstantConfig but got \".concat(args));\n    }\n    if (args.value === undefined) {\n      throw new ValueError(\"config must have value set but got \".concat(args));\n    }\n    _this.value = args.value;\n    return _this;\n  }\n  _createClass(Constant, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      var _this2 = this;\n      return tidy(function () {\n        return mul(scalar(_this2.value), ones(shape, dtype));\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        value: this.value\n      };\n    }\n  }]);\n  return Constant;\n}(Initializer);\n/** @nocollapse */\nConstant.className = 'Constant';\nserialization.registerClass(Constant);\nexport var RandomUniform = /*#__PURE__*/function (_Initializer4) {\n  _inherits(RandomUniform, _Initializer4);\n  var _super5 = _createSuper(RandomUniform);\n  function RandomUniform(args) {\n    var _this3;\n    _classCallCheck(this, RandomUniform);\n    _this3 = _super5.call(this);\n    _this3.DEFAULT_MINVAL = -0.05;\n    _this3.DEFAULT_MAXVAL = 0.05;\n    _this3.minval = args.minval || _this3.DEFAULT_MINVAL;\n    _this3.maxval = args.maxval || _this3.DEFAULT_MAXVAL;\n    _this3.seed = args.seed;\n    return _this3;\n  }\n  _createClass(RandomUniform, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      return randomUniform(shape, this.minval, this.maxval, dtype, this.seed);\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        minval: this.minval,\n        maxval: this.maxval,\n        seed: this.seed\n      };\n    }\n  }]);\n  return RandomUniform;\n}(Initializer);\n/** @nocollapse */\nRandomUniform.className = 'RandomUniform';\nserialization.registerClass(RandomUniform);\nexport var RandomNormal = /*#__PURE__*/function (_Initializer5) {\n  _inherits(RandomNormal, _Initializer5);\n  var _super6 = _createSuper(RandomNormal);\n  function RandomNormal(args) {\n    var _this4;\n    _classCallCheck(this, RandomNormal);\n    _this4 = _super6.call(this);\n    _this4.DEFAULT_MEAN = 0.;\n    _this4.DEFAULT_STDDEV = 0.05;\n    _this4.mean = args.mean || _this4.DEFAULT_MEAN;\n    _this4.stddev = args.stddev || _this4.DEFAULT_STDDEV;\n    _this4.seed = args.seed;\n    return _this4;\n  }\n  _createClass(RandomNormal, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(\"randomNormal does not support dType \".concat(dtype, \".\"));\n      }\n      return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        mean: this.mean,\n        stddev: this.stddev,\n        seed: this.seed\n      };\n    }\n  }]);\n  return RandomNormal;\n}(Initializer);\n/** @nocollapse */\nRandomNormal.className = 'RandomNormal';\nserialization.registerClass(RandomNormal);\nexport var TruncatedNormal = /*#__PURE__*/function (_Initializer6) {\n  _inherits(TruncatedNormal, _Initializer6);\n  var _super7 = _createSuper(TruncatedNormal);\n  function TruncatedNormal(args) {\n    var _this5;\n    _classCallCheck(this, TruncatedNormal);\n    _this5 = _super7.call(this);\n    _this5.DEFAULT_MEAN = 0.;\n    _this5.DEFAULT_STDDEV = 0.05;\n    _this5.mean = args.mean || _this5.DEFAULT_MEAN;\n    _this5.stddev = args.stddev || _this5.DEFAULT_STDDEV;\n    _this5.seed = args.seed;\n    return _this5;\n  }\n  _createClass(TruncatedNormal, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(\"truncatedNormal does not support dType \".concat(dtype, \".\"));\n      }\n      return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        mean: this.mean,\n        stddev: this.stddev,\n        seed: this.seed\n      };\n    }\n  }]);\n  return TruncatedNormal;\n}(Initializer);\n/** @nocollapse */\nTruncatedNormal.className = 'TruncatedNormal';\nserialization.registerClass(TruncatedNormal);\nexport var Identity = /*#__PURE__*/function (_Initializer7) {\n  _inherits(Identity, _Initializer7);\n  var _super8 = _createSuper(Identity);\n  function Identity(args) {\n    var _this6;\n    _classCallCheck(this, Identity);\n    _this6 = _super8.call(this);\n    _this6.gain = args.gain != null ? args.gain : 1.0;\n    return _this6;\n  }\n  _createClass(Identity, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      var _this7 = this;\n      return tidy(function () {\n        if (shape.length !== 2 || shape[0] !== shape[1]) {\n          throw new ValueError('Identity matrix initializer can only be used for' + ' 2D square matrices.');\n        } else {\n          return mul(_this7.gain, eye(shape[0]));\n        }\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        gain: this.gain\n      };\n    }\n  }]);\n  return Identity;\n}(Initializer);\n/** @nocollapse */\nIdentity.className = 'Identity';\nserialization.registerClass(Identity);\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(shape) {\n  var dataFormat = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'channelsLast';\n  var fanIn;\n  var fanOut;\n  checkDataFormat(dataFormat);\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      var receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      var _receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * _receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * _receptiveFieldSize;\n    }\n  } else {\n    var shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n  return [fanIn, fanOut];\n}\nexport var VarianceScaling = /*#__PURE__*/function (_Initializer8) {\n  _inherits(VarianceScaling, _Initializer8);\n  var _super9 = _createSuper(VarianceScaling);\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  function VarianceScaling(args) {\n    var _this8;\n    _classCallCheck(this, VarianceScaling);\n    _this8 = _super9.call(this);\n    if (args.scale < 0.0) {\n      throw new ValueError(\"scale must be a positive float. Got: \".concat(args.scale));\n    }\n    _this8.scale = args.scale == null ? 1.0 : args.scale;\n    _this8.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(_this8.mode);\n    _this8.distribution = args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(_this8.distribution);\n    _this8.seed = args.seed;\n    return _this8;\n  }\n  _createClass(VarianceScaling, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      var fans = computeFans(shape);\n      var fanIn = fans[0];\n      var fanOut = fans[1];\n      var scale = this.scale;\n      if (this.mode === 'fanIn') {\n        scale /= Math.max(1, fanIn);\n      } else if (this.mode === 'fanOut') {\n        scale /= Math.max(1, fanOut);\n      } else {\n        scale /= Math.max(1, (fanIn + fanOut) / 2);\n      }\n      if (this.distribution === 'normal') {\n        var stddev = Math.sqrt(scale);\n        dtype = dtype || 'float32';\n        if (dtype !== 'float32' && dtype !== 'int32') {\n          throw new NotImplementedError(\"\".concat(this.getClassName(), \" does not support dType \").concat(dtype, \".\"));\n        }\n        return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n      } else {\n        var limit = Math.sqrt(3 * scale);\n        return randomUniform(shape, -limit, limit, dtype, this.seed);\n      }\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        scale: this.scale,\n        mode: this.mode,\n        distribution: this.distribution,\n        seed: this.seed\n      };\n    }\n  }]);\n  return VarianceScaling;\n}(Initializer);\n/** @nocollapse */\nVarianceScaling.className = 'VarianceScaling';\nserialization.registerClass(VarianceScaling);\nexport var GlorotUniform = /*#__PURE__*/function (_VarianceScaling) {\n  _inherits(GlorotUniform, _VarianceScaling);\n  var _super10 = _createSuper(GlorotUniform);\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  function GlorotUniform(args) {\n    _classCallCheck(this, GlorotUniform);\n    return _super10.call(this, {\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n  _createClass(GlorotUniform, [{\n    key: \"getClassName\",\n    value: function getClassName() {\n      // In Python Keras, GlorotUniform is not a class, but a helper method\n      // that creates a VarianceScaling object. Use 'VarianceScaling' as\n      // class name to be compatible with that.\n      return VarianceScaling.className;\n    }\n  }]);\n  return GlorotUniform;\n}(VarianceScaling);\n/** @nocollapse */\nGlorotUniform.className = 'GlorotUniform';\nserialization.registerClass(GlorotUniform);\nexport var GlorotNormal = /*#__PURE__*/function (_VarianceScaling2) {\n  _inherits(GlorotNormal, _VarianceScaling2);\n  var _super11 = _createSuper(GlorotNormal);\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  function GlorotNormal(args) {\n    _classCallCheck(this, GlorotNormal);\n    return _super11.call(this, {\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n  _createClass(GlorotNormal, [{\n    key: \"getClassName\",\n    value: function getClassName() {\n      // In Python Keras, GlorotNormal is not a class, but a helper method\n      // that creates a VarianceScaling object. Use 'VarianceScaling' as\n      // class name to be compatible with that.\n      return VarianceScaling.className;\n    }\n  }]);\n  return GlorotNormal;\n}(VarianceScaling);\n/** @nocollapse */\nGlorotNormal.className = 'GlorotNormal';\nserialization.registerClass(GlorotNormal);\nexport var HeNormal = /*#__PURE__*/function (_VarianceScaling3) {\n  _inherits(HeNormal, _VarianceScaling3);\n  var _super12 = _createSuper(HeNormal);\n  function HeNormal(args) {\n    _classCallCheck(this, HeNormal);\n    return _super12.call(this, {\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n  _createClass(HeNormal, [{\n    key: \"getClassName\",\n    value: function getClassName() {\n      // In Python Keras, HeNormal is not a class, but a helper method\n      // that creates a VarianceScaling object. Use 'VarianceScaling' as\n      // class name to be compatible with that.\n      return VarianceScaling.className;\n    }\n  }]);\n  return HeNormal;\n}(VarianceScaling);\n/** @nocollapse */\nHeNormal.className = 'HeNormal';\nserialization.registerClass(HeNormal);\nexport var HeUniform = /*#__PURE__*/function (_VarianceScaling4) {\n  _inherits(HeUniform, _VarianceScaling4);\n  var _super13 = _createSuper(HeUniform);\n  function HeUniform(args) {\n    _classCallCheck(this, HeUniform);\n    return _super13.call(this, {\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n  _createClass(HeUniform, [{\n    key: \"getClassName\",\n    value: function getClassName() {\n      // In Python Keras, HeUniform is not a class, but a helper method\n      // that creates a VarianceScaling object. Use 'VarianceScaling' as\n      // class name to be compatible with that.\n      return VarianceScaling.className;\n    }\n  }]);\n  return HeUniform;\n}(VarianceScaling);\n/** @nocollapse */\nHeUniform.className = 'HeUniform';\nserialization.registerClass(HeUniform);\nexport var LeCunNormal = /*#__PURE__*/function (_VarianceScaling5) {\n  _inherits(LeCunNormal, _VarianceScaling5);\n  var _super14 = _createSuper(LeCunNormal);\n  function LeCunNormal(args) {\n    _classCallCheck(this, LeCunNormal);\n    return _super14.call(this, {\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n  _createClass(LeCunNormal, [{\n    key: \"getClassName\",\n    value: function getClassName() {\n      // In Python Keras, LeCunNormal is not a class, but a helper method\n      // that creates a VarianceScaling object. Use 'VarianceScaling' as\n      // class name to be compatible with that.\n      return VarianceScaling.className;\n    }\n  }]);\n  return LeCunNormal;\n}(VarianceScaling);\n/** @nocollapse */\nLeCunNormal.className = 'LeCunNormal';\nserialization.registerClass(LeCunNormal);\nexport var LeCunUniform = /*#__PURE__*/function (_VarianceScaling6) {\n  _inherits(LeCunUniform, _VarianceScaling6);\n  var _super15 = _createSuper(LeCunUniform);\n  function LeCunUniform(args) {\n    _classCallCheck(this, LeCunUniform);\n    return _super15.call(this, {\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n  _createClass(LeCunUniform, [{\n    key: \"getClassName\",\n    value: function getClassName() {\n      // In Python Keras, LeCunUniform is not a class, but a helper method\n      // that creates a VarianceScaling object. Use 'VarianceScaling' as\n      // class name to be compatible with that.\n      return VarianceScaling.className;\n    }\n  }]);\n  return LeCunUniform;\n}(VarianceScaling);\n/** @nocollapse */\nLeCunUniform.className = 'LeCunUniform';\nserialization.registerClass(LeCunUniform);\nexport var Orthogonal = /*#__PURE__*/function (_Initializer9) {\n  _inherits(Orthogonal, _Initializer9);\n  var _super16 = _createSuper(Orthogonal);\n  function Orthogonal(args) {\n    var _this9;\n    _classCallCheck(this, Orthogonal);\n    _this9 = _super16.call(this);\n    _this9.DEFAULT_GAIN = 1;\n    _this9.gain = args.gain == null ? _this9.DEFAULT_GAIN : args.gain;\n    _this9.seed = args.seed;\n    if (_this9.seed != null) {\n      throw new NotImplementedError('Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n    return _this9;\n  }\n  _createClass(Orthogonal, [{\n    key: \"apply\",\n    value: function apply(shape, dtype) {\n      var _this10 = this;\n      return tidy(function () {\n        if (shape.length < 2) {\n          throw new NotImplementedError('Shape must be at least 2D.');\n        }\n        if (shape[0] * shape[1] > 2000) {\n          console.warn(\"Orthogonal initializer is being called on a matrix with more \" + \"than 2000 (\".concat(shape[0] * shape[1], \") elements: \") + \"Slowness may result.\");\n        }\n        // TODO(cais): Add seed support.\n        var normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n        var a = K.randomNormal(normalizedShape, 0, 1, 'float32');\n        var q = linalg.gramSchmidt(a);\n        if (shape[0] > shape[1]) {\n          q = transpose(q);\n        }\n        return mul(_this10.gain, q);\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      return {\n        gain: this.gain,\n        seed: this.seed\n      };\n    }\n  }]);\n  return Orthogonal;\n}(Initializer);\n/** @nocollapse */\nOrthogonal.className = 'Orthogonal';\nserialization.registerClass(Orthogonal);\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexport var INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {\n  'constant': 'Constant',\n  'glorotNormal': 'GlorotNormal',\n  'glorotUniform': 'GlorotUniform',\n  'heNormal': 'HeNormal',\n  'heUniform': 'HeUniform',\n  'identity': 'Identity',\n  'leCunNormal': 'LeCunNormal',\n  'leCunUniform': 'LeCunUniform',\n  'ones': 'Ones',\n  'orthogonal': 'Orthogonal',\n  'randomNormal': 'RandomNormal',\n  'randomUniform': 'RandomUniform',\n  'truncatedNormal': 'TruncatedNormal',\n  'varianceScaling': 'VarianceScaling',\n  'zeros': 'Zeros'\n};\nfunction deserializeInitializer(config) {\n  var customObjects = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return deserializeKerasObject(config, serialization.SerializationMap.getMap().classNameMap, customObjects, 'initializer');\n}\nexport function serializeInitializer(initializer) {\n  return serializeKerasObject(initializer);\n}\nexport function getInitializer(identifier) {\n  if (typeof identifier === 'string') {\n    var className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      var config = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}","map":{"version":3,"mappings":";;;;AAAA;;;;;;;;;AAUA,SAAkBA,GAAG,EAAEC,MAAM,EAAEC,GAAG,EAAEC,IAAI,EAAEC,aAAa,EAAEC,MAAM,EAAEC,aAAa,EAAoBC,IAAI,EAAEC,SAAS,EAAEC,eAAe,EAAEC,KAAK,QAAO,uBAAuB;AAEvK,OAAO,KAAKC,CAAC,MAAM,wBAAwB;AAC3C,SAAQC,eAAe,QAAO,UAAU;AACxC,SAAQC,mBAAmB,EAAEC,UAAU,QAAO,UAAU;AAExD,SAA+BC,yBAAyB,EAAEC,qBAAqB,QAAO,mCAAmC;AACzH,SAAQC,yBAAyB,EAAEC,sBAAsB,EAAEC,oBAAoB,QAAO,uBAAuB;AAC7G,SAAQC,SAAS,QAAO,oBAAoB;AAE5C,OAAM,SAAUC,YAAY,CAACC,KAAc;EACzCL,yBAAyB,CAACD,qBAAqB,EAAE,SAAS,EAAEM,KAAK,CAAC;AACpE;AAEA,OAAM,SAAUC,iBAAiB,CAACD,KAAc;EAC9CL,yBAAyB,CAACF,yBAAyB,EAAE,cAAc,EAAEO,KAAK,CAAC;AAC7E;AAEA;;;;;;AAMA,WAAsBE,WAAY;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OACzB,uCAA2B;MAChC,OAAO,KAAK;IACd;EAAC;IAAA;IAAA,OASD,qBAAS;MACP,OAAO,EAAE;IACX;EAAC;EAAA;AAAA,EAduClB,aAAa,CAACmB,YAAY;AAiBpE,WAAaC,KAAM;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OAIjB,eAAMC,KAAY,EAAEC,KAAgB;MAClC,OAAOlB,KAAK,CAACiB,KAAK,EAAEC,KAAK,CAAC;IAC5B;EAAC;EAAA;AAAA,EANwBJ,WAAW;AACpC;AACOE,eAAS,GAAG,OAAO;AAM5BpB,aAAa,CAACuB,aAAa,CAACH,KAAK,CAAC;AAElC,WAAaI,IAAK;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OAIhB,eAAMH,KAAY,EAAEC,KAAgB;MAClC,OAAOzB,IAAI,CAACwB,KAAK,EAAEC,KAAK,CAAC;IAC3B;EAAC;EAAA;AAAA,EANuBJ,WAAW;AACnC;AACOM,cAAS,GAAG,MAAM;AAM3BxB,aAAa,CAACuB,aAAa,CAACC,IAAI,CAAC;AAOjC,WAAaC,QAAS;EAAA;EAAA;EAIpB,kBAAYC,IAAkB;IAAA;IAAA;IAC5B;IACA,IAAI,OAAOA,IAAI,KAAK,QAAQ,EAAE;MAC5B,MAAM,IAAIlB,UAAU,4DACoCkB,IAAI,EAAG;;IAEjE,IAAIA,IAAI,CAACV,KAAK,KAAKW,SAAS,EAAE;MAC5B,MAAM,IAAInB,UAAU,8CAAuCkB,IAAI,EAAG;;IAEpE,MAAKV,KAAK,GAAGU,IAAI,CAACV,KAAK;IAAC;EAC1B;EAAC;IAAA;IAAA,OAED,eAAMK,KAAY,EAAEC,KAAgB;MAAA;MAClC,OAAOrB,IAAI,CAAC;QAAA,OAAML,GAAG,CAACG,MAAM,CAAC,MAAI,CAACiB,KAAK,CAAC,EAAEnB,IAAI,CAACwB,KAAK,EAAEC,KAAK,CAAC,CAAC;MAAA,EAAC;IAChE;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,OAAO;QACLN,KAAK,EAAE,IAAI,CAACA;OACb;IACH;EAAC;EAAA;AAAA,EAxB2BE,WAAW;AACvC;AACOO,kBAAS,GAAG,UAAU;AAwB/BzB,aAAa,CAACuB,aAAa,CAACE,QAAQ,CAAC;AAWrC,WAAaG,aAAc;EAAA;EAAA;EASzB,uBAAYF,IAAuB;IAAA;IAAA;IACjC;IAPO,qBAAc,GAAG,CAAC,IAAI;IACtB,qBAAc,GAAG,IAAI;IAO5B,OAAKG,MAAM,GAAGH,IAAI,CAACG,MAAM,IAAI,OAAKC,cAAc;IAChD,OAAKC,MAAM,GAAGL,IAAI,CAACK,MAAM,IAAI,OAAKC,cAAc;IAChD,OAAKC,IAAI,GAAGP,IAAI,CAACO,IAAI;IAAC;EACxB;EAAC;IAAA;IAAA,OAED,eAAMZ,KAAY,EAAEC,KAAgB;MAClC,OAAOxB,aAAa,CAACuB,KAAK,EAAE,IAAI,CAACQ,MAAM,EAAE,IAAI,CAACE,MAAM,EAAET,KAAK,EAAE,IAAI,CAACW,IAAI,CAAC;IACzE;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,OAAO;QAACJ,MAAM,EAAE,IAAI,CAACA,MAAM;QAAEE,MAAM,EAAE,IAAI,CAACA,MAAM;QAAEE,IAAI,EAAE,IAAI,CAACA;MAAI,CAAC;IACpE;EAAC;EAAA;AAAA,EAtBgCf,WAAW;AAC5C;AACOU,uBAAS,GAAG,eAAe;AAsBpC5B,aAAa,CAACuB,aAAa,CAACK,aAAa,CAAC;AAW1C,WAAaM,YAAa;EAAA;EAAA;EASxB,sBAAYR,IAAsB;IAAA;IAAA;IAChC;IAPO,mBAAY,GAAG,EAAE;IACjB,qBAAc,GAAG,IAAI;IAO5B,OAAKS,IAAI,GAAGT,IAAI,CAACS,IAAI,IAAI,OAAKC,YAAY;IAC1C,OAAKC,MAAM,GAAGX,IAAI,CAACW,MAAM,IAAI,OAAKC,cAAc;IAChD,OAAKL,IAAI,GAAGP,IAAI,CAACO,IAAI;IAAC;EACxB;EAAC;IAAA;IAAA,OAED,eAAMZ,KAAY,EAAEC,KAAgB;MAClCA,KAAK,GAAGA,KAAK,IAAI,SAAS;MAC1B,IAAIA,KAAK,KAAK,SAAS,IAAIA,KAAK,KAAK,OAAO,EAAE;QAC5C,MAAM,IAAIf,mBAAmB,+CACce,KAAK,OAAI;;MAGtD,OAAOjB,CAAC,CAACkC,YAAY,CAAClB,KAAK,EAAE,IAAI,CAACc,IAAI,EAAE,IAAI,CAACE,MAAM,EAAEf,KAAK,EAAE,IAAI,CAACW,IAAI,CAAC;IACxE;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,OAAO;QAACE,IAAI,EAAE,IAAI,CAACA,IAAI;QAAEE,MAAM,EAAE,IAAI,CAACA,MAAM;QAAEJ,IAAI,EAAE,IAAI,CAACA;MAAI,CAAC;IAChE;EAAC;EAAA;AAAA,EA5B+Bf,WAAW;AAC3C;AACOgB,sBAAS,GAAG,cAAc;AA4BnClC,aAAa,CAACuB,aAAa,CAACW,YAAY,CAAC;AAWzC,WAAaM,eAAgB;EAAA;EAAA;EAU3B,yBAAYd,IAAyB;IAAA;IAAA;IACnC;IAPO,mBAAY,GAAG,EAAE;IACjB,qBAAc,GAAG,IAAI;IAO5B,OAAKS,IAAI,GAAGT,IAAI,CAACS,IAAI,IAAI,OAAKC,YAAY;IAC1C,OAAKC,MAAM,GAAGX,IAAI,CAACW,MAAM,IAAI,OAAKC,cAAc;IAChD,OAAKL,IAAI,GAAGP,IAAI,CAACO,IAAI;IAAC;EACxB;EAAC;IAAA;IAAA,OAED,eAAMZ,KAAY,EAAEC,KAAgB;MAClCA,KAAK,GAAGA,KAAK,IAAI,SAAS;MAC1B,IAAIA,KAAK,KAAK,SAAS,IAAIA,KAAK,KAAK,OAAO,EAAE;QAC5C,MAAM,IAAIf,mBAAmB,kDACiBe,KAAK,OAAI;;MAEzD,OAAOnB,eAAe,CAACkB,KAAK,EAAE,IAAI,CAACc,IAAI,EAAE,IAAI,CAACE,MAAM,EAAEf,KAAK,EAAE,IAAI,CAACW,IAAI,CAAC;IACzE;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,OAAO;QAACE,IAAI,EAAE,IAAI,CAACA,IAAI;QAAEE,MAAM,EAAE,IAAI,CAACA,MAAM;QAAEJ,IAAI,EAAE,IAAI,CAACA;MAAI,CAAC;IAChE;EAAC;EAAA;AAAA,EA5BkCf,WAAW;AAC9C;AACOsB,yBAAS,GAAG,iBAAiB;AA4BtCxC,aAAa,CAACuB,aAAa,CAACiB,eAAe,CAAC;AAS5C,WAAaC,QAAS;EAAA;EAAA;EAIpB,kBAAYf,IAAkB;IAAA;IAAA;IAC5B;IACA,OAAKgB,IAAI,GAAGhB,IAAI,CAACgB,IAAI,IAAI,IAAI,GAAGhB,IAAI,CAACgB,IAAI,GAAG,GAAG;IAAC;EAClD;EAAC;IAAA;IAAA,OAED,eAAMrB,KAAY,EAAEC,KAAgB;MAAA;MAClC,OAAOrB,IAAI,CAAC,YAAK;QACf,IAAIoB,KAAK,CAACsB,MAAM,KAAK,CAAC,IAAItB,KAAK,CAAC,CAAC,CAAC,KAAKA,KAAK,CAAC,CAAC,CAAC,EAAE;UAC/C,MAAM,IAAIb,UAAU,CAChB,kDAAkD,GAClD,sBAAsB,CAAC;SAC5B,MAAM;UACL,OAAOZ,GAAG,CAAC,MAAI,CAAC8C,IAAI,EAAEhD,GAAG,CAAC2B,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;;MAExC,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,OAAO;QAACqB,IAAI,EAAE,IAAI,CAACA;MAAI,CAAC;IAC1B;EAAC;EAAA;AAAA,EAvB2BxB,WAAW;AACvC;AACOuB,kBAAS,GAAG,UAAU;AAuB/BzC,aAAa,CAACuB,aAAa,CAACkB,QAAQ,CAAC;AAErC;;;;;;;;AAQA,SAASG,WAAW,CAChBvB,KAAY,EAAyC;EAAA,IAAvCwB,iFAAyB,cAAc;EACvD,IAAIC,KAAa;EACjB,IAAIC,MAAc;EAClBzC,eAAe,CAACuC,UAAU,CAAC;EAC3B,IAAIxB,KAAK,CAACsB,MAAM,KAAK,CAAC,EAAE;IACtBG,KAAK,GAAGzB,KAAK,CAAC,CAAC,CAAC;IAChB0B,MAAM,GAAG1B,KAAK,CAAC,CAAC,CAAC;GAClB,MAAM,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC2B,OAAO,CAAC3B,KAAK,CAACsB,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE;IACjD,IAAIE,UAAU,KAAK,eAAe,EAAE;MAClC,IAAMI,kBAAkB,GAAGnC,SAAS,CAACO,KAAK,EAAE,CAAC,CAAC;MAC9CyB,KAAK,GAAGzB,KAAK,CAAC,CAAC,CAAC,GAAG4B,kBAAkB;MACrCF,MAAM,GAAG1B,KAAK,CAAC,CAAC,CAAC,GAAG4B,kBAAkB;KACvC,MAAM,IAAIJ,UAAU,KAAK,cAAc,EAAE;MACxC,IAAMI,mBAAkB,GAAGnC,SAAS,CAACO,KAAK,EAAE,CAAC,EAAEA,KAAK,CAACsB,MAAM,GAAG,CAAC,CAAC;MAChEG,KAAK,GAAGzB,KAAK,CAACA,KAAK,CAACsB,MAAM,GAAG,CAAC,CAAC,GAAGM,mBAAkB;MACpDF,MAAM,GAAG1B,KAAK,CAACA,KAAK,CAACsB,MAAM,GAAG,CAAC,CAAC,GAAGM,mBAAkB;;GAExD,MAAM;IACL,IAAMC,SAAS,GAAGpC,SAAS,CAACO,KAAK,CAAC;IAClCyB,KAAK,GAAGK,IAAI,CAACC,IAAI,CAACF,SAAS,CAAC;IAC5BH,MAAM,GAAGI,IAAI,CAACC,IAAI,CAACF,SAAS,CAAC;;EAG/B,OAAO,CAACJ,KAAK,EAAEC,MAAM,CAAC;AACxB;AAgBA,WAAaM,eAAgB;EAAA;EAAA;EAQ3B;;;;EAIA,yBAAY3B,IAAyB;IAAA;IAAA;IACnC;IACA,IAAIA,IAAI,CAAC4B,KAAK,GAAG,GAAG,EAAE;MACpB,MAAM,IAAI9C,UAAU,gDACwBkB,IAAI,CAAC4B,KAAK,EAAG;;IAE3D,OAAKA,KAAK,GAAG5B,IAAI,CAAC4B,KAAK,IAAI,IAAI,GAAG,GAAG,GAAG5B,IAAI,CAAC4B,KAAK;IAClD,OAAKC,IAAI,GAAG7B,IAAI,CAAC6B,IAAI,IAAI,IAAI,GAAG,OAAO,GAAG7B,IAAI,CAAC6B,IAAI;IACnDxC,YAAY,CAAC,OAAKwC,IAAI,CAAC;IACvB,OAAKC,YAAY,GACb9B,IAAI,CAAC8B,YAAY,IAAI,IAAI,GAAG,QAAQ,GAAG9B,IAAI,CAAC8B,YAAY;IAC5DvC,iBAAiB,CAAC,OAAKuC,YAAY,CAAC;IACpC,OAAKvB,IAAI,GAAGP,IAAI,CAACO,IAAI;IAAC;EACxB;EAAC;IAAA;IAAA,OAED,eAAMZ,KAAY,EAAEC,KAAgB;MAClC,IAAMmC,IAAI,GAAGb,WAAW,CAACvB,KAAK,CAAC;MAC/B,IAAMyB,KAAK,GAAGW,IAAI,CAAC,CAAC,CAAC;MACrB,IAAMV,MAAM,GAAGU,IAAI,CAAC,CAAC,CAAC;MACtB,IAAIH,KAAK,GAAG,IAAI,CAACA,KAAK;MACtB,IAAI,IAAI,CAACC,IAAI,KAAK,OAAO,EAAE;QACzBD,KAAK,IAAIH,IAAI,CAACO,GAAG,CAAC,CAAC,EAAEZ,KAAK,CAAC;OAC5B,MAAM,IAAI,IAAI,CAACS,IAAI,KAAK,QAAQ,EAAE;QACjCD,KAAK,IAAIH,IAAI,CAACO,GAAG,CAAC,CAAC,EAAEX,MAAM,CAAC;OAC7B,MAAM;QACLO,KAAK,IAAIH,IAAI,CAACO,GAAG,CAAC,CAAC,EAAE,CAACZ,KAAK,GAAGC,MAAM,IAAI,CAAC,CAAC;;MAG5C,IAAI,IAAI,CAACS,YAAY,KAAK,QAAQ,EAAE;QAClC,IAAMnB,MAAM,GAAGc,IAAI,CAACC,IAAI,CAACE,KAAK,CAAC;QAC/BhC,KAAK,GAAGA,KAAK,IAAI,SAAS;QAC1B,IAAIA,KAAK,KAAK,SAAS,IAAIA,KAAK,KAAK,OAAO,EAAE;UAC5C,MAAM,IAAIf,mBAAmB,WACtB,IAAI,CAACoD,YAAY,EAAE,qCAA2BrC,KAAK,OAAI;;QAEhE,OAAOnB,eAAe,CAACkB,KAAK,EAAE,CAAC,EAAEgB,MAAM,EAAEf,KAAK,EAAE,IAAI,CAACW,IAAI,CAAC;OAC3D,MAAM;QACL,IAAM2B,KAAK,GAAGT,IAAI,CAACC,IAAI,CAAC,CAAC,GAAGE,KAAK,CAAC;QAClC,OAAOxD,aAAa,CAACuB,KAAK,EAAE,CAACuC,KAAK,EAAEA,KAAK,EAAEtC,KAAK,EAAE,IAAI,CAACW,IAAI,CAAC;;IAEhE;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,OAAO;QACLqB,KAAK,EAAE,IAAI,CAACA,KAAK;QACjBC,IAAI,EAAE,IAAI,CAACA,IAAI;QACfC,YAAY,EAAE,IAAI,CAACA,YAAY;QAC/BvB,IAAI,EAAE,IAAI,CAACA;OACZ;IACH;EAAC;EAAA;AAAA,EA7DkCf,WAAW;AAC9C;AACOmC,yBAAS,GAAG,iBAAiB;AA6DtCrD,aAAa,CAACuB,aAAa,CAAC8B,eAAe,CAAC;AAO5C,WAAaQ,aAAc;EAAA;EAAA;EAIzB;;;;;;;EAOA,uBAAYnC,IAA8B;IAAA;IAAA,2BAClC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,QAAQ;MACdC,YAAY,EAAE,SAAS;MACvBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC;EACH;EAAC;IAAA;IAAA,OAEQ,wBAAY;MACnB;MACA;MACA;MACA,OAAOoB,eAAe,CAACS,SAAS;IAClC;EAAC;EAAA;AAAA,EAzBgCT,eAAe;AAChD;AACgBQ,uBAAS,GAAG,eAAe;AAyB7C7D,aAAa,CAACuB,aAAa,CAACsC,aAAa,CAAC;AAE1C,WAAaE,YAAa;EAAA;EAAA;EAIxB;;;;;;;EAOA,sBAAYrC,IAA8B;IAAA;IAAA,2BAClC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,QAAQ;MACdC,YAAY,EAAE,QAAQ;MACtBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC;EACH;EAAC;IAAA;IAAA,OAEQ,wBAAY;MACnB;MACA;MACA;MACA,OAAOoB,eAAe,CAACS,SAAS;IAClC;EAAC;EAAA;AAAA,EAzB+BT,eAAe;AAC/C;AACgBU,sBAAS,GAAG,cAAc;AAyB5C/D,aAAa,CAACuB,aAAa,CAACwC,YAAY,CAAC;AAEzC,WAAaC,QAAS;EAAA;EAAA;EAIpB,kBAAYtC,IAA8B;IAAA;IAAA,2BAClC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,QAAQ;MACtBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC;EACH;EAAC;IAAA;IAAA,OAEQ,wBAAY;MACnB;MACA;MACA;MACA,OAAOoB,eAAe,CAACS,SAAS;IAClC;EAAC;EAAA;AAAA,EAlB2BT,eAAe;AAC3C;AACgBW,kBAAS,GAAG,UAAU;AAkBxChE,aAAa,CAACuB,aAAa,CAACyC,QAAQ,CAAC;AAErC,WAAaC,SAAU;EAAA;EAAA;EAIrB,mBAAYvC,IAA8B;IAAA;IAAA,2BAClC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,SAAS;MACvBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC;EACH;EAAC;IAAA;IAAA,OAEQ,wBAAY;MACnB;MACA;MACA;MACA,OAAOoB,eAAe,CAACS,SAAS;IAClC;EAAC;EAAA;AAAA,EAlB4BT,eAAe;AAC5C;AACgBY,mBAAS,GAAG,WAAW;AAkBzCjE,aAAa,CAACuB,aAAa,CAAC0C,SAAS,CAAC;AAEtC,WAAaC,WAAY;EAAA;EAAA;EAIvB,qBAAYxC,IAA8B;IAAA;IAAA,2BAClC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,QAAQ;MACtBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC;EACH;EAAC;IAAA;IAAA,OAEQ,wBAAY;MACnB;MACA;MACA;MACA,OAAOoB,eAAe,CAACS,SAAS;IAClC;EAAC;EAAA;AAAA,EAlB8BT,eAAe;AAC9C;AACgBa,qBAAS,GAAG,aAAa;AAkB3ClE,aAAa,CAACuB,aAAa,CAAC2C,WAAW,CAAC;AAExC,WAAaC,YAAa;EAAA;EAAA;EAIxB,sBAAYzC,IAA8B;IAAA;IAAA,2BAClC;MACJ4B,KAAK,EAAE,GAAG;MACVC,IAAI,EAAE,OAAO;MACbC,YAAY,EAAE,SAAS;MACvBvB,IAAI,EAAEP,IAAI,IAAI,IAAI,GAAG,IAAI,GAAGA,IAAI,CAACO;KAClC;EACH;EAAC;IAAA;IAAA,OAEQ,wBAAY;MACnB;MACA;MACA;MACA,OAAOoB,eAAe,CAACS,SAAS;IAClC;EAAC;EAAA;AAAA,EAlB+BT,eAAe;AAC/C;AACgBc,sBAAS,GAAG,cAAc;AAkB5CnE,aAAa,CAACuB,aAAa,CAAC4C,YAAY,CAAC;AASzC,WAAaC,UAAW;EAAA;EAAA;EAOtB,oBAAY1C,IAAqB;IAAA;IAAA;IAC/B;IALO,mBAAY,GAAG,CAAC;IAMvB,OAAKgB,IAAI,GAAGhB,IAAI,CAACgB,IAAI,IAAI,IAAI,GAAG,OAAK2B,YAAY,GAAG3C,IAAI,CAACgB,IAAI;IAC7D,OAAKT,IAAI,GAAGP,IAAI,CAACO,IAAI;IAErB,IAAI,OAAKA,IAAI,IAAI,IAAI,EAAE;MACrB,MAAM,IAAI1B,mBAAmB,CACzB,gEAAgE,CAAC;;IACtE;EACH;EAAC;IAAA;IAAA,OAED,eAAMc,KAAY,EAAEC,KAAgB;MAAA;MAClC,OAAOrB,IAAI,CAAC,YAAK;QACf,IAAIoB,KAAK,CAACsB,MAAM,GAAG,CAAC,EAAE;UACpB,MAAM,IAAIpC,mBAAmB,CAAC,4BAA4B,CAAC;;QAE7D,IAAIc,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,GAAG,IAAI,EAAE;UAC9BiD,OAAO,CAACC,IAAI,CACR,uFACclD,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,iBAAc,yBACzB,CAAC;;QAG7B;QACA,IAAMmD,eAAe,GACjBnD,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,GAAG,CAACA,KAAK,CAAC,CAAC,CAAC,EAAEA,KAAK,CAAC,CAAC,CAAC,CAAC,GAAGA,KAAK;QACtD,IAAMoD,CAAC,GAAGpE,CAAC,CAACkC,YAAY,CAACiC,eAAe,EAAE,CAAC,EAAE,CAAC,EAAE,SAAS,CAAa;QACtE,IAAIE,CAAC,GAAG/E,MAAM,CAACgF,WAAW,CAACF,CAAC,CAAa;QACzC,IAAIpD,KAAK,CAAC,CAAC,CAAC,GAAGA,KAAK,CAAC,CAAC,CAAC,EAAE;UACvBqD,CAAC,GAAGxE,SAAS,CAACwE,CAAC,CAAC;;QAElB,OAAO9E,GAAG,CAAC,OAAI,CAAC8C,IAAI,EAAEgC,CAAC,CAAC;MAC1B,CAAC,CAAC;IACJ;EAAC;IAAA;IAAA,OAEQ,qBAAS;MAChB,OAAO;QACLhC,IAAI,EAAE,IAAI,CAACA,IAAI;QACfT,IAAI,EAAE,IAAI,CAACA;OACZ;IACH;EAAC;EAAA;AAAA,EA/C6Bf,WAAW;AACzC;AACOkD,oBAAS,GAAG,YAAY;AA+CjCpE,aAAa,CAACuB,aAAa,CAAC6C,UAAU,CAAC;AAQvC;AACA;AACA,OAAO,IAAMQ,0CAA0C,GACD;EAChD,UAAU,EAAE,UAAU;EACtB,cAAc,EAAE,cAAc;EAC9B,eAAe,EAAE,eAAe;EAChC,UAAU,EAAE,UAAU;EACtB,WAAW,EAAE,WAAW;EACxB,UAAU,EAAE,UAAU;EACtB,aAAa,EAAE,aAAa;EAC5B,cAAc,EAAE,cAAc;EAC9B,MAAM,EAAE,MAAM;EACd,YAAY,EAAE,YAAY;EAC1B,cAAc,EAAE,cAAc;EAC9B,eAAe,EAAE,eAAe;EAChC,iBAAiB,EAAE,iBAAiB;EACpC,iBAAiB,EAAE,iBAAiB;EACpC,OAAO,EAAE;CACV;AAEL,SAASC,sBAAsB,CAC3BC,MAAgC,EACY;EAAA,IAA5CC,oFAA0C,EAAE;EAC9C,OAAOnE,sBAAsB,CACzBkE,MAAM,EAAE9E,aAAa,CAACgF,gBAAgB,CAACC,MAAM,EAAE,CAACC,YAAY,EAC5DH,aAAa,EAAE,aAAa,CAAC;AACnC;AAEA,OAAM,SAAUI,oBAAoB,CAACC,WAAwB;EAE3D,OAAOvE,oBAAoB,CAACuE,WAAW,CAAC;AAC1C;AAEA,OAAM,SAAUC,cAAc,CAACC,UACwB;EACrD,IAAI,OAAOA,UAAU,KAAK,QAAQ,EAAE;IAClC,IAAMxB,SAAS,GAAGwB,UAAU,IAAIV,0CAA0C,GACtEA,0CAA0C,CAACU,UAAU,CAAC,GACtDA,UAAU;IACd;;;IAGA,IAAIxB,SAAS,KAAK,cAAc,EAAE;MAChC,OAAO,IAAIC,YAAY,EAAE;KAC1B,MAAM,IAAID,SAAS,KAAK,eAAe,EAAE;MACxC,OAAO,IAAID,aAAa,EAAE;KAC3B,MAAM,IAAIC,SAAS,KAAK,UAAU,EAAE;MACnC,OAAO,IAAIE,QAAQ,EAAE;KACtB,MAAM,IAAIF,SAAS,KAAK,WAAW,EAAE;MACpC,OAAO,IAAIG,SAAS,EAAE;KACvB,MAAM,IAAIH,SAAS,KAAK,aAAa,EAAE;MACtC,OAAO,IAAII,WAAW,EAAE;KACzB,MAAM,IAAIJ,SAAS,KAAK,cAAc,EAAE;MACvC,OAAO,IAAIK,YAAY,EAAE;KAC1B,MAAM;MACL,IAAMW,MAAM,GAA6B,EAAE;MAC3CA,MAAM,CAAC,WAAW,CAAC,GAAGhB,SAAS;MAC/BgB,MAAM,CAAC,QAAQ,CAAC,GAAG,EAAE;MACrB,OAAOD,sBAAsB,CAACC,MAAM,CAAC;;GAExC,MAAM,IAAIQ,UAAU,YAAYpE,WAAW,EAAE;IAC5C,OAAOoE,UAAU;GAClB,MAAM;IACL,OAAOT,sBAAsB,CAACS,UAAU,CAAC;;AAE7C","names":["eye","linalg","mul","ones","randomUniform","scalar","serialization","tidy","transpose","truncatedNormal","zeros","K","checkDataFormat","NotImplementedError","ValueError","VALID_DISTRIBUTION_VALUES","VALID_FAN_MODE_VALUES","checkStringTypeUnionValue","deserializeKerasObject","serializeKerasObject","arrayProd","checkFanMode","value","checkDistribution","Initializer","Serializable","Zeros","shape","dtype","registerClass","Ones","Constant","args","undefined","RandomUniform","minval","DEFAULT_MINVAL","maxval","DEFAULT_MAXVAL","seed","RandomNormal","mean","DEFAULT_MEAN","stddev","DEFAULT_STDDEV","randomNormal","TruncatedNormal","Identity","gain","length","computeFans","dataFormat","fanIn","fanOut","indexOf","receptiveFieldSize","shapeProd","Math","sqrt","VarianceScaling","scale","mode","distribution","fans","max","getClassName","limit","GlorotUniform","className","GlorotNormal","HeNormal","HeUniform","LeCunNormal","LeCunUniform","Orthogonal","DEFAULT_GAIN","console","warn","normalizedShape","a","q","gramSchmidt","INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP","deserializeInitializer","config","customObjects","SerializationMap","getMap","classNameMap","serializeInitializer","initializer","getInitializer","identifier"],"sources":["E:\\react-detect-toxicity-in-a-chat-app-youtube-2\\Toxic-Word-Checker\\node_modules\\@tensorflow\\tfjs-layers\\src\\initializers.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {DataType, eye, linalg, mul, ones, randomUniform, scalar, serialization, Tensor, Tensor2D, tidy, transpose, truncatedNormal, zeros} from '@tensorflow/tfjs-core';\n\nimport * as K from './backend/tfjs_backend';\nimport {checkDataFormat} from './common';\nimport {NotImplementedError, ValueError} from './errors';\nimport {DataFormat, Shape} from './keras_format/common';\nimport {Distribution, FanMode, VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES} from './keras_format/initializer_config';\nimport {checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject} from './utils/generic_utils';\nimport {arrayProd} from './utils/math_utils';\n\nexport function checkFanMode(value?: string): void {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\n\nexport function checkDistribution(value?: string): void {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nexport abstract class Initializer extends serialization.Serializable {\n  public fromConfigUsesCustomObjects(): boolean {\n    return false;\n  }\n  /**\n   * Generate an initial value.\n   * @param shape\n   * @param dtype\n   * @return The init value.\n   */\n  abstract apply(shape: Shape, dtype?: DataType): Tensor;\n\n  getConfig(): serialization.ConfigDict {\n    return {};\n  }\n}\n\nexport class Zeros extends Initializer {\n  /** @nocollapse */\n  static className = 'Zeros';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return zeros(shape, dtype);\n  }\n}\nserialization.registerClass(Zeros);\n\nexport class Ones extends Initializer {\n  /** @nocollapse */\n  static className = 'Ones';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return ones(shape, dtype);\n  }\n}\nserialization.registerClass(Ones);\n\nexport interface ConstantArgs {\n  /** The value for each element in the variable. */\n  value: number;\n}\n\nexport class Constant extends Initializer {\n  /** @nocollapse */\n  static className = 'Constant';\n  private value: number;\n  constructor(args: ConstantArgs) {\n    super();\n    if (typeof args !== 'object') {\n      throw new ValueError(\n          `Expected argument of type ConstantConfig but got ${args}`);\n    }\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n    this.value = args.value;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {\n      value: this.value,\n    };\n  }\n}\nserialization.registerClass(Constant);\n\nexport interface RandomUniformArgs {\n  /** Lower bound of the range of random values to generate. */\n  minval?: number;\n  /** Upper bound of the range of random values to generate. */\n  maxval?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomUniform extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomUniform';\n  readonly DEFAULT_MINVAL = -0.05;\n  readonly DEFAULT_MAXVAL = 0.05;\n  private minval: number;\n  private maxval: number;\n  private seed: number;\n\n  constructor(args: RandomUniformArgs) {\n    super();\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return randomUniform(shape, this.minval, this.maxval, dtype, this.seed);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {minval: this.minval, maxval: this.maxval, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomUniform);\n\nexport interface RandomNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomNormal';\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: RandomNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `randomNormal does not support dType ${dtype}.`);\n    }\n\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomNormal);\n\nexport interface TruncatedNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class TruncatedNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'TruncatedNormal';\n\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: TruncatedNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `truncatedNormal does not support dType ${dtype}.`);\n    }\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(TruncatedNormal);\n\nexport interface IdentityArgs {\n  /**\n   * Multiplicative factor to apply to the identity matrix.\n   */\n  gain?: number;\n}\n\nexport class Identity extends Initializer {\n  /** @nocollapse */\n  static className = 'Identity';\n  private gain: number;\n  constructor(args: IdentityArgs) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError(\n            'Identity matrix initializer can only be used for' +\n            ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {gain: this.gain};\n  }\n}\nserialization.registerClass(Identity);\n\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(\n    shape: Shape, dataFormat: DataFormat = 'channelsLast'): number[] {\n  let fanIn: number;\n  let fanOut: number;\n  checkDataFormat(dataFormat);\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n\n  return [fanIn, fanOut];\n}\n\nexport interface VarianceScalingArgs {\n  /** Scaling factor (positive float). */\n  scale?: number;\n\n  /** Fanning mode for inputs and outputs. */\n  mode?: FanMode;\n\n  /** Probabilistic distribution of the values. */\n  distribution?: Distribution;\n\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class VarianceScaling extends Initializer {\n  /** @nocollapse */\n  static className = 'VarianceScaling';\n  private scale: number;\n  private mode: FanMode;\n  private distribution: Distribution;\n  private seed: number;\n\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args: VarianceScalingArgs) {\n    super();\n    if (args.scale < 0.0) {\n      throw new ValueError(\n          `scale must be a positive float. Got: ${args.scale}`);\n    }\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution =\n        args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(\n            `${this.getClassName()} does not support dType ${dtype}.`);\n      }\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype, this.seed);\n    }\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n}\nserialization.registerClass(VarianceScaling);\n\nexport interface SeedOnlyInitializerArgs {\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class GlorotUniform extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'GlorotUniform';\n\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotUniform);\n\nexport class GlorotNormal extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'GlorotNormal';\n\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotNormal);\n\nexport class HeNormal extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'HeNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeNormal);\n\nexport class HeUniform extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'HeUniform';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeUniform);\n\nexport class LeCunNormal extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunNormal);\n\nexport class LeCunUniform extends VarianceScaling {\n  /** @nocollapse */\n  static override className = 'LeCunUniform';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  override getClassName(): string {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunUniform);\n\nexport interface OrthogonalArgs extends SeedOnlyInitializerArgs {\n  /**\n   * Multiplicative factor to apply to the orthogonal matrix. Defaults to 1.\n   */\n  gain?: number;\n}\n\nexport class Orthogonal extends Initializer {\n  /** @nocollapse */\n  static className = 'Orthogonal';\n  readonly DEFAULT_GAIN = 1;\n  protected readonly gain: number;\n  protected readonly seed: number;\n\n  constructor(args?: OrthogonalArgs) {\n    super();\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n\n    if (this.seed != null) {\n      throw new NotImplementedError(\n          'Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length < 2) {\n        throw new NotImplementedError('Shape must be at least 2D.');\n      }\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(\n            `Orthogonal initializer is being called on a matrix with more ` +\n            `than 2000 (${shape[0] * shape[1]}) elements: ` +\n            `Slowness may result.`);\n      }\n\n      // TODO(cais): Add seed support.\n      const normalizedShape =\n          shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32') as Tensor2D;\n      let q = linalg.gramSchmidt(a) as Tensor2D;\n      if (shape[0] > shape[1]) {\n        q = transpose(q);\n      }\n      return mul(this.gain, q);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    return {\n      gain: this.gain,\n      seed: this.seed,\n    };\n  }\n}\nserialization.registerClass(Orthogonal);\n\n/** @docinline */\nexport type InitializerIdentifier =\n    'constant'|'glorotNormal'|'glorotUniform'|'heNormal'|'heUniform'|'identity'|\n    'leCunNormal'|'leCunUniform'|'ones'|'orthogonal'|'randomNormal'|\n    'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string;\n\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP:\n    {[identifier in InitializerIdentifier]: string} = {\n      'constant': 'Constant',\n      'glorotNormal': 'GlorotNormal',\n      'glorotUniform': 'GlorotUniform',\n      'heNormal': 'HeNormal',\n      'heUniform': 'HeUniform',\n      'identity': 'Identity',\n      'leCunNormal': 'LeCunNormal',\n      'leCunUniform': 'LeCunUniform',\n      'ones': 'Ones',\n      'orthogonal': 'Orthogonal',\n      'randomNormal': 'RandomNormal',\n      'randomUniform': 'RandomUniform',\n      'truncatedNormal': 'TruncatedNormal',\n      'varianceScaling': 'VarianceScaling',\n      'zeros': 'Zeros'\n    };\n\nfunction deserializeInitializer(\n    config: serialization.ConfigDict,\n    customObjects: serialization.ConfigDict = {}): Initializer {\n  return deserializeKerasObject(\n      config, serialization.SerializationMap.getMap().classNameMap,\n      customObjects, 'initializer');\n}\n\nexport function serializeInitializer(initializer: Initializer):\n    serialization.ConfigDictValue {\n  return serializeKerasObject(initializer);\n}\n\nexport function getInitializer(identifier: InitializerIdentifier|Initializer|\n                               serialization.ConfigDict): Initializer {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ?\n        INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] :\n        identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config: serialization.ConfigDict = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}